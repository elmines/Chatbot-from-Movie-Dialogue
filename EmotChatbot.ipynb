{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will build a chatbot using conversations from Cornell University's [Movie Dialogue Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html). The main features of our model are LSTM cells, a bidirectional dynamic RNN, and decoders with attention. \n",
    "\n",
    "The conversations will be cleaned rather extensively to help the model to produce better responses. As part of the cleaning process, punctuation will be removed, rare words will be replaced with \"UNK\" (our \"unknown\" token), longer sentences will not be used, and all letters will be in the lowercase. \n",
    "\n",
    "With a larger amount of data, it would be more practical to keep features, such as punctuation. However, I am using FloydHub's GPU services and I don't want to get carried away with too training for too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import time\n",
    "\n",
    "from corpus import Corpus\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the code to load the data is courtesy of https://github.com/suriyadeepan/practical_seq2seq/blob/master/datasets/cornell_corpus/data.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect and Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornell_corpus = Corpus(\"movie_lines.txt\", \"movie_conversations.txt\", max_vocab=8100, max_line_length=30)\n",
    "questions_text = cornell_corpus.prompts\n",
    "answers_text = cornell_corpus.answers\n",
    "questions_int = cornell_corpus.prompts_int\n",
    "answers_int = cornell_corpus.answers_int\n",
    "\n",
    "UNK = cornell_corpus.unk\n",
    "vocab2int = cornell_corpus.vocab2int\n",
    "int2vocab = cornell_corpus.int2vocab\n",
    "\n",
    "METATOKEN_INDEX = len(vocab2int)\n",
    "EOS = \"<EOS>\"\n",
    "PAD = \"<PAD>\"\n",
    "GO = \"<GO>\"\n",
    "    \n",
    "\n",
    "source_vocab_size = len(vocab2int)\n",
    "dest_vocab_size = len(vocab2int)\n",
    "\n",
    "vocab_dicts = (vocab2int, int2vocab)\n",
    "(questions_vocab_to_int, questions_int_to_vocab) = vocab_dicts\n",
    "(answers_vocab_to_int, answers_int_to_vocab) = vocab_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Word2Vec</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_corpus=[]\n",
    "combined_corpus.extend(questions_text)\n",
    "combined_corpus.extend(answers_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394916"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['can',\n",
       "  'we',\n",
       "  'make',\n",
       "  'this',\n",
       "  'quick',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  'and',\n",
       "  'andrew',\n",
       "  'barrett',\n",
       "  'are',\n",
       "  'having',\n",
       "  'an',\n",
       "  'incredibly',\n",
       "  '<UNK>',\n",
       "  'public',\n",
       "  'break',\n",
       "  'up',\n",
       "  'on',\n",
       "  'the',\n",
       "  '<UNK>',\n",
       "  'again'],\n",
       " ['well',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'we',\n",
       "  'would',\n",
       "  'start',\n",
       "  'with',\n",
       "  '<UNK>',\n",
       "  'if',\n",
       "  'that',\n",
       "  'okay',\n",
       "  'with',\n",
       "  'you'],\n",
       " ['not', 'the', 'hacking', 'and', '<UNK>', 'and', '<UNK>', 'part', 'please'],\n",
       " ['you',\n",
       "  'are',\n",
       "  'asking',\n",
       "  'me',\n",
       "  'out',\n",
       "  'that',\n",
       "  'so',\n",
       "  'cute',\n",
       "  'what',\n",
       "  'your',\n",
       "  'name',\n",
       "  'again'],\n",
       " ['no',\n",
       "  'no',\n",
       "  'it',\n",
       "  'my',\n",
       "  'fault',\n",
       "  'we',\n",
       "  'did',\n",
       "  'not',\n",
       "  'have',\n",
       "  'a',\n",
       "  'proper',\n",
       "  'introduction'],\n",
       " ['cameron'],\n",
       " ['the',\n",
       "  'thing',\n",
       "  'is',\n",
       "  'cameron',\n",
       "  'i',\n",
       "  'at',\n",
       "  'the',\n",
       "  'mercy',\n",
       "  'of',\n",
       "  'a',\n",
       "  'particularly',\n",
       "  '<UNK>',\n",
       "  'breed',\n",
       "  'of',\n",
       "  'loser',\n",
       "  'my',\n",
       "  'sister',\n",
       "  'i',\n",
       "  'ca',\n",
       "  'not',\n",
       "  'date',\n",
       "  'until',\n",
       "  'she',\n",
       "  'does'],\n",
       " ['why'],\n",
       " ['<UNK>',\n",
       "  'mystery',\n",
       "  'she',\n",
       "  'used',\n",
       "  'to',\n",
       "  'be',\n",
       "  'really',\n",
       "  'popular',\n",
       "  'when',\n",
       "  'she',\n",
       "  'started',\n",
       "  'high',\n",
       "  'school',\n",
       "  'then',\n",
       "  'it',\n",
       "  'was',\n",
       "  'just',\n",
       "  'like',\n",
       "  'she',\n",
       "  'got',\n",
       "  'sick',\n",
       "  'of',\n",
       "  'it',\n",
       "  'or',\n",
       "  'something'],\n",
       " ['gosh', 'if', 'only', 'we', 'could', 'find', 'kat', 'a', 'boyfriend'],\n",
       " ['<UNK>', 'ma', '<UNK>', 'this', 'is', 'my', 'head'],\n",
       " ['that', 'because', 'it', 'such', 'a', 'nice', 'one'],\n",
       " ['how',\n",
       "  'is',\n",
       "  'our',\n",
       "  'little',\n",
       "  'find',\n",
       "  'the',\n",
       "  '<UNK>',\n",
       "  'a',\n",
       "  'date',\n",
       "  'plan',\n",
       "  '<UNK>'],\n",
       " ['there'],\n",
       " ['you', 'got', 'something', 'on', 'your', 'mind'],\n",
       " ['you', 'have', 'my', 'word', 'as', 'a', 'gentleman'],\n",
       " ['how', 'do', 'you', 'get', 'your', 'hair', 'to', 'look', 'like', 'that'],\n",
       " ['sure', 'have'],\n",
       " ['i',\n",
       "  'really',\n",
       "  'really',\n",
       "  'really',\n",
       "  'wan',\n",
       "  'na',\n",
       "  'go',\n",
       "  'but',\n",
       "  'i',\n",
       "  'ca',\n",
       "  'not',\n",
       "  'not',\n",
       "  'unless',\n",
       "  'my',\n",
       "  'sister',\n",
       "  'goes'],\n",
       " ['she', 'not', 'a'],\n",
       " ['lesbian',\n",
       "  'no',\n",
       "  'i',\n",
       "  'found',\n",
       "  'a',\n",
       "  'picture',\n",
       "  'of',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  'in',\n",
       "  'one',\n",
       "  'of',\n",
       "  'her',\n",
       "  '<UNK>',\n",
       "  'so',\n",
       "  'i',\n",
       "  'pretty',\n",
       "  'sure',\n",
       "  'she',\n",
       "  'not',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  '<UNK>'],\n",
       " ['so', 'that', 'the', 'kind', 'of', 'guy', 'she', 'likes', 'pretty', 'ones'],\n",
       " ['hi'],\n",
       " ['you', 'know', '<UNK>'],\n",
       " ['have', 'fun', 'tonight'],\n",
       " ['i',\n",
       "  'looked',\n",
       "  'for',\n",
       "  'you',\n",
       "  'back',\n",
       "  'at',\n",
       "  'the',\n",
       "  'party',\n",
       "  'but',\n",
       "  'you',\n",
       "  'always',\n",
       "  'seemed',\n",
       "  'to',\n",
       "  'be',\n",
       "  'occupied'],\n",
       " ['i', 'was'],\n",
       " ['well', 'no'],\n",
       " ['then', 'that', 'all', 'you', 'had', 'to', 'say'],\n",
       " ['but'],\n",
       " ['then',\n",
       "  '<UNK>',\n",
       "  'says',\n",
       "  'if',\n",
       "  'you',\n",
       "  'go',\n",
       "  'any',\n",
       "  'lighter',\n",
       "  'you',\n",
       "  'are',\n",
       "  'gon',\n",
       "  'na',\n",
       "  'look',\n",
       "  'like',\n",
       "  'an',\n",
       "  'extra',\n",
       "  'on'],\n",
       " ['do', 'you', 'listen', 'to', 'this', 'crap'],\n",
       " ['what', 'crap'],\n",
       " ['me', 'this', '<UNK>', 'blonde', '<UNK>', 'i', 'like', 'boring', 'myself'],\n",
       " ['i',\n",
       "  'figured',\n",
       "  'you',\n",
       "  'would',\n",
       "  'get',\n",
       "  'to',\n",
       "  'the',\n",
       "  'good',\n",
       "  'stuff',\n",
       "  'eventually'],\n",
       " ['what', 'good', 'stuff'],\n",
       " ['the', 'real', 'you'],\n",
       " ['i',\n",
       "  'kidding',\n",
       "  'you',\n",
       "  'know',\n",
       "  'how',\n",
       "  'sometimes',\n",
       "  'you',\n",
       "  'just',\n",
       "  'become',\n",
       "  'this',\n",
       "  '<UNK>',\n",
       "  'and',\n",
       "  'you',\n",
       "  'do',\n",
       "  'not',\n",
       "  'know',\n",
       "  'how',\n",
       "  'to',\n",
       "  'quit'],\n",
       " ['no'],\n",
       " ['wow'],\n",
       " ['she', 'okay'],\n",
       " ['they', 'do', 'to'],\n",
       " ['did', 'you', 'change', 'your', 'hair'],\n",
       " ['no'],\n",
       " ['where', 'did', 'he', 'go', 'he', 'was', 'just', 'here'],\n",
       " ['who'],\n",
       " ['great'],\n",
       " ['he',\n",
       "  'practically',\n",
       "  'proposed',\n",
       "  'when',\n",
       "  'he',\n",
       "  'found',\n",
       "  'out',\n",
       "  'we',\n",
       "  'had',\n",
       "  'the',\n",
       "  'same',\n",
       "  '<UNK>',\n",
       "  'i',\n",
       "  'mean',\n",
       "  'dr',\n",
       "  '<UNK>',\n",
       "  'is',\n",
       "  'great',\n",
       "  'an',\n",
       "  'all',\n",
       "  'but',\n",
       "  'he',\n",
       "  'not',\n",
       "  'exactly',\n",
       "  'relevant',\n",
       "  'party',\n",
       "  'conversation'],\n",
       " ['is', 'he', '<UNK>', 'or', 'dry'],\n",
       " ['bianca',\n",
       "  'i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'think',\n",
       "  'the',\n",
       "  '<UNK>',\n",
       "  'of',\n",
       "  'dating',\n",
       "  'joey',\n",
       "  '<UNK>',\n",
       "  'are',\n",
       "  'going',\n",
       "  'to',\n",
       "  'include',\n",
       "  '<UNK>',\n",
       "  'and',\n",
       "  '<UNK>'],\n",
       " ['sometimes',\n",
       "  'i',\n",
       "  'wonder',\n",
       "  'if',\n",
       "  'the',\n",
       "  'guys',\n",
       "  'we',\n",
       "  'are',\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'want',\n",
       "  'to',\n",
       "  'go',\n",
       "  'out',\n",
       "  'with',\n",
       "  'are',\n",
       "  'the',\n",
       "  'ones',\n",
       "  'we',\n",
       "  'actually',\n",
       "  'want',\n",
       "  'to',\n",
       "  'go',\n",
       "  'out',\n",
       "  'with',\n",
       "  'you',\n",
       "  'know'],\n",
       " ['i', 'have', 'to', 'be', 'home', 'in', 'twenty', 'minutes'],\n",
       " ['you', 'think', 'you', 're', 'the', 'only', '<UNK>', 'at', 'the', 'prom'],\n",
       " ['it', 'more'],\n",
       " ['exactly',\n",
       "  'so',\n",
       "  'you',\n",
       "  'going',\n",
       "  'to',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  'thing',\n",
       "  'on',\n",
       "  'saturday'],\n",
       " ['queen', 'harry'],\n",
       " ['neat'],\n",
       " ['hey', 'sweet', 'cheeks'],\n",
       " ['hi', 'joey'],\n",
       " ['listen', 'i', 'want', 'to', 'talk', 'to', 'you', 'about', 'the', 'prom'],\n",
       " ['where', 'have', 'you', 'been'],\n",
       " ['i',\n",
       "  'have',\n",
       "  'the',\n",
       "  'potential',\n",
       "  'to',\n",
       "  'smack',\n",
       "  'the',\n",
       "  'crap',\n",
       "  'out',\n",
       "  'of',\n",
       "  'you',\n",
       "  'if',\n",
       "  'you',\n",
       "  'do',\n",
       "  'not',\n",
       "  'get',\n",
       "  'out',\n",
       "  'of',\n",
       "  'my',\n",
       "  'way'],\n",
       " ['oh',\n",
       "  'my',\n",
       "  'god',\n",
       "  'does',\n",
       "  'this',\n",
       "  'mean',\n",
       "  'you',\n",
       "  'are',\n",
       "  'becoming',\n",
       "  'normal'],\n",
       " ['it',\n",
       "  'means',\n",
       "  'that',\n",
       "  '<UNK>',\n",
       "  'is',\n",
       "  'playing',\n",
       "  'at',\n",
       "  'club',\n",
       "  '<UNK>',\n",
       "  'and',\n",
       "  'we',\n",
       "  'are',\n",
       "  'going'],\n",
       " ['oh',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'you',\n",
       "  'might',\n",
       "  'have',\n",
       "  'a',\n",
       "  'date',\n",
       "  'i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'know',\n",
       "  'why',\n",
       "  'i',\n",
       "  'bothering',\n",
       "  'to',\n",
       "  'ask',\n",
       "  'but',\n",
       "  'are',\n",
       "  'you',\n",
       "  'going',\n",
       "  'to',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  'party',\n",
       "  'saturday',\n",
       "  'night'],\n",
       " ['what', 'do', 'you', 'think'],\n",
       " ['you',\n",
       "  'are',\n",
       "  'ruining',\n",
       "  'my',\n",
       "  'life',\n",
       "  'because',\n",
       "  'you',\n",
       "  'wo',\n",
       "  'not',\n",
       "  'be',\n",
       "  'normal',\n",
       "  'i',\n",
       "  'ca',\n",
       "  'not',\n",
       "  'be',\n",
       "  'normal'],\n",
       " ['what', 'normal'],\n",
       " ['ca',\n",
       "  'not',\n",
       "  'you',\n",
       "  'forget',\n",
       "  'for',\n",
       "  'just',\n",
       "  'one',\n",
       "  'night',\n",
       "  'that',\n",
       "  'you',\n",
       "  'are',\n",
       "  'completely',\n",
       "  'wretched'],\n",
       " ['like', 'i', 'supposed', 'to', 'know', 'what', 'that', 'even', 'means'],\n",
       " ['it', 'shakespeare', 'maybe', 'you', 'have', 'heard', 'of', 'him'],\n",
       " ['you', 'are', 'so', 'completely', '<UNK>'],\n",
       " ['bianca',\n",
       "  'i',\n",
       "  'need',\n",
       "  'to',\n",
       "  'talk',\n",
       "  'to',\n",
       "  'you',\n",
       "  'i',\n",
       "  'need',\n",
       "  'to',\n",
       "  'tell',\n",
       "  'you'],\n",
       " ['i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'get',\n",
       "  'you',\n",
       "  'you',\n",
       "  'act',\n",
       "  'like',\n",
       "  'you',\n",
       "  'are',\n",
       "  'too',\n",
       "  'good',\n",
       "  'for',\n",
       "  'any',\n",
       "  'of',\n",
       "  'this',\n",
       "  'and',\n",
       "  'then',\n",
       "  'you',\n",
       "  'go',\n",
       "  'totally',\n",
       "  '<UNK>',\n",
       "  'when',\n",
       "  'you',\n",
       "  'get',\n",
       "  'here'],\n",
       " ['listen',\n",
       "  'i',\n",
       "  'know',\n",
       "  'you',\n",
       "  'hate',\n",
       "  'having',\n",
       "  'to',\n",
       "  'sit',\n",
       "  'home',\n",
       "  'because',\n",
       "  'i',\n",
       "  'not',\n",
       "  'susie',\n",
       "  'high',\n",
       "  'school'],\n",
       " ['like', 'you', 'care'],\n",
       " ['i',\n",
       "  'do',\n",
       "  'care',\n",
       "  'but',\n",
       "  'i',\n",
       "  'a',\n",
       "  'firm',\n",
       "  'believer',\n",
       "  'in',\n",
       "  'doing',\n",
       "  'something',\n",
       "  'for',\n",
       "  'your',\n",
       "  'own',\n",
       "  'reasons',\n",
       "  'not',\n",
       "  'someone',\n",
       "  'else',\n",
       "  's'],\n",
       " ['joey', 'never', 'told', 'you', 'we', 'went', 'out', 'did', 'he'],\n",
       " ['what'],\n",
       " ['in', 'for', 'a', 'month'],\n",
       " ['why'],\n",
       " ['he', 'was', 'like', 'a', 'total', 'babe'],\n",
       " ['but', 'you', 'hate', 'joey'],\n",
       " ['now', 'i', 'do', 'back', 'then', 'was', 'a', 'different', 'story'],\n",
       " ['he', 'said', 'everyone', 'was', 'doing', 'it', 'so', 'i', 'did', 'it'],\n",
       " ['you', 'did', 'what'],\n",
       " ['but'],\n",
       " ['after',\n",
       "  'that',\n",
       "  'i',\n",
       "  'swore',\n",
       "  'i',\n",
       "  'would',\n",
       "  'never',\n",
       "  'do',\n",
       "  'anything',\n",
       "  'just',\n",
       "  'because',\n",
       "  'everyone',\n",
       "  'else',\n",
       "  'was',\n",
       "  'doing',\n",
       "  'it',\n",
       "  'and',\n",
       "  'i',\n",
       "  'have',\n",
       "  'not',\n",
       "  'since',\n",
       "  'except',\n",
       "  'for',\n",
       "  '<UNK>',\n",
       "  'party',\n",
       "  'and',\n",
       "  'my',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  'display'],\n",
       " ['why', 'did', 'not', 'you', 'tell', 'me'],\n",
       " ['i',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'let',\n",
       "  'you',\n",
       "  'make',\n",
       "  'up',\n",
       "  'your',\n",
       "  'own',\n",
       "  'mind',\n",
       "  'about',\n",
       "  'him'],\n",
       " ['that', 'not'],\n",
       " ['i', 'not', 'stupid', 'enough', 'to', 'repeat', 'your', 'mistakes'],\n",
       " ['i', 'guess', 'i', 'thought', 'i', 'was', 'protecting', 'you'],\n",
       " ['god',\n",
       "  'you',\n",
       "  'are',\n",
       "  'just',\n",
       "  'like',\n",
       "  'him',\n",
       "  'just',\n",
       "  'keep',\n",
       "  'me',\n",
       "  'locked',\n",
       "  'away',\n",
       "  'in',\n",
       "  'the',\n",
       "  'dark',\n",
       "  'so',\n",
       "  'i',\n",
       "  'ca',\n",
       "  'not',\n",
       "  'experience',\n",
       "  'anything',\n",
       "  'for',\n",
       "  'myself'],\n",
       " ['not',\n",
       "  'all',\n",
       "  'experiences',\n",
       "  'are',\n",
       "  'good',\n",
       "  'bianca',\n",
       "  'you',\n",
       "  'ca',\n",
       "  'not',\n",
       "  'always',\n",
       "  'trust',\n",
       "  'the',\n",
       "  'people',\n",
       "  'you',\n",
       "  'want',\n",
       "  'to'],\n",
       " ['you', 'looked', 'beautiful', 'last', 'night', 'you', 'know'],\n",
       " ['let', 'go'],\n",
       " ['you', 'set', 'me', 'up'],\n",
       " ['i', 'just', 'wanted'],\n",
       " ['what',\n",
       "  'to',\n",
       "  'completely',\n",
       "  'damage',\n",
       "  'me',\n",
       "  'to',\n",
       "  'send',\n",
       "  'me',\n",
       "  'to',\n",
       "  'therapy',\n",
       "  'forever',\n",
       "  'what'],\n",
       " ['is',\n",
       "  'that',\n",
       "  'woman',\n",
       "  'a',\n",
       "  'complete',\n",
       "  '<UNK>',\n",
       "  'or',\n",
       "  'is',\n",
       "  'it',\n",
       "  'just',\n",
       "  'me'],\n",
       " ['patrick', 'is', 'that', 'a'],\n",
       " ['now',\n",
       "  'do',\n",
       "  'not',\n",
       "  'get',\n",
       "  'upset',\n",
       "  'daddy',\n",
       "  'but',\n",
       "  'there',\n",
       "  'this',\n",
       "  'boy',\n",
       "  'and',\n",
       "  'i',\n",
       "  'think',\n",
       "  'he',\n",
       "  'might',\n",
       "  'ask'],\n",
       " ['no',\n",
       "  'you',\n",
       "  'are',\n",
       "  'not',\n",
       "  'dating',\n",
       "  'until',\n",
       "  'your',\n",
       "  'sister',\n",
       "  'starts',\n",
       "  'dating',\n",
       "  'end',\n",
       "  'of',\n",
       "  'discussion'],\n",
       " ['what', 'if', 'she', 'never', 'starts', 'dating'],\n",
       " ['then',\n",
       "  'neither',\n",
       "  'will',\n",
       "  'you',\n",
       "  'and',\n",
       "  'i',\n",
       "  'will',\n",
       "  'get',\n",
       "  'to',\n",
       "  'sleep',\n",
       "  'at',\n",
       "  'night'],\n",
       " ['but', 'she', 'does', 'not', 'want', 'to', 'date'],\n",
       " ['daddy', 'i'],\n",
       " ['and', 'where', 'are', 'you', 'going'],\n",
       " ['if',\n",
       "  'you',\n",
       "  'must',\n",
       "  'know',\n",
       "  'we',\n",
       "  'were',\n",
       "  'attempting',\n",
       "  'to',\n",
       "  'go',\n",
       "  'to',\n",
       "  'a',\n",
       "  'small',\n",
       "  'study',\n",
       "  'group',\n",
       "  'of',\n",
       "  'friends'],\n",
       " ['otherwise', 'known', 'as', 'an', '<UNK>'],\n",
       " ['daddy', 'people', 'expect', 'me', 'to', 'be', 'there'],\n",
       " ['oh', 'god', 'it', 'starting'],\n",
       " ['wear', 'the', 'belly', 'before', 'you', 'go'],\n",
       " ['daddy', 'no'],\n",
       " ['promise',\n",
       "  'me',\n",
       "  'you',\n",
       "  'wo',\n",
       "  'not',\n",
       "  'talk',\n",
       "  'to',\n",
       "  'any',\n",
       "  'boys',\n",
       "  'unless',\n",
       "  'your',\n",
       "  'sister',\n",
       "  'is',\n",
       "  'present'],\n",
       " ['why'],\n",
       " ['daddy',\n",
       "  'i',\n",
       "  'want',\n",
       "  'to',\n",
       "  'discuss',\n",
       "  'the',\n",
       "  'prom',\n",
       "  'with',\n",
       "  'you',\n",
       "  'it',\n",
       "  'tomorrow',\n",
       "  'night'],\n",
       " ['the', 'prom', 'kat', 'has', 'a', 'date'],\n",
       " ['no', 'but'],\n",
       " ['it',\n",
       "  'that',\n",
       "  'hot',\n",
       "  'rod',\n",
       "  'joey',\n",
       "  'right',\n",
       "  'that',\n",
       "  's',\n",
       "  'who',\n",
       "  'you',\n",
       "  'want',\n",
       "  'me',\n",
       "  'to',\n",
       "  'bend',\n",
       "  'my',\n",
       "  'rules',\n",
       "  'for'],\n",
       " ['he', 'not', 'a', 'hot', 'rod', 'whatever', 'that', 'is'],\n",
       " ['you',\n",
       "  'are',\n",
       "  'not',\n",
       "  'going',\n",
       "  'unless',\n",
       "  'your',\n",
       "  'sister',\n",
       "  'goes',\n",
       "  'end',\n",
       "  'of',\n",
       "  'story'],\n",
       " ['i', 'missing', 'something'],\n",
       " ['always', 'a', 'pleasure', '<UNK>'],\n",
       " ['did',\n",
       "  'not',\n",
       "  'have',\n",
       "  'you',\n",
       "  'pegged',\n",
       "  'for',\n",
       "  'a',\n",
       "  '<UNK>',\n",
       "  'fan',\n",
       "  'are',\n",
       "  'not',\n",
       "  'they',\n",
       "  'a',\n",
       "  'little',\n",
       "  'too',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  'ring',\n",
       "  'for',\n",
       "  'you'],\n",
       " ['fan',\n",
       "  'of',\n",
       "  'a',\n",
       "  'fan',\n",
       "  'you',\n",
       "  'see',\n",
       "  'a',\n",
       "  'couple',\n",
       "  'of',\n",
       "  '<UNK>',\n",
       "  'come',\n",
       "  'in'],\n",
       " ['never'],\n",
       " ['<UNK>',\n",
       "  'girls',\n",
       "  'one',\n",
       "  'tall',\n",
       "  'decent',\n",
       "  'body',\n",
       "  'the',\n",
       "  'other',\n",
       "  'one',\n",
       "  'kinda',\n",
       "  'short',\n",
       "  'and',\n",
       "  '<UNK>'],\n",
       " ['you', 'the', 'new', 'guy'],\n",
       " ['so', 'they', 'tell', 'me'],\n",
       " ['so', 'which', 'dakota', 'you', 'from'],\n",
       " ['north', 'actually', 'how', 'would', 'you'],\n",
       " ['i', 'was', 'kidding', 'people', 'actually', 'live', 'there'],\n",
       " ['yeah', 'a', 'couple', 'we', 'are', '<UNK>', 'by', 'the', 'cows', 'though'],\n",
       " ['how', 'many', 'people', 'were', 'in', 'your', 'old', 'school'],\n",
       " ['thirtytwo'],\n",
       " ['get', 'out'],\n",
       " ['how', 'many', 'people', 'go', 'here'],\n",
       " ['that', 'i', 'used', 'to'],\n",
       " ['that', 'girl', 'i'],\n",
       " ['you', 'burn', 'you', '<UNK>', 'you', '<UNK>'],\n",
       " ['who', 'is', 'she'],\n",
       " ['bianca', '<UNK>', '<UNK>', 'do', 'not', 'even', 'think', 'about', 'it'],\n",
       " ['why', 'not'],\n",
       " ['why',\n",
       "  'do',\n",
       "  'girls',\n",
       "  'like',\n",
       "  'that',\n",
       "  'always',\n",
       "  'like',\n",
       "  'guys',\n",
       "  'like',\n",
       "  'that'],\n",
       " ['because',\n",
       "  'they',\n",
       "  'are',\n",
       "  '<UNK>',\n",
       "  'to',\n",
       "  'their',\n",
       "  'mothers',\n",
       "  'liked',\n",
       "  'guys',\n",
       "  'like',\n",
       "  'that',\n",
       "  'and',\n",
       "  'their',\n",
       "  '<UNK>',\n",
       "  'before',\n",
       "  'them',\n",
       "  'their',\n",
       "  'gene',\n",
       "  'pool',\n",
       "  'is',\n",
       "  'rarely',\n",
       "  '<UNK>'],\n",
       " ['you', 'know', 'french'],\n",
       " ['sure', 'do', 'my', 'mom', 'from', 'canada'],\n",
       " ['guess', 'who', 'just', 'signed', 'up', 'for', 'a', '<UNK>'],\n",
       " ['you',\n",
       "  'mean',\n",
       "  'i',\n",
       "  'would',\n",
       "  'get',\n",
       "  'a',\n",
       "  'chance',\n",
       "  'to',\n",
       "  'talk',\n",
       "  'to',\n",
       "  'her'],\n",
       " ['yeah', 'just', 'a', 'minor', 'encounter', 'with', 'the', '<UNK>'],\n",
       " ['that', 'her', 'bianca', 'sister'],\n",
       " ['i',\n",
       "  'teach',\n",
       "  'her',\n",
       "  'french',\n",
       "  'get',\n",
       "  'to',\n",
       "  'know',\n",
       "  'her',\n",
       "  '<UNK>',\n",
       "  'her',\n",
       "  'with',\n",
       "  'charm',\n",
       "  'and',\n",
       "  'she',\n",
       "  'falls',\n",
       "  'in',\n",
       "  'love',\n",
       "  'with',\n",
       "  'me'],\n",
       " ['what', 'about', 'him'],\n",
       " ['what', 'makes', 'you', 'think', 'he', 'will', 'do', 'it'],\n",
       " ['he', 'seems', 'like', 'he', '<UNK>', 'on', 'danger'],\n",
       " ['no',\n",
       "  'kidding',\n",
       "  'he',\n",
       "  'a',\n",
       "  'criminal',\n",
       "  'i',\n",
       "  'heard',\n",
       "  'he',\n",
       "  'lit',\n",
       "  'a',\n",
       "  'state',\n",
       "  '<UNK>',\n",
       "  'on',\n",
       "  'fire',\n",
       "  'he',\n",
       "  'just',\n",
       "  'got',\n",
       "  'out',\n",
       "  'of',\n",
       "  '<UNK>'],\n",
       " ['they', 'always', 'let', '<UNK>', 'sit', 'in', 'on', '<UNK>', '<UNK>'],\n",
       " ['i',\n",
       "  'serious',\n",
       "  'man',\n",
       "  'he',\n",
       "  'whacked',\n",
       "  'he',\n",
       "  'sold',\n",
       "  'his',\n",
       "  'own',\n",
       "  'liver',\n",
       "  'on',\n",
       "  'the',\n",
       "  'black',\n",
       "  'market',\n",
       "  'so',\n",
       "  'he',\n",
       "  'could',\n",
       "  'buy',\n",
       "  'new',\n",
       "  '<UNK>'],\n",
       " ['forget',\n",
       "  'his',\n",
       "  'reputation',\n",
       "  'do',\n",
       "  'you',\n",
       "  'think',\n",
       "  'we',\n",
       "  'have',\n",
       "  'got',\n",
       "  'a',\n",
       "  'plan',\n",
       "  'or',\n",
       "  'not'],\n",
       " ['did', 'she', 'actually', 'say', 'she', 'would', 'go', 'out', 'with', 'you'],\n",
       " ['you',\n",
       "  'know',\n",
       "  'if',\n",
       "  'you',\n",
       "  'do',\n",
       "  'go',\n",
       "  'out',\n",
       "  'with',\n",
       "  'bianca',\n",
       "  'you',\n",
       "  'would',\n",
       "  'be',\n",
       "  'set',\n",
       "  'you',\n",
       "  'would',\n",
       "  '<UNK>',\n",
       "  'everyone',\n",
       "  'strictly',\n",
       "  '<UNK>',\n",
       "  'with',\n",
       "  'me',\n",
       "  'by',\n",
       "  'your',\n",
       "  'side'],\n",
       " ['i', 'thought', 'you', 'hated', 'those', 'people'],\n",
       " ['this',\n",
       "  'is',\n",
       "  'it',\n",
       "  'a',\n",
       "  'golden',\n",
       "  'opportunity',\n",
       "  'patrick',\n",
       "  'can',\n",
       "  'ask',\n",
       "  '<UNK>',\n",
       "  'to',\n",
       "  'the',\n",
       "  'party'],\n",
       " ['in',\n",
       "  'that',\n",
       "  'case',\n",
       "  'we',\n",
       "  'will',\n",
       "  'need',\n",
       "  'to',\n",
       "  'make',\n",
       "  'it',\n",
       "  'a',\n",
       "  '<UNK>',\n",
       "  'blow',\n",
       "  'out'],\n",
       " ['will', '<UNK>', 'get', 'bent'],\n",
       " ['number', 'one', 'she', 'hates', '<UNK>'],\n",
       " ['it', 'a', 'lung', 'cancer', 'issue'],\n",
       " ['her', 'favorite', 'uncle'],\n",
       " ['he', 'pretty'],\n",
       " ['<UNK>', 'your', 'ears', 'for', 'one', 'night'],\n",
       " ['you', 'told', 'me', 'that', 'part', 'already'],\n",
       " ['extremely', 'unfortunate', 'maneuver'],\n",
       " ['the',\n",
       "  'hell',\n",
       "  'is',\n",
       "  'that',\n",
       "  'what',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'just',\n",
       "  'picks',\n",
       "  'up',\n",
       "  'a',\n",
       "  'girl',\n",
       "  'and',\n",
       "  'carries',\n",
       "  'her',\n",
       "  'away',\n",
       "  'while',\n",
       "  'you',\n",
       "  'are',\n",
       "  'talking',\n",
       "  'to',\n",
       "  'her'],\n",
       " ['<UNK>', '<UNK>', 'but', 'hey', 'you', 'are', 'making', 'progress'],\n",
       " ['you',\n",
       "  'humiliated',\n",
       "  'the',\n",
       "  'woman',\n",
       "  'sacrifice',\n",
       "  'yourself',\n",
       "  'on',\n",
       "  'the',\n",
       "  '<UNK>',\n",
       "  'of',\n",
       "  'dignity',\n",
       "  'and',\n",
       "  'even',\n",
       "  'the',\n",
       "  'score'],\n",
       " ['and',\n",
       "  'he',\n",
       "  'means',\n",
       "  'that',\n",
       "  'strictly',\n",
       "  'in',\n",
       "  'a',\n",
       "  'non',\n",
       "  '<UNK>',\n",
       "  'type',\n",
       "  'of',\n",
       "  'way'],\n",
       " ['what', 'have', 'you', 'got', 'for', 'me'],\n",
       " ['okay',\n",
       "  'likes',\n",
       "  '<UNK>',\n",
       "  'food',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  'and',\n",
       "  'angry',\n",
       "  '<UNK>',\n",
       "  'girl',\n",
       "  'music',\n",
       "  'of',\n",
       "  'the',\n",
       "  '<UNK>',\n",
       "  '<UNK>'],\n",
       " ['<UNK>', 'is', 'playing', 'there', 'tomorrow', 'night'],\n",
       " ['cameron', 'i', 'a', 'little', 'busy'],\n",
       " ['what', 'are', 'you', 'talking', 'about'],\n",
       " ['cameron', 'do', 'you', 'like', 'the', 'girl'],\n",
       " ['sure'],\n",
       " ['what', 'would', 'you', 'do', 'to', 'her'],\n",
       " ['she',\n",
       "  'hates',\n",
       "  'you',\n",
       "  'with',\n",
       "  'the',\n",
       "  'fire',\n",
       "  'of',\n",
       "  'a',\n",
       "  'thousand',\n",
       "  '<UNK>',\n",
       "  'that',\n",
       "  'a',\n",
       "  'direct',\n",
       "  'quote'],\n",
       " ['you', 'makin', 'any', '<UNK>'],\n",
       " ['she', 'kissed', 'me'],\n",
       " ['what', 'the', 'worst'],\n",
       " ['the',\n",
       "  '<UNK>',\n",
       "  'look',\n",
       "  'is',\n",
       "  'over',\n",
       "  'kat',\n",
       "  'have',\n",
       "  'not',\n",
       "  'you',\n",
       "  'been',\n",
       "  'reading',\n",
       "  'your',\n",
       "  '<UNK>'],\n",
       " ['yeah',\n",
       "  'and',\n",
       "  'i',\n",
       "  'noticed',\n",
       "  'the',\n",
       "  'only',\n",
       "  'part',\n",
       "  'of',\n",
       "  'you',\n",
       "  '<UNK>',\n",
       "  'in',\n",
       "  'your',\n",
       "  'big',\n",
       "  '<UNK>',\n",
       "  'spread',\n",
       "  'was',\n",
       "  'your',\n",
       "  '<UNK>',\n",
       "  'tough',\n",
       "  'break'],\n",
       " ['hey', 'do', 'you', 'mind'],\n",
       " ['where', 'ya', 'goin'],\n",
       " ['away'],\n",
       " ['leave', 'my', 'sister', 'alone'],\n",
       " ['yeah'],\n",
       " ['two', 'legs', 'nice', 'rack'],\n",
       " ['yeah', 'whatever', 'i', 'want', 'you', 'to', 'go', 'out', 'with', 'her'],\n",
       " ['sure', '<UNK>', 'i', 'will', 'get', 'right', 'on', 'it'],\n",
       " ['you', 'just', 'said'],\n",
       " ['you', 'need', 'money', 'to', 'take', 'a', 'girl', 'out'],\n",
       " ['you',\n",
       "  'got',\n",
       "  'it',\n",
       "  'verona',\n",
       "  'i',\n",
       "  'pick',\n",
       "  'up',\n",
       "  'the',\n",
       "  'tab',\n",
       "  'you',\n",
       "  'do',\n",
       "  'the',\n",
       "  '<UNK>'],\n",
       " ['you', 'are', 'gon', 'na', 'pay', 'me', 'to', 'take', 'out', 'some', 'girl'],\n",
       " ['i',\n",
       "  'ca',\n",
       "  'not',\n",
       "  'date',\n",
       "  'her',\n",
       "  'sister',\n",
       "  'until',\n",
       "  'that',\n",
       "  'one',\n",
       "  'gets',\n",
       "  'a',\n",
       "  'boyfriend',\n",
       "  'and',\n",
       "  'that',\n",
       "  'the',\n",
       "  'catch',\n",
       "  'she',\n",
       "  'does',\n",
       "  'not',\n",
       "  'want',\n",
       "  'a',\n",
       "  'boyfriend'],\n",
       " ['i',\n",
       "  'ca',\n",
       "  'not',\n",
       "  'take',\n",
       "  'a',\n",
       "  'girl',\n",
       "  'like',\n",
       "  'that',\n",
       "  'out',\n",
       "  'on',\n",
       "  'twenty',\n",
       "  'bucks'],\n",
       " ['take', 'it', 'or', 'leave', 'it', 'this', 'is', 'not', 'a', '<UNK>'],\n",
       " ['when', 'i', 'shell', 'out', 'fifty', 'i', 'expect', 'results'],\n",
       " ['i', 'on', 'it'],\n",
       " ['watching',\n",
       "  'the',\n",
       "  'bitch',\n",
       "  'trash',\n",
       "  'my',\n",
       "  'car',\n",
       "  'does',\n",
       "  'not',\n",
       "  'count',\n",
       "  'as',\n",
       "  'a',\n",
       "  'date'],\n",
       " ['i', 'just', '<UNK>', 'my', 'price'],\n",
       " ['what'],\n",
       " ['a', 'hundred', 'bucks', 'a', 'date'],\n",
       " ['forget', 'it'],\n",
       " ['it', 'about', 'time'],\n",
       " ['how', 'would', 'you', 'do', 'it'],\n",
       " ['do', 'what'],\n",
       " ['i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'know',\n",
       "  '<UNK>',\n",
       "  'the',\n",
       "  '<UNK>',\n",
       "  'flowers',\n",
       "  'another',\n",
       "  'hundred',\n",
       "  'for',\n",
       "  'the',\n",
       "  '<UNK>'],\n",
       " ['hey'],\n",
       " ['are', 'you', 'lost'],\n",
       " ['nope', 'just', 'came', 'by', 'to', 'chat'],\n",
       " ['we', 'do', 'not', 'chat'],\n",
       " ['well',\n",
       "  'actually',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'i',\n",
       "  'would',\n",
       "  'run',\n",
       "  'an',\n",
       "  'idea',\n",
       "  'by',\n",
       "  'you',\n",
       "  'you',\n",
       "  'know',\n",
       "  'just',\n",
       "  'to',\n",
       "  'see',\n",
       "  'if',\n",
       "  'you',\n",
       "  'are',\n",
       "  'interested'],\n",
       " ['but',\n",
       "  'she',\n",
       "  'ca',\n",
       "  'not',\n",
       "  'go',\n",
       "  'out',\n",
       "  'with',\n",
       "  'you',\n",
       "  'because',\n",
       "  'her',\n",
       "  'sister',\n",
       "  'is',\n",
       "  'this',\n",
       "  'insane',\n",
       "  'head',\n",
       "  'case',\n",
       "  'and',\n",
       "  'no',\n",
       "  'one',\n",
       "  'will',\n",
       "  'go',\n",
       "  'out',\n",
       "  'with',\n",
       "  'her',\n",
       "  'right'],\n",
       " ['does', 'this', 'conversation', 'have', 'a', 'purpose'],\n",
       " ['i', 'hear', 'you', 'are', '<UNK>', 'verona'],\n",
       " ['uh', 'yeah', 'we', 'are', 'old', '<UNK>'],\n",
       " ['you', 'and', 'verona'],\n",
       " ['you', 'better', 'not', 'fuck', 'this', 'up', 'i', 'heavily', 'invested'],\n",
       " ['who', 'that'],\n",
       " ['patrick', 'verona', 'random', '<UNK>'],\n",
       " ['that',\n",
       "  'pat',\n",
       "  'verona',\n",
       "  'the',\n",
       "  'one',\n",
       "  'who',\n",
       "  'was',\n",
       "  'gone',\n",
       "  'for',\n",
       "  'a',\n",
       "  'year',\n",
       "  'i',\n",
       "  'heard',\n",
       "  'he',\n",
       "  'was',\n",
       "  'doing',\n",
       "  'porn',\n",
       "  'movies'],\n",
       " ['i',\n",
       "  'sure',\n",
       "  'he',\n",
       "  'completely',\n",
       "  '<UNK>',\n",
       "  'of',\n",
       "  'doing',\n",
       "  'anything',\n",
       "  'that',\n",
       "  'interesting'],\n",
       " ['he', 'always', 'look', 'so'],\n",
       " ['<UNK>',\n",
       "  'eat',\n",
       "  'starving',\n",
       "  'yourself',\n",
       "  'is',\n",
       "  'a',\n",
       "  'very',\n",
       "  'slow',\n",
       "  'way',\n",
       "  'to',\n",
       "  'die'],\n",
       " ['what', 'this'],\n",
       " ['the', 'people', 'at', 'this', 'school', 'are', 'so', 'incredibly', 'foul'],\n",
       " ['william', 'would', 'never', 'have', 'gone', 'to', 'a', 'state', 'school'],\n",
       " ['william', 'did', 'not', 'even', 'go', 'to', 'high', 'school'],\n",
       " ['that', 'never', 'been', 'proven'],\n",
       " ['i',\n",
       "  'appreciate',\n",
       "  'your',\n",
       "  'efforts',\n",
       "  'toward',\n",
       "  'a',\n",
       "  '<UNK>',\n",
       "  'death',\n",
       "  'but',\n",
       "  'i',\n",
       "  '<UNK>',\n",
       "  'do',\n",
       "  'you',\n",
       "  'mind'],\n",
       " ['does', 'it', 'matter'],\n",
       " ['you', 'think', 'this', 'will', 'work'],\n",
       " ['what', 'would', 'he', 'say'],\n",
       " ['you',\n",
       "  'went',\n",
       "  'to',\n",
       "  'the',\n",
       "  'party',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'we',\n",
       "  'were',\n",
       "  'officially',\n",
       "  'opposed',\n",
       "  'to',\n",
       "  '<UNK>',\n",
       "  'social',\n",
       "  'activity'],\n",
       " ['i', 'did', 'not', 'have', 'a', 'choice'],\n",
       " ['you',\n",
       "  'did',\n",
       "  'not',\n",
       "  'have',\n",
       "  'a',\n",
       "  'choice',\n",
       "  'where',\n",
       "  'kat',\n",
       "  'and',\n",
       "  'what',\n",
       "  'have',\n",
       "  'you',\n",
       "  'done',\n",
       "  'with',\n",
       "  'her'],\n",
       " ['i', 'did', 'bianca', 'a', 'favor', 'and', 'it', '<UNK>'],\n",
       " ['you', 'did', 'not'],\n",
       " ['can',\n",
       "  'you',\n",
       "  'even',\n",
       "  'imagine',\n",
       "  'who',\n",
       "  'the',\n",
       "  'hell',\n",
       "  'would',\n",
       "  'go',\n",
       "  'to',\n",
       "  'this',\n",
       "  'a',\n",
       "  '<UNK>',\n",
       "  'of',\n",
       "  'commercial',\n",
       "  '<UNK>'],\n",
       " ['well',\n",
       "  'i',\n",
       "  'guess',\n",
       "  'we',\n",
       "  'are',\n",
       "  'not',\n",
       "  'since',\n",
       "  'we',\n",
       "  'do',\n",
       "  'not',\n",
       "  'have',\n",
       "  'dates'],\n",
       " ['listen',\n",
       "  'to',\n",
       "  'you',\n",
       "  'you',\n",
       "  'sound',\n",
       "  'like',\n",
       "  'betty',\n",
       "  'all',\n",
       "  'pissed',\n",
       "  'off',\n",
       "  'because',\n",
       "  'archie',\n",
       "  'is',\n",
       "  'taking',\n",
       "  'veronica'],\n",
       " ['okay',\n",
       "  'okay',\n",
       "  'we',\n",
       "  'wo',\n",
       "  'not',\n",
       "  'go',\n",
       "  'it',\n",
       "  'not',\n",
       "  'like',\n",
       "  'i',\n",
       "  'have',\n",
       "  'a',\n",
       "  'dress',\n",
       "  'anyway'],\n",
       " ['you',\n",
       "  're',\n",
       "  'looking',\n",
       "  'at',\n",
       "  'this',\n",
       "  'from',\n",
       "  'the',\n",
       "  'wrong',\n",
       "  'perspective',\n",
       "  'we',\n",
       "  'are',\n",
       "  'making',\n",
       "  'a',\n",
       "  'statement'],\n",
       " ['have', 'you', 'seen', 'him'],\n",
       " ['who'],\n",
       " ['william', 'he', 'asked', 'me', 'to', 'meet', 'him', 'here'],\n",
       " ['i', 'mean', 'woman', 'how', 'ya', 'doin'],\n",
       " ['sweating', 'like', 'a', 'pig', 'actually', 'and', 'yourself'],\n",
       " ['there', 'a', 'way', 'to', 'get', 'a', 'guy', 'attention'],\n",
       " ['pick', 'you', 'up', 'friday', 'then'],\n",
       " ['the',\n",
       "  'night',\n",
       "  'i',\n",
       "  'take',\n",
       "  'you',\n",
       "  'to',\n",
       "  'places',\n",
       "  'you',\n",
       "  'have',\n",
       "  'never',\n",
       "  'been',\n",
       "  'before',\n",
       "  'and',\n",
       "  'back'],\n",
       " ['like',\n",
       "  'where',\n",
       "  'the',\n",
       "  'on',\n",
       "  '<UNK>',\n",
       "  'do',\n",
       "  'you',\n",
       "  'even',\n",
       "  'know',\n",
       "  'my',\n",
       "  'name',\n",
       "  '<UNK>'],\n",
       " ['you', 'hate', 'me', 'do', 'not', 'you'],\n",
       " ['i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'really',\n",
       "  'think',\n",
       "  'you',\n",
       "  'warrant',\n",
       "  'that',\n",
       "  'strong',\n",
       "  'an',\n",
       "  'emotion'],\n",
       " ['then',\n",
       "  'say',\n",
       "  'you',\n",
       "  'will',\n",
       "  'spend',\n",
       "  'dollar',\n",
       "  'night',\n",
       "  'at',\n",
       "  'the',\n",
       "  'track',\n",
       "  'with',\n",
       "  'me'],\n",
       " ['and', 'why', 'would', 'i', 'do', 'that'],\n",
       " ['come',\n",
       "  'on',\n",
       "  'the',\n",
       "  'ponies',\n",
       "  'the',\n",
       "  'flat',\n",
       "  'beer',\n",
       "  'you',\n",
       "  'with',\n",
       "  'money',\n",
       "  'in',\n",
       "  'your',\n",
       "  'eyes',\n",
       "  'me',\n",
       "  'with',\n",
       "  'my',\n",
       "  'hand',\n",
       "  'on',\n",
       "  'your',\n",
       "  'ass'],\n",
       " ['you', 'covered', 'in', 'my', 'vomit'],\n",
       " ['are', 'you', 'following', 'me'],\n",
       " ['i',\n",
       "  'was',\n",
       "  'in',\n",
       "  'the',\n",
       "  '<UNK>',\n",
       "  'i',\n",
       "  'saw',\n",
       "  'your',\n",
       "  'car',\n",
       "  'thought',\n",
       "  'i',\n",
       "  'would',\n",
       "  'say',\n",
       "  'hi'],\n",
       " ['you', 'are', 'not', 'a', 'big', '<UNK>', 'are', 'you'],\n",
       " ['hey', 'great', 'show', 'huh'],\n",
       " ['excuse', 'me'],\n",
       " ['that', 'what', 'you', 'want', 'is', 'not', 'it'],\n",
       " ['you',\n",
       "  'know',\n",
       "  'these',\n",
       "  'guys',\n",
       "  'are',\n",
       "  'no',\n",
       "  '<UNK>',\n",
       "  'kill',\n",
       "  'or',\n",
       "  'the',\n",
       "  '<UNK>',\n",
       "  'but',\n",
       "  'they',\n",
       "  'are',\n",
       "  'right',\n",
       "  'up',\n",
       "  'there'],\n",
       " ['you', 'know', 'who', 'the', '<UNK>', 'are'],\n",
       " ['what', 'this'],\n",
       " ['i',\n",
       "  'getting',\n",
       "  '<UNK>',\n",
       "  'man',\n",
       "  'is',\n",
       "  'not',\n",
       "  'that',\n",
       "  'what',\n",
       "  'you',\n",
       "  'are',\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'do',\n",
       "  'at',\n",
       "  'a',\n",
       "  'party'],\n",
       " ['i', 'say', 'do', 'what', 'you', 'wan', 'na', 'do'],\n",
       " ['okay'],\n",
       " ['you', 'are', 'not', 'okay'],\n",
       " ['i', 'just', 'need', 'to', 'lie', 'down', 'for', 'awhile'],\n",
       " ['uh', 'uh', 'you', 'lie', 'down', 'and', 'you', 'will', 'go', 'to', 'sleep'],\n",
       " ['i', 'know', 'just', 'let', 'me', 'sleep'],\n",
       " ['this', 'is', 'so', '<UNK>'],\n",
       " ['leave',\n",
       "  'it',\n",
       "  'to',\n",
       "  'you',\n",
       "  'to',\n",
       "  'use',\n",
       "  'big',\n",
       "  'words',\n",
       "  'when',\n",
       "  'you',\n",
       "  'are',\n",
       "  '<UNK>'],\n",
       " ['why', 'are', 'you', 'doing', 'this'],\n",
       " ['i', 'told', 'you'],\n",
       " ['you', 'do', 'not', 'care', 'if', 'i', 'die'],\n",
       " ['sure', 'i', 'do'],\n",
       " ['why'],\n",
       " ['because',\n",
       "  'then',\n",
       "  'i',\n",
       "  'would',\n",
       "  'have',\n",
       "  'to',\n",
       "  'start',\n",
       "  'taking',\n",
       "  'out',\n",
       "  'girls',\n",
       "  'who',\n",
       "  'like',\n",
       "  'me'],\n",
       " ['like', 'you', 'could', 'find', 'one'],\n",
       " ['see',\n",
       "  'that',\n",
       "  'who',\n",
       "  'needs',\n",
       "  'affection',\n",
       "  'when',\n",
       "  'i',\n",
       "  'have',\n",
       "  'got',\n",
       "  'blind',\n",
       "  'hatred'],\n",
       " ['why', 'would', 'you', 'let', 'him', 'get', 'to', 'you'],\n",
       " ['who'],\n",
       " ['<UNK>'],\n",
       " ['i', 'hate', 'him'],\n",
       " ['i',\n",
       "  'know',\n",
       "  'it',\n",
       "  'would',\n",
       "  'have',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'pretty',\n",
       "  'big',\n",
       "  'deal',\n",
       "  'to',\n",
       "  'get',\n",
       "  'you',\n",
       "  'to',\n",
       "  '<UNK>',\n",
       "  'tequila',\n",
       "  'you',\n",
       "  'do',\n",
       "  'not',\n",
       "  'seem',\n",
       "  'like',\n",
       "  'the',\n",
       "  'type'],\n",
       " ['hey',\n",
       "  'man',\n",
       "  'you',\n",
       "  'don',\n",
       "  't',\n",
       "  'think',\n",
       "  'i',\n",
       "  'can',\n",
       "  'be',\n",
       "  'cool',\n",
       "  'you',\n",
       "  'do',\n",
       "  'not',\n",
       "  'think',\n",
       "  'i',\n",
       "  'can',\n",
       "  'be',\n",
       "  'laid',\n",
       "  'back',\n",
       "  'like',\n",
       "  'everyone',\n",
       "  'else'],\n",
       " ['i', 'thought', 'you', 'were', 'above', 'all', 'that'],\n",
       " ['kat', 'wake', 'up'],\n",
       " ['and', 'i', 'in', 'control', 'of', 'it'],\n",
       " ['when', 'you', 'were', 'gone', 'last', 'year', 'where', 'were', 'you'],\n",
       " ['busy'],\n",
       " ['were', 'you', 'in', 'jail'],\n",
       " ['maybe'],\n",
       " ['no', 'you', 'were', 'not'],\n",
       " ['then', 'why', 'would', 'you', 'ask'],\n",
       " ['i', 'should', 'do', 'this'],\n",
       " ['do', 'what'],\n",
       " ['start', 'a', 'band'],\n",
       " ['my', 'father', 'would', 'not', 'approve', 'of', 'that', 'that'],\n",
       " ['oh', 'so', 'now', 'you', 'think', 'you', 'know', 'me'],\n",
       " ['so',\n",
       "  'what',\n",
       "  's',\n",
       "  'up',\n",
       "  'with',\n",
       "  'your',\n",
       "  'dad',\n",
       "  'he',\n",
       "  'a',\n",
       "  'pain',\n",
       "  'in',\n",
       "  'the',\n",
       "  'ass'],\n",
       " ['he', 'just', 'wants', 'me', 'to', 'be', 'someone', 'i', 'not'],\n",
       " ['who'],\n",
       " ['bianca'],\n",
       " ['excuse',\n",
       "  'me',\n",
       "  'have',\n",
       "  'you',\n",
       "  'seen',\n",
       "  'the',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  'i',\n",
       "  'lost',\n",
       "  'my',\n",
       "  'copy'],\n",
       " ['what', 'are', 'you', 'doing', 'here'],\n",
       " ['i', 'heard', 'there', 'was', 'a', 'poetry', 'reading'],\n",
       " ['you', 'are', 'so'],\n",
       " ['<UNK>'],\n",
       " ['<UNK>'],\n",
       " ['<UNK>',\n",
       "  'i',\n",
       "  'guess',\n",
       "  'someone',\n",
       "  'still',\n",
       "  'has',\n",
       "  'her',\n",
       "  'panties',\n",
       "  'in',\n",
       "  'a',\n",
       "  'twist'],\n",
       " ['do',\n",
       "  'not',\n",
       "  'for',\n",
       "  'one',\n",
       "  'minute',\n",
       "  'think',\n",
       "  'that',\n",
       "  'you',\n",
       "  'had',\n",
       "  'any',\n",
       "  'effect',\n",
       "  'whatsoever',\n",
       "  'on',\n",
       "  'my',\n",
       "  'panties'],\n",
       " ['so', 'what', 'did', 'i', 'have', 'an', 'effect', 'on'],\n",
       " ['he',\n",
       "  'left',\n",
       "  'i',\n",
       "  '<UNK>',\n",
       "  'the',\n",
       "  'dickhead',\n",
       "  'and',\n",
       "  'he',\n",
       "  '<UNK>',\n",
       "  'on',\n",
       "  'me'],\n",
       " ['i', 'guess', 'i', 'never', 'told', 'you', 'i', 'afraid', 'of', 'heights'],\n",
       " [\"c'mon\", 'it', 'not', 'that', 'bad'],\n",
       " ['put', 'your', 'right', 'foot', 'there'],\n",
       " ['forget', 'it', 'i', 'stayin'],\n",
       " ['you',\n",
       "  'want',\n",
       "  'me',\n",
       "  'to',\n",
       "  'climb',\n",
       "  'up',\n",
       "  'and',\n",
       "  'show',\n",
       "  'you',\n",
       "  'how',\n",
       "  'to',\n",
       "  'get',\n",
       "  'down'],\n",
       " ['the', '<UNK>', 'family'],\n",
       " ['i',\n",
       "  'figured',\n",
       "  'it',\n",
       "  'had',\n",
       "  'to',\n",
       "  'be',\n",
       "  'something',\n",
       "  'ridiculous',\n",
       "  'to',\n",
       "  'win',\n",
       "  'your',\n",
       "  'respect',\n",
       "  'and',\n",
       "  'piss',\n",
       "  'you',\n",
       "  'off'],\n",
       " ['good', 'call'],\n",
       " ['so',\n",
       "  'how',\n",
       "  'would',\n",
       "  'you',\n",
       "  'get',\n",
       "  '<UNK>',\n",
       "  'to',\n",
       "  'look',\n",
       "  'the',\n",
       "  'other',\n",
       "  'way'],\n",
       " ['a', 'soft', 'side', 'who', 'knew'],\n",
       " ['yeah', 'well', 'do', 'not', 'let', 'it', 'get', 'out'],\n",
       " ['so', 'what', 'your', 'excuse'],\n",
       " ['acting', 'the', 'way', 'we', 'do'],\n",
       " ['yes'],\n",
       " ['i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'like',\n",
       "  'to',\n",
       "  'do',\n",
       "  'what',\n",
       "  'people',\n",
       "  'expect',\n",
       "  'then',\n",
       "  'they',\n",
       "  'expect',\n",
       "  'it',\n",
       "  'all',\n",
       "  'the',\n",
       "  'time',\n",
       "  'and',\n",
       "  'they',\n",
       "  'get',\n",
       "  'disappointed',\n",
       "  'when',\n",
       "  'you',\n",
       "  'change'],\n",
       " ['so',\n",
       "  'if',\n",
       "  'you',\n",
       "  'disappoint',\n",
       "  'them',\n",
       "  'from',\n",
       "  'the',\n",
       "  'start',\n",
       "  'you',\n",
       "  'are',\n",
       "  'covered'],\n",
       " ['something', 'like', 'that'],\n",
       " ['then', 'you', 'screwed', 'up'],\n",
       " ['how'],\n",
       " ['you', 'up', 'for', 'it'],\n",
       " ['state', '<UNK>'],\n",
       " ['<UNK>'],\n",
       " ['the', 'duck'],\n",
       " ['<UNK>'],\n",
       " ['tell', 'me', 'something', 'true'],\n",
       " ['i', 'hate', '<UNK>'],\n",
       " ['no', 'something', 'real', 'something', 'no', 'one', 'else', 'knows'],\n",
       " ['you',\n",
       "  'are',\n",
       "  'sweet',\n",
       "  'and',\n",
       "  'sexy',\n",
       "  'and',\n",
       "  'completely',\n",
       "  'hot',\n",
       "  'for',\n",
       "  'me'],\n",
       " ['what'],\n",
       " ['no', 'one', 'else', 'knows'],\n",
       " ['you',\n",
       "  'are',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  'has',\n",
       "  'anyone',\n",
       "  'ever',\n",
       "  'told',\n",
       "  'you',\n",
       "  'that'],\n",
       " ['is', 'that', 'a', 'request', 'or', 'a', 'command'],\n",
       " ['you', 'know', 'what', 'i', 'mean'],\n",
       " ['no'],\n",
       " ['no', 'what'],\n",
       " ['no', 'i', 'wo', 'not', 'go', 'with', 'you'],\n",
       " ['why', 'not'],\n",
       " ['create', 'a', 'little', 'drama', 'start', 'a', 'new', 'rumor', 'what'],\n",
       " ['so', 'i', 'have', 'to', 'have', 'a', 'motive', 'to', 'be', 'with', 'you'],\n",
       " ['you', 'tell', 'me'],\n",
       " ['you', 'need', 'therapy', 'has', 'anyone', 'ever', 'told', 'you', 'that'],\n",
       " ['answer', 'the', 'question', 'patrick'],\n",
       " ['how', 'would', 'you', 'get', 'a', '<UNK>', 'at', 'the', 'last', 'minute'],\n",
       " ['it',\n",
       "  '<UNK>',\n",
       "  'his',\n",
       "  'date',\n",
       "  'got',\n",
       "  'convicted',\n",
       "  'where',\n",
       "  'would',\n",
       "  'you',\n",
       "  'get',\n",
       "  'the',\n",
       "  'dress'],\n",
       " ['it', 'just', 'something', 'i', 'had', 'you', 'know'],\n",
       " ['oh', 'huh'],\n",
       " ['my', 'grandmother'],\n",
       " ['that', 's', 'completely', 'adorable'],\n",
       " ['wait', 'i'],\n",
       " ['you',\n",
       "  'were',\n",
       "  'paid',\n",
       "  'to',\n",
       "  'take',\n",
       "  'me',\n",
       "  'out',\n",
       "  'by',\n",
       "  'the',\n",
       "  'one',\n",
       "  'person',\n",
       "  'i',\n",
       "  'truly',\n",
       "  'hate',\n",
       "  'i',\n",
       "  'knew',\n",
       "  'it',\n",
       "  'was',\n",
       "  'a',\n",
       "  'setup'],\n",
       " ['it', 'was', 'not', 'like', 'that'],\n",
       " ['really',\n",
       "  'what',\n",
       "  'was',\n",
       "  'it',\n",
       "  'like',\n",
       "  'a',\n",
       "  'down',\n",
       "  'payment',\n",
       "  'now',\n",
       "  'then',\n",
       "  'a',\n",
       "  'bonus',\n",
       "  'for',\n",
       "  'sleeping',\n",
       "  'with',\n",
       "  'me'],\n",
       " ['a', '<UNK>', '<UNK>', 'you', 'bought', 'this'],\n",
       " ['besides',\n",
       "  'i',\n",
       "  'had',\n",
       "  'some',\n",
       "  'extra',\n",
       "  'cash',\n",
       "  'some',\n",
       "  'asshole',\n",
       "  'paid',\n",
       "  'me',\n",
       "  'to',\n",
       "  'take',\n",
       "  'out',\n",
       "  'a',\n",
       "  'really',\n",
       "  'great',\n",
       "  'girl'],\n",
       " ['is', 'that', 'right'],\n",
       " ['why',\n",
       "  'is',\n",
       "  'my',\n",
       "  '<UNK>',\n",
       "  'burger',\n",
       "  'the',\n",
       "  'only',\n",
       "  'burnt',\n",
       "  'object',\n",
       "  'on',\n",
       "  'this',\n",
       "  '<UNK>'],\n",
       " ['because', 'i', 'like', 'to', 'torture', 'you'],\n",
       " ['oh', 'bianca', 'can', 'you', 'get', 'me', 'my', '<UNK>', '<UNK>'],\n",
       " ['i', 'know'],\n",
       " ['i',\n",
       "  'thought',\n",
       "  'we',\n",
       "  'decided',\n",
       "  'you',\n",
       "  'were',\n",
       "  'going',\n",
       "  'to',\n",
       "  'school',\n",
       "  'here',\n",
       "  'at',\n",
       "  'u',\n",
       "  'of'],\n",
       " ['this',\n",
       "  'from',\n",
       "  'someone',\n",
       "  'whose',\n",
       "  'diary',\n",
       "  'is',\n",
       "  '<UNK>',\n",
       "  'to',\n",
       "  'favorite',\n",
       "  '<UNK>',\n",
       "  'tips'],\n",
       " ['my', 'insurance', 'does', 'not', 'cover', 'pms'],\n",
       " ['then', 'tell', 'them', 'i', 'had', 'a', '<UNK>'],\n",
       " ['is', 'this', 'about', 'sarah', 'lawrence', 'you', '<UNK>', 'me'],\n",
       " ['i', 'thought', 'you', 'were', '<UNK>', 'me'],\n",
       " ['why', 'ca', 'not', 'we', 'agree', 'on', 'this'],\n",
       " ['because', 'you', 'are', 'making', 'decisions', 'for', 'me'],\n",
       " ['as', 'a', 'parent', 'that', 'my', 'right'],\n",
       " ['so', 'what', 'i', 'want', 'does', 'not', 'matter'],\n",
       " ['you',\n",
       "  'are',\n",
       "  'eighteen',\n",
       "  'you',\n",
       "  'do',\n",
       "  'not',\n",
       "  'know',\n",
       "  'what',\n",
       "  'you',\n",
       "  'want',\n",
       "  'you',\n",
       "  'wo',\n",
       "  'not',\n",
       "  'know',\n",
       "  'until',\n",
       "  'you',\n",
       "  'are',\n",
       "  'fortyfive',\n",
       "  'and',\n",
       "  'you',\n",
       "  'do',\n",
       "  'not',\n",
       "  'have',\n",
       "  'it'],\n",
       " ['was', 'that', 'your', 'sister'],\n",
       " ['yeah',\n",
       "  'she',\n",
       "  'left',\n",
       "  'with',\n",
       "  'some',\n",
       "  '<UNK>',\n",
       "  'big',\n",
       "  'ones',\n",
       "  'full',\n",
       "  'of',\n",
       "  '<UNK>'],\n",
       " ['i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'understand',\n",
       "  'the',\n",
       "  '<UNK>',\n",
       "  'of',\n",
       "  '<UNK>',\n",
       "  'food',\n",
       "  'is',\n",
       "  'this',\n",
       "  'something',\n",
       "  'i',\n",
       "  'should',\n",
       "  'be',\n",
       "  'hip',\n",
       "  'to'],\n",
       " ['no', 'daddy'],\n",
       " ['so', 'tell', 'me', 'about', 'this', 'dance', 'was', 'it', 'fun'],\n",
       " ['parts', 'of', 'it'],\n",
       " ['which', 'parts'],\n",
       " ['the',\n",
       "  'part',\n",
       "  'where',\n",
       "  'bianca',\n",
       "  'beat',\n",
       "  'the',\n",
       "  'hell',\n",
       "  'out',\n",
       "  'of',\n",
       "  'some',\n",
       "  'guy'],\n",
       " ['bianca', 'did', 'what'],\n",
       " ['what', 'the', 'matter', 'upset', 'that', 'i', '<UNK>', 'off', 'on', 'her'],\n",
       " ['when', 'i', 'go'],\n",
       " ['<UNK>',\n",
       "  '<UNK>',\n",
       "  'my',\n",
       "  'my',\n",
       "  'you',\n",
       "  'have',\n",
       "  'been',\n",
       "  '<UNK>',\n",
       "  'ms',\n",
       "  '<UNK>',\n",
       "  'again'],\n",
       " ['i',\n",
       "  'still',\n",
       "  'maintain',\n",
       "  'that',\n",
       "  'he',\n",
       "  'kicked',\n",
       "  'himself',\n",
       "  'in',\n",
       "  'the',\n",
       "  'balls',\n",
       "  'i',\n",
       "  'was',\n",
       "  'merely',\n",
       "  'a',\n",
       "  '<UNK>'],\n",
       " ['<UNK>'],\n",
       " ['am',\n",
       "  'i',\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'feel',\n",
       "  'better',\n",
       "  'like',\n",
       "  'right',\n",
       "  'now',\n",
       "  'or',\n",
       "  'do',\n",
       "  'i',\n",
       "  'have',\n",
       "  'some',\n",
       "  'time',\n",
       "  'to',\n",
       "  'think',\n",
       "  'about',\n",
       "  'it'],\n",
       " ['hey', 'there', 'tired', 'of', 'breathing'],\n",
       " ['hi'],\n",
       " ['cool', 'pictures', 'you', 'a', 'fan'],\n",
       " ['you', 'think'],\n",
       " ['<UNK>', 'right'],\n",
       " ['right'],\n",
       " ['kat', 'a', 'fan', 'too'],\n",
       " ['say', 'it'],\n",
       " ['what'],\n",
       " ['what', 'plan'],\n",
       " ['the',\n",
       "  'situation',\n",
       "  'is',\n",
       "  'my',\n",
       "  'man',\n",
       "  'cameron',\n",
       "  'here',\n",
       "  'has',\n",
       "  'a',\n",
       "  'major',\n",
       "  'jones',\n",
       "  'for',\n",
       "  'bianca',\n",
       "  '<UNK>'],\n",
       " ['i',\n",
       "  'think',\n",
       "  'i',\n",
       "  'speak',\n",
       "  '<UNK>',\n",
       "  'when',\n",
       "  'i',\n",
       "  'say',\n",
       "  'that',\n",
       "  'cameron',\n",
       "  'love',\n",
       "  'is',\n",
       "  'pure',\n",
       "  '<UNK>',\n",
       "  'than',\n",
       "  'say',\n",
       "  'joey',\n",
       "  '<UNK>'],\n",
       " ['that', 'where', 'we', 'can', 'help', 'you', 'with', 'kat'],\n",
       " ['so', '<UNK>', 'can', 'get', 'the', 'girl'],\n",
       " ['you',\n",
       "  'two',\n",
       "  'are',\n",
       "  'gon',\n",
       "  'na',\n",
       "  'help',\n",
       "  'me',\n",
       "  '<UNK>',\n",
       "  'the',\n",
       "  'wild',\n",
       "  'beast'],\n",
       " ['what'],\n",
       " ['are', 'you', 'telling', 'me', 'i', 'a', '<UNK>'],\n",
       " ['ever', 'been', 'to', 'club', '<UNK>'],\n",
       " ['i',\n",
       "  'prefer',\n",
       "  'to',\n",
       "  'think',\n",
       "  'of',\n",
       "  'it',\n",
       "  'simply',\n",
       "  'as',\n",
       "  'an',\n",
       "  'alternative',\n",
       "  'to',\n",
       "  'what',\n",
       "  'the',\n",
       "  'law',\n",
       "  'allows'],\n",
       " ['so', 'you', 'got', 'cozy', 'with', 'she', 'who', '<UNK>'],\n",
       " ['you', 'were', 'right', 'she', 'still', 'pissed'],\n",
       " ['sweet', 'love', '<UNK>', 'thy', 'force'],\n",
       " ['i', 'missed', 'you'],\n",
       " ['it',\n",
       "  'says',\n",
       "  'here',\n",
       "  'you',\n",
       "  'exposed',\n",
       "  'yourself',\n",
       "  'to',\n",
       "  'a',\n",
       "  'group',\n",
       "  'of',\n",
       "  '<UNK>',\n",
       "  'girls'],\n",
       " ['it', 'was', 'a', '<UNK>', 'i', 'was', 'eating', 'lunch'],\n",
       " ['i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'understand',\n",
       "  'patrick',\n",
       "  'you',\n",
       "  'have',\n",
       "  'not',\n",
       "  'done',\n",
       "  'anything',\n",
       "  '<UNK>',\n",
       "  'this',\n",
       "  'week',\n",
       "  'are',\n",
       "  'you',\n",
       "  'not',\n",
       "  'feeling',\n",
       "  'well'],\n",
       " ['touch', 'of', 'the', 'flu'],\n",
       " ['why',\n",
       "  'do',\n",
       "  'not',\n",
       "  'we',\n",
       "  'discuss',\n",
       "  'your',\n",
       "  'driving',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  '<UNK>'],\n",
       " ['what', 'to', 'discuss'],\n",
       " ['you',\n",
       "  'were',\n",
       "  'not',\n",
       "  '<UNK>',\n",
       "  'you',\n",
       "  'are',\n",
       "  'not',\n",
       "  'stupid',\n",
       "  'and',\n",
       "  'as',\n",
       "  'far',\n",
       "  'as',\n",
       "  'i',\n",
       "  'can',\n",
       "  'tell',\n",
       "  'you',\n",
       "  'are',\n",
       "  'only',\n",
       "  'slightly',\n",
       "  'psychotic',\n",
       "  'so',\n",
       "  'why',\n",
       "  'is',\n",
       "  'it',\n",
       "  'that',\n",
       "  'you',\n",
       "  'are',\n",
       "  'such',\n",
       "  'a',\n",
       "  '<UNK>'],\n",
       " ['you', 'are', 'completely', '<UNK>'],\n",
       " ['in', 'the', 'microwave'],\n",
       " ['what', 'a', '<UNK>', 'for', '<UNK>'],\n",
       " ['jesus',\n",
       "  'can',\n",
       "  'a',\n",
       "  'man',\n",
       "  'even',\n",
       "  'grab',\n",
       "  'a',\n",
       "  'sandwich',\n",
       "  'before',\n",
       "  'you',\n",
       "  'women',\n",
       "  'start',\n",
       "  '<UNK>'],\n",
       " ['<UNK>'],\n",
       " ['would',\n",
       "  'you',\n",
       "  'rather',\n",
       "  'be',\n",
       "  '<UNK>',\n",
       "  'by',\n",
       "  'a',\n",
       "  'pirate',\n",
       "  'or',\n",
       "  'a',\n",
       "  'british',\n",
       "  'rear',\n",
       "  'admiral'],\n",
       " ['they',\n",
       "  'will',\n",
       "  'dance',\n",
       "  'they',\n",
       "  'will',\n",
       "  'kiss',\n",
       "  'they',\n",
       "  'will',\n",
       "  'come',\n",
       "  'home',\n",
       "  'let',\n",
       "  'her',\n",
       "  'go'],\n",
       " ['what',\n",
       "  'do',\n",
       "  'you',\n",
       "  'wan',\n",
       "  'na',\n",
       "  'watch',\n",
       "  'we',\n",
       "  'have',\n",
       "  'got',\n",
       "  'crap',\n",
       "  'crap',\n",
       "  'crap',\n",
       "  'or',\n",
       "  'crap'],\n",
       " ['have', 'a', 'great', 'time', 'honey'],\n",
       " ['what', 'just', 'happened'],\n",
       " ['your', 'daughters', 'went', 'to', 'the', 'prom'],\n",
       " ['did', 'i', 'have', 'anything', 'to', 'say', 'about', 'it'],\n",
       " ['absolutely', 'not'],\n",
       " ['i',\n",
       "  'never',\n",
       "  'seen',\n",
       "  'heat',\n",
       "  'like',\n",
       "  'this',\n",
       "  'not',\n",
       "  'even',\n",
       "  'in',\n",
       "  'las',\n",
       "  '<UNK>'],\n",
       " ['the', 'water', 'going', '<UNK>', 'in', 'the', 'barrels'],\n",
       " ['what', 'are', 'you', 'listening', 'to', 'chicken', 'ass'],\n",
       " ['ah', 'leave', 'him', 'alone', 'he', 'doing', 'no', 'harm'],\n",
       " ['he', 'the', 'devil', 'child'],\n",
       " ['we', 'should', 'have', 'seen', 'land'],\n",
       " ['we',\n",
       "  'left',\n",
       "  'three',\n",
       "  'weeks',\n",
       "  'ago',\n",
       "  '<UNK>',\n",
       "  'ca',\n",
       "  'not',\n",
       "  'be',\n",
       "  'that',\n",
       "  'near'],\n",
       " ['you', 'say', 'asia', 'can', 'be', 'found', 'by', 'sailing', 'west'],\n",
       " ['yes',\n",
       "  'your',\n",
       "  '<UNK>',\n",
       "  'the',\n",
       "  'voyage',\n",
       "  'should',\n",
       "  'not',\n",
       "  'take',\n",
       "  'more',\n",
       "  'than',\n",
       "  'six',\n",
       "  'or',\n",
       "  'seven',\n",
       "  'weeks'],\n",
       " ['unfortunately',\n",
       "  'don',\n",
       "  'colon',\n",
       "  'that',\n",
       "  'is',\n",
       "  'precisely',\n",
       "  'where',\n",
       "  'our',\n",
       "  'opinions',\n",
       "  '<UNK>',\n",
       "  'are',\n",
       "  'you',\n",
       "  'familiar',\n",
       "  'with',\n",
       "  'the',\n",
       "  'work',\n",
       "  'of',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  '<UNK>'],\n",
       " ['i', 'am', 'your', '<UNK>'],\n",
       " ['your',\n",
       "  '<UNK>',\n",
       "  'there',\n",
       "  'is',\n",
       "  'only',\n",
       "  'one',\n",
       "  'way',\n",
       "  'to',\n",
       "  'settle',\n",
       "  'the',\n",
       "  'matter',\n",
       "  'and',\n",
       "  'that',\n",
       "  'is',\n",
       "  'to',\n",
       "  'make',\n",
       "  'the',\n",
       "  'journey',\n",
       "  'i',\n",
       "  'am',\n",
       "  'ready',\n",
       "  'to',\n",
       "  'risk',\n",
       "  'my',\n",
       "  'life',\n",
       "  'to',\n",
       "  'prove',\n",
       "  'it',\n",
       "  'possible'],\n",
       " ['your', 'life', 'and', 'that', 'of', 'others'],\n",
       " ['trade',\n",
       "  'your',\n",
       "  'excellency',\n",
       "  'according',\n",
       "  'to',\n",
       "  '<UNK>',\n",
       "  'polo',\n",
       "  'the',\n",
       "  'kingdom',\n",
       "  'of',\n",
       "  'china',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  '<UNK>',\n",
       "  'of',\n",
       "  'the',\n",
       "  'world',\n",
       "  'even',\n",
       "  'the',\n",
       "  '<UNK>',\n",
       "  'buildings',\n",
       "  'are',\n",
       "  '<UNK>',\n",
       "  'with',\n",
       "  'gold'],\n",
       " ['is', 'that', 'all', 'that', 'interests', 'you', 'gold'],\n",
       " ['if',\n",
       "  'god',\n",
       "  'intended',\n",
       "  'our',\n",
       "  '<UNK>',\n",
       "  'to',\n",
       "  'asia',\n",
       "  'do',\n",
       "  'you',\n",
       "  'believe',\n",
       "  'he',\n",
       "  'would',\n",
       "  'have',\n",
       "  'waited',\n",
       "  'for',\n",
       "  'you',\n",
       "  'to',\n",
       "  'show',\n",
       "  'it',\n",
       "  'to',\n",
       "  'the',\n",
       "  'world'],\n",
       " ['do',\n",
       "  'not',\n",
       "  'you',\n",
       "  'realize',\n",
       "  'your',\n",
       "  'words',\n",
       "  'could',\n",
       "  'be',\n",
       "  'considered',\n",
       "  '<UNK>'],\n",
       " ['asia',\n",
       "  'can',\n",
       "  'be',\n",
       "  'found',\n",
       "  'to',\n",
       "  'the',\n",
       "  'west',\n",
       "  'and',\n",
       "  'i',\n",
       "  'will',\n",
       "  'prove',\n",
       "  'it'],\n",
       " ['the',\n",
       "  'state',\n",
       "  'has',\n",
       "  'some',\n",
       "  'reason',\n",
       "  'to',\n",
       "  'be',\n",
       "  'interested',\n",
       "  'in',\n",
       "  'this',\n",
       "  'man',\n",
       "  'proposition',\n",
       "  'your',\n",
       "  '<UNK>'],\n",
       " ['the', 'judgment', 'is', 'ours'],\n",
       " ['he',\n",
       "  'is',\n",
       "  'a',\n",
       "  '<UNK>',\n",
       "  'did',\n",
       "  'he',\n",
       "  'not',\n",
       "  'already',\n",
       "  'try',\n",
       "  'to',\n",
       "  'convince',\n",
       "  'the',\n",
       "  'king',\n",
       "  'of',\n",
       "  '<UNK>',\n",
       "  'of',\n",
       "  'his',\n",
       "  'absurd',\n",
       "  'notions'],\n",
       " ['it',\n",
       "  'wo',\n",
       "  'not',\n",
       "  'be',\n",
       "  'easy',\n",
       "  'to',\n",
       "  'get',\n",
       "  'rid',\n",
       "  'of',\n",
       "  'your',\n",
       "  '<UNK>',\n",
       "  'now',\n",
       "  'don',\n",
       "  'sanchez'],\n",
       " ['you', 'can', 'see', 'for', 'yourself'],\n",
       " ['what', 'a', 'tragedy', 'what', 'a', 'waste', 'of', 'a', 'life'],\n",
       " ['i', 'could', 'be', 'gone', 'for', 'years'],\n",
       " ['i', 'know'],\n",
       " ['i', 'have', 'not', 'given', 'you', 'much', 'of', 'a', 'life'],\n",
       " ['well',\n",
       "  'that',\n",
       "  'true',\n",
       "  'i',\n",
       "  'have',\n",
       "  'a',\n",
       "  'child',\n",
       "  'by',\n",
       "  'a',\n",
       "  'man',\n",
       "  'who',\n",
       "  'wo',\n",
       "  'not',\n",
       "  'marry',\n",
       "  'me',\n",
       "  'who',\n",
       "  'always',\n",
       "  'leaving'],\n",
       " ['are', 'we', 'going', 'to', 'argue'],\n",
       " ['perhaps', 'i', 'was', 'never', 'meant', 'to', 'live', 'with', 'a', 'woman'],\n",
       " ['she', 'said', 'yes'],\n",
       " ['i', 'not', 'asking', 'you', 'to', 'swear', 'to', 'anything'],\n",
       " ['i', 'do', 'not', 'want', 'you', 'to', 'wait', 'for', 'me'],\n",
       " ['<UNK>', 'i', 'want', 'to', 'ask', 'you', 'something'],\n",
       " ['you', 'do', 'not', 'usually', 'ask'],\n",
       " ['god',\n",
       "  'you',\n",
       "  'are',\n",
       "  'so',\n",
       "  'beautiful',\n",
       "  'i',\n",
       "  'ca',\n",
       "  'not',\n",
       "  'believe',\n",
       "  'no',\n",
       "  'other',\n",
       "  'man',\n",
       "  'has',\n",
       "  'ever',\n",
       "  'taken',\n",
       "  'you',\n",
       "  'away',\n",
       "  'from',\n",
       "  'me'],\n",
       " ['they', 'took', 'everything'],\n",
       " ['ca', 'not', 'you', 'stay', 'with', 'us', 'a', 'little'],\n",
       " ['what', 'is', 'it', 'now', 'tell', 'me'],\n",
       " ['i',\n",
       "  'understand',\n",
       "  'that',\n",
       "  'you',\n",
       "  'will',\n",
       "  'soon',\n",
       "  'be',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  'for',\n",
       "  'the',\n",
       "  'islands',\n",
       "  'is',\n",
       "  'it',\n",
       "  'not',\n",
       "  'so'],\n",
       " ['forgive',\n",
       "  'me',\n",
       "  'don',\n",
       "  '<UNK>',\n",
       "  'those',\n",
       "  'positions',\n",
       "  'have',\n",
       "  'already',\n",
       "  'been',\n",
       "  'taken'],\n",
       " ['may', 'i', 'ask', 'by', 'whom'],\n",
       " ['don', '<UNK>', 'de', '<UNK>'],\n",
       " ['my', 'letters', 'of', 'appointment'],\n",
       " ['appointment', 'to', 'what'],\n",
       " ['<UNK>', 'of', 'the', 'west', '<UNK>'],\n",
       " ['how', 'far', 'from', 'here'],\n",
       " ['i',\n",
       "  'am',\n",
       "  'not',\n",
       "  'a',\n",
       "  '<UNK>',\n",
       "  'but',\n",
       "  'i',\n",
       "  'heard',\n",
       "  'it',\n",
       "  'is',\n",
       "  'no',\n",
       "  'more',\n",
       "  'than',\n",
       "  'a',\n",
       "  'week',\n",
       "  'at',\n",
       "  'sea',\n",
       "  'i',\n",
       "  'hope',\n",
       "  'you',\n",
       "  'are',\n",
       "  'not',\n",
       "  'too',\n",
       "  'disappointed'],\n",
       " ['how',\n",
       "  'could',\n",
       "  'i',\n",
       "  'be',\n",
       "  'the',\n",
       "  'mainland',\n",
       "  'has',\n",
       "  'been',\n",
       "  'found',\n",
       "  'exactly',\n",
       "  'as',\n",
       "  'i',\n",
       "  'said',\n",
       "  'it',\n",
       "  'would'],\n",
       " ['i', 'want', 'to', 'go', 'with', 'you'],\n",
       " ['there', 'will', 'be', 'a', 'time'],\n",
       " ['do', 'you', 'swear', 'on', 'all', 'the', 'holy', 'saints', 'in', 'heaven'],\n",
       " ['i', 'have', 'to', 'explore', 'the', 'mainland'],\n",
       " ['how', 'are', 'you', 'feeling', '<UNK>'],\n",
       " ['father'],\n",
       " ['what', 'are', 'you', 'listening', 'to'],\n",
       " ['what', 'does', 'he', 'say'],\n",
       " ['he',\n",
       "  'asks',\n",
       "  'when',\n",
       "  'he',\n",
       "  'can',\n",
       "  'come',\n",
       "  'to',\n",
       "  'visit',\n",
       "  'you',\n",
       "  'he',\n",
       "  'left',\n",
       "  'his',\n",
       "  'address'],\n",
       " ['i',\n",
       "  'want',\n",
       "  'you',\n",
       "  'to',\n",
       "  'tell',\n",
       "  'me',\n",
       "  'everything',\n",
       "  'you',\n",
       "  'remember',\n",
       "  'father',\n",
       "  'from',\n",
       "  'the',\n",
       "  'beginning',\n",
       "  'everything'],\n",
       " ['really',\n",
       "  'god',\n",
       "  'i',\n",
       "  'would',\n",
       "  'not',\n",
       "  'know',\n",
       "  'where',\n",
       "  'to',\n",
       "  'start',\n",
       "  'and',\n",
       "  'yet'],\n",
       " ['no'],\n",
       " ['no'],\n",
       " ['i',\n",
       "  'remind',\n",
       "  'you',\n",
       "  '<UNK>',\n",
       "  'colon',\n",
       "  'that',\n",
       "  'you',\n",
       "  'are',\n",
       "  'in',\n",
       "  'no',\n",
       "  'position',\n",
       "  'to',\n",
       "  'bargain',\n",
       "  'with',\n",
       "  'me'],\n",
       " ['i', 'not', '<UNK>'],\n",
       " ['and',\n",
       "  'were',\n",
       "  'you',\n",
       "  'never',\n",
       "  'ambitious',\n",
       "  'excellency',\n",
       "  'or',\n",
       "  'is',\n",
       "  'ambition',\n",
       "  'only',\n",
       "  'a',\n",
       "  'virtue',\n",
       "  'among',\n",
       "  'the',\n",
       "  '<UNK>',\n",
       "  'a',\n",
       "  'fault',\n",
       "  'for',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'us'],\n",
       " ['they',\n",
       "  'do',\n",
       "  'not',\n",
       "  'see',\n",
       "  'sin',\n",
       "  'in',\n",
       "  'their',\n",
       "  '<UNK>',\n",
       "  'they',\n",
       "  'live',\n",
       "  'according',\n",
       "  'to',\n",
       "  'nature',\n",
       "  'in',\n",
       "  'a',\n",
       "  'never',\n",
       "  'ending',\n",
       "  'summer',\n",
       "  'the',\n",
       "  'islands',\n",
       "  'are',\n",
       "  'covered',\n",
       "  'with',\n",
       "  'trees',\n",
       "  'filled',\n",
       "  'with',\n",
       "  '<UNK>',\n",
       "  'and',\n",
       "  '<UNK>',\n",
       "  'and'],\n",
       " ['you', 'defend', 'yourself', '<UNK>'],\n",
       " ['but',\n",
       "  'we',\n",
       "  'do',\n",
       "  'have',\n",
       "  'a',\n",
       "  'lack',\n",
       "  'of',\n",
       "  '<UNK>',\n",
       "  'you',\n",
       "  'should',\n",
       "  'contact',\n",
       "  'my',\n",
       "  'administration'],\n",
       " ['don', '<UNK>', 'is', 'already', 'a', 'judge', 'my', 'dear', 'don', '<UNK>'],\n",
       " ['you',\n",
       "  'seem',\n",
       "  'to',\n",
       "  'have',\n",
       "  'a',\n",
       "  'special',\n",
       "  'talent',\n",
       "  'for',\n",
       "  'making',\n",
       "  'friends'],\n",
       " ['what', 'do', 'i', 'have', 'so', 'many', 'already'],\n",
       " ['all', 'i', 'have', 'to', 'do', 'is', 'call', 'the', 'guards'],\n",
       " ['i',\n",
       "  'am',\n",
       "  'not',\n",
       "  'afraid',\n",
       "  'of',\n",
       "  'you',\n",
       "  'you',\n",
       "  'are',\n",
       "  'nothing',\n",
       "  'but',\n",
       "  'a',\n",
       "  '<UNK>'],\n",
       " ['what', 'do', 'you', 'see'],\n",
       " ['<UNK>', 'towers', '<UNK>', '<UNK>'],\n",
       " ['say', 'not', 'here', 'cuba'],\n",
       " ['what', 'is', 'it', 'a', 'tribe', 'an', 'island'],\n",
       " ['you', 'come', 'you', 'speak', 'first'],\n",
       " ['tell', 'the', 'chief', 'we', 'thank', 'him'],\n",
       " ['chief', 'knows'],\n",
       " ['chief', 'says', 'how', 'many'],\n",
       " ['thousands'],\n",
       " ['to', 'bring', 'the', 'word', 'of', 'god'],\n",
       " ['chief', 'says', 'he', 'has', 'a', 'god'],\n",
       " ['and', 'also', 'to', 'bring', 'medicine'],\n",
       " ['chief', 'says'],\n",
       " ['we',\n",
       "  'will',\n",
       "  'work',\n",
       "  'with',\n",
       "  'his',\n",
       "  'people',\n",
       "  'we',\n",
       "  'want',\n",
       "  'peace',\n",
       "  'ask',\n",
       "  'the',\n",
       "  'chief',\n",
       "  'if',\n",
       "  'he',\n",
       "  'understands'],\n",
       " ['he', 'understands'],\n",
       " ['you', 'have', 'to', 'find', 'them', '<UNK>', 'look', 'what', 'they', 'did'],\n",
       " ['<UNK>',\n",
       "  'wo',\n",
       "  'not',\n",
       "  'you',\n",
       "  'speak',\n",
       "  'to',\n",
       "  'me',\n",
       "  'you',\n",
       "  'used',\n",
       "  'to',\n",
       "  'know',\n",
       "  'how',\n",
       "  'to',\n",
       "  'speak',\n",
       "  'to',\n",
       "  'me'],\n",
       " ['diego',\n",
       "  'is',\n",
       "  'a',\n",
       "  'bright',\n",
       "  'boy',\n",
       "  'a',\n",
       "  'pleasure',\n",
       "  'to',\n",
       "  'teach',\n",
       "  'but',\n",
       "  'so',\n",
       "  'serious',\n",
       "  'brothers',\n",
       "  'should',\n",
       "  'be',\n",
       "  'raised',\n",
       "  'together',\n",
       "  'colon',\n",
       "  'even',\n",
       "  'brothers',\n",
       "  'from',\n",
       "  'different',\n",
       "  'mothers'],\n",
       " ['god', 'that', 'in', 'a', 'week'],\n",
       " ['that', 'what', 'it', 'says'],\n",
       " ['how', 'did', 'you', 'manage', 'it'],\n",
       " ['why', 'do', 'you', 'wish', 'to', 'sail', 'west'],\n",
       " ['how',\n",
       "  'can',\n",
       "  'you',\n",
       "  'be',\n",
       "  'so',\n",
       "  'certain',\n",
       "  'the',\n",
       "  'ocean',\n",
       "  'is',\n",
       "  'said',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<UNK>'],\n",
       " ['ignorance',\n",
       "  'i',\n",
       "  'believe',\n",
       "  'the',\n",
       "  '<UNK>',\n",
       "  'are',\n",
       "  'no',\n",
       "  'more',\n",
       "  'than',\n",
       "  'leagues',\n",
       "  'west',\n",
       "  'of',\n",
       "  'the',\n",
       "  'canary',\n",
       "  'islands'],\n",
       " ['how', 'can', 'you', 'be', 'so', 'certain'],\n",
       " ['the', '<UNK>', 'of', '<UNK>', '<UNK>', 'de', '<UNK>', '<UNK>'],\n",
       " ['<UNK>', 'is', 'a', 'jew'],\n",
       " ['two',\n",
       "  'minutes',\n",
       "  'and',\n",
       "  'already',\n",
       "  'you',\n",
       "  'are',\n",
       "  'a',\n",
       "  'dead',\n",
       "  'man',\n",
       "  'do',\n",
       "  'not',\n",
       "  'let',\n",
       "  'passion',\n",
       "  '<UNK>',\n",
       "  'you',\n",
       "  'colon'],\n",
       " ['i', 'will', 'try', 'to', 'remember', 'that', '<UNK>'],\n",
       " ['father', '<UNK>'],\n",
       " ['passion', 'is', 'something', 'one', 'can', 'not', 'control'],\n",
       " ['you',\n",
       "  'get',\n",
       "  'so',\n",
       "  'carried',\n",
       "  'away',\n",
       "  'when',\n",
       "  'you',\n",
       "  'are',\n",
       "  'being',\n",
       "  '<UNK>'],\n",
       " ['i', 'have', 'been', '<UNK>', 'all', 'my', 'life', 'eternity'],\n",
       " ['you', 'must', 'not', 'give', 'way', 'to', 'despair', 'you', 'must', 'wait'],\n",
       " ['wait',\n",
       "  'i',\n",
       "  'have',\n",
       "  'waited',\n",
       "  'seven',\n",
       "  'years',\n",
       "  'already',\n",
       "  'how',\n",
       "  'much',\n",
       "  'longer',\n",
       "  'do',\n",
       "  'you',\n",
       "  'want',\n",
       "  'me',\n",
       "  'to',\n",
       "  'wait'],\n",
       " ['if', 'god', '<UNK>', 'you', 'to', 'go', 'then', 'you', 'will', 'go'],\n",
       " ['all', 'of', 'them', 'just', 'lies'],\n",
       " ['in', '<UNK>', '<UNK>', 'et', '<UNK>', 'et', '<UNK>', '<UNK>'],\n",
       " ['i', 'am', 'listening', 'my', 'son'],\n",
       " ['father',\n",
       "  'i',\n",
       "  'have',\n",
       "  'betrayed',\n",
       "  'my',\n",
       "  'family',\n",
       "  'i',\n",
       "  'betrayed',\n",
       "  'my',\n",
       "  'men',\n",
       "  'and',\n",
       "  'i',\n",
       "  'betrayed',\n",
       "  'you'],\n",
       " ['what', 'are', 'you', 'saying'],\n",
       " ['i', 'lied', 'the', 'journey', 'will', 'be', 'longer', 'than', 'i', 'said'],\n",
       " ['how', 'long'],\n",
       " ['may',\n",
       "  'god',\n",
       "  'forgive',\n",
       "  'you',\n",
       "  'you',\n",
       "  'must',\n",
       "  'tell',\n",
       "  'them',\n",
       "  'you',\n",
       "  'must',\n",
       "  'tell',\n",
       "  'your',\n",
       "  'men'],\n",
       " ['if',\n",
       "  'i',\n",
       "  'tell',\n",
       "  'them',\n",
       "  'they',\n",
       "  'wo',\n",
       "  'not',\n",
       "  'follow',\n",
       "  'me',\n",
       "  'you',\n",
       "  'know',\n",
       "  'that',\n",
       "  'i',\n",
       "  'am',\n",
       "  'right',\n",
       "  'father',\n",
       "  'you',\n",
       "  'trust',\n",
       "  'me'],\n",
       " ['my',\n",
       "  'son',\n",
       "  'my',\n",
       "  'son',\n",
       "  'your',\n",
       "  '<UNK>',\n",
       "  'are',\n",
       "  'sometimes',\n",
       "  'frightening',\n",
       "  '<UNK>',\n",
       "  'you',\n",
       "  'must',\n",
       "  'speak',\n",
       "  'to',\n",
       "  'them',\n",
       "  'and',\n",
       "  'if',\n",
       "  'you',\n",
       "  'do',\n",
       "  'not',\n",
       "  'i',\n",
       "  'will'],\n",
       " ['i', 'believed', 'in', 'you'],\n",
       " ['i', 'suppose', 'we', 'are', 'both', 'old', 'men', 'now'],\n",
       " ['i', 'have', 'to', 'disagree'],\n",
       " ['i', 'knew', 'you', 'would'],\n",
       " ['new', 'worlds', 'create', 'new', 'people'],\n",
       " ['oh', 'so', 'you', 'are', 'a', 'new', 'man'],\n",
       " ['the', 'ocean', 'is', '<UNK>'],\n",
       " ['what', 'did', 'they', 'say', 'about', '<UNK>', 'before', 'today'],\n",
       " ['i', 'can', 'not', 'ignore', 'the', '<UNK>', 'of', 'my', 'council'],\n",
       " ['may', 'i', 'speak', '<UNK>'],\n",
       " ['you', 'show', 'no', '<UNK>', 'to', 'speak', 'otherwise'],\n",
       " ['i',\n",
       "  'know',\n",
       "  'what',\n",
       "  'i',\n",
       "  'see',\n",
       "  'i',\n",
       "  'see',\n",
       "  'someone',\n",
       "  'who',\n",
       "  'does',\n",
       "  'not',\n",
       "  'accept',\n",
       "  'the',\n",
       "  'world',\n",
       "  'as',\n",
       "  'it',\n",
       "  'is',\n",
       "  'who',\n",
       "  'not',\n",
       "  'afraid',\n",
       "  'i',\n",
       "  'see',\n",
       "  'a',\n",
       "  'women',\n",
       "  'who',\n",
       "  'thinks',\n",
       "  'what',\n",
       "  'if'],\n",
       " ['how', 'old', 'are', 'you', '<UNK>', 'colon'],\n",
       " ['do', 'they', 'have', 'such', 'thoughts'],\n",
       " ['but',\n",
       "  'without',\n",
       "  'your',\n",
       "  'brothers',\n",
       "  'nor',\n",
       "  'are',\n",
       "  'you',\n",
       "  'to',\n",
       "  'return',\n",
       "  'to',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  'or',\n",
       "  'any',\n",
       "  'of',\n",
       "  'the',\n",
       "  'other',\n",
       "  '<UNK>',\n",
       "  'you',\n",
       "  'may',\n",
       "  'explore',\n",
       "  'the',\n",
       "  '<UNK>'],\n",
       " ['thank', 'you'],\n",
       " ['there',\n",
       "  'is',\n",
       "  'one',\n",
       "  'thing',\n",
       "  'i',\n",
       "  'would',\n",
       "  'like',\n",
       "  'to',\n",
       "  'understand',\n",
       "  'why',\n",
       "  'do',\n",
       "  'you',\n",
       "  'want',\n",
       "  'to',\n",
       "  'go',\n",
       "  'back',\n",
       "  'after',\n",
       "  'all',\n",
       "  'this'],\n",
       " ['and',\n",
       "  'you',\n",
       "  'say',\n",
       "  'this',\n",
       "  'is',\n",
       "  'an',\n",
       "  'indian',\n",
       "  'vice',\n",
       "  'by',\n",
       "  'god',\n",
       "  'i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'see',\n",
       "  'any',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'pleasure',\n",
       "  'that',\n",
       "  'would',\n",
       "  'make',\n",
       "  'this',\n",
       "  'a',\n",
       "  'sin'],\n",
       " ['we',\n",
       "  'lost',\n",
       "  'cousins',\n",
       "  'friends',\n",
       "  'we',\n",
       "  'will',\n",
       "  'wash',\n",
       "  'this',\n",
       "  'in',\n",
       "  'blood'],\n",
       " ['you',\n",
       "  'want',\n",
       "  'a',\n",
       "  'war',\n",
       "  'fine',\n",
       "  'we',\n",
       "  'are',\n",
       "  'a',\n",
       "  'thousand',\n",
       "  'they',\n",
       "  '<UNK>',\n",
       "  'us',\n",
       "  'by',\n",
       "  'ten',\n",
       "  'who',\n",
       "  'will',\n",
       "  'you',\n",
       "  'kill',\n",
       "  'which',\n",
       "  'tribe'],\n",
       " ['we', 'ca', 'not', 'raise', 'the', 'wheel', 'without', 'it'],\n",
       " ['don', '<UNK>', 'we', 'all', 'have', 'to', 'work'],\n",
       " ['in',\n",
       "  'one',\n",
       "  'act',\n",
       "  'of',\n",
       "  '<UNK>',\n",
       "  'you',\n",
       "  'have',\n",
       "  'created',\n",
       "  'chaos',\n",
       "  '<UNK>',\n",
       "  'who',\n",
       "  'were',\n",
       "  'fighting',\n",
       "  'each',\n",
       "  'other',\n",
       "  'are',\n",
       "  'now',\n",
       "  'joining',\n",
       "  'forces',\n",
       "  'against',\n",
       "  'us',\n",
       "  'all',\n",
       "  'that',\n",
       "  'because',\n",
       "  'of',\n",
       "  'your',\n",
       "  'criminal',\n",
       "  '<UNK>'],\n",
       " ['<UNK>', 'is', 'what', 'monkeys', 'understand'],\n",
       " ['you',\n",
       "  'will',\n",
       "  'be',\n",
       "  'held',\n",
       "  'in',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  'of',\n",
       "  'your',\n",
       "  '<UNK>',\n",
       "  'and',\n",
       "  '<UNK>',\n",
       "  'until',\n",
       "  'you',\n",
       "  'are',\n",
       "  'returned',\n",
       "  'to',\n",
       "  'spain',\n",
       "  'where',\n",
       "  'you',\n",
       "  'will',\n",
       "  'be',\n",
       "  '<UNK>',\n",
       "  'have',\n",
       "  'you',\n",
       "  'anything',\n",
       "  'to',\n",
       "  'say'],\n",
       " ['due', 'west', 'captain', '<UNK>', 'and', 'may', 'god', 'be', 'with', 'us'],\n",
       " ['well',\n",
       "  'it',\n",
       "  'the',\n",
       "  'men',\n",
       "  'sir',\n",
       "  'they',\n",
       "  'wonder',\n",
       "  'how',\n",
       "  'you',\n",
       "  'know',\n",
       "  'our',\n",
       "  'position',\n",
       "  'we',\n",
       "  'have',\n",
       "  'lost',\n",
       "  'sight',\n",
       "  'from',\n",
       "  'land',\n",
       "  'days',\n",
       "  'ago'],\n",
       " ['and', 'what', 'do', 'you', 'think', '<UNK>'],\n",
       " ['well',\n",
       "  'i',\n",
       "  'surely',\n",
       "  'know',\n",
       "  'what',\n",
       "  'a',\n",
       "  'quadrant',\n",
       "  'is',\n",
       "  'but',\n",
       "  'i',\n",
       "  'have',\n",
       "  'never',\n",
       "  'seen',\n",
       "  'it',\n",
       "  'used',\n",
       "  'at',\n",
       "  'night',\n",
       "  'before'],\n",
       " ['what', 'do', 'you', 'read'],\n",
       " ['what', 'he', 'doing'],\n",
       " ['he',\n",
       "  'drawing',\n",
       "  'an',\n",
       "  '<UNK>',\n",
       "  'he',\n",
       "  'saying',\n",
       "  'we',\n",
       "  'are',\n",
       "  'on',\n",
       "  'an',\n",
       "  '<UNK>'],\n",
       " ['where', 'can', 'i', 'meet', 'this', 'man'],\n",
       " ['you', 'lied', 'you', 'cheated', 'we', 'are', 'way', 'past', 'leagues'],\n",
       " ['six', 'days', 'ago', 'yes'],\n",
       " ['you', 'must', 'be', 'mad'],\n",
       " ['we', 'have', 'to', 'keep', 'the', 'hopes', 'of', 'these', 'men', 'alive'],\n",
       " ['we', 'are', 'on', 'the', '<UNK>', 'of', 'a', '<UNK>', 'colon'],\n",
       " ['you', 'think', 'i', 'do', 'not', 'know', 'that'],\n",
       " ['we', 'are', 'lost'],\n",
       " ['the', 'land', 'is', 'there', 'i', 'know', 'it'],\n",
       " ['you',\n",
       "  'do',\n",
       "  'not',\n",
       "  'know',\n",
       "  'anything',\n",
       "  'listen',\n",
       "  'colon',\n",
       "  'these',\n",
       "  'are',\n",
       "  'my',\n",
       "  'ships',\n",
       "  'right',\n",
       "  'so',\n",
       "  'i',\n",
       "  'telling',\n",
       "  'you',\n",
       "  'we',\n",
       "  'are',\n",
       "  'turning',\n",
       "  'back'],\n",
       " ['and',\n",
       "  'then',\n",
       "  'what',\n",
       "  'half',\n",
       "  'of',\n",
       "  'the',\n",
       "  'water',\n",
       "  'has',\n",
       "  'gone',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'is',\n",
       "  'nearly',\n",
       "  '<UNK>',\n",
       "  'you',\n",
       "  'know',\n",
       "  'that'],\n",
       " ['jesus', 'maria', 'i', 'should', 'have', 'never', 'listened', 'to', 'you'],\n",
       " ['you',\n",
       "  'never',\n",
       "  'did',\n",
       "  'you',\n",
       "  'did',\n",
       "  'all',\n",
       "  'the',\n",
       "  'talking',\n",
       "  'for',\n",
       "  'both',\n",
       "  'of',\n",
       "  'us',\n",
       "  'remember'],\n",
       " ['you', 'bloody'],\n",
       " ['<UNK>',\n",
       "  '<UNK>',\n",
       "  'all',\n",
       "  'we',\n",
       "  'can',\n",
       "  'do',\n",
       "  'now',\n",
       "  'is',\n",
       "  'go',\n",
       "  'forward',\n",
       "  'think',\n",
       "  'about',\n",
       "  'that'],\n",
       " ['you', 'tell', 'that', 'to', 'them'],\n",
       " ['is', 'that', 'the', 'man', 'i', 'knew', '<UNK>', 'sanchez'],\n",
       " ['you',\n",
       "  'were',\n",
       "  'right',\n",
       "  'don',\n",
       "  'sanchez',\n",
       "  'his',\n",
       "  'demands',\n",
       "  'could',\n",
       "  'never',\n",
       "  'be',\n",
       "  'granted'],\n",
       " ['into', 'a', '<UNK>'],\n",
       " ['every',\n",
       "  'ship',\n",
       "  'returns',\n",
       "  'with',\n",
       "  'a',\n",
       "  'cargo',\n",
       "  'of',\n",
       "  'sick',\n",
       "  'and',\n",
       "  'dying',\n",
       "  'but',\n",
       "  'with',\n",
       "  'no',\n",
       "  'gold',\n",
       "  'the',\n",
       "  'new',\n",
       "  'world',\n",
       "  'proves',\n",
       "  'expensive',\n",
       "  'your',\n",
       "  'majesty'],\n",
       " ['but',\n",
       "  'there',\n",
       "  'is',\n",
       "  'worse',\n",
       "  'he',\n",
       "  'ordered',\n",
       "  'the',\n",
       "  '<UNK>',\n",
       "  'of',\n",
       "  'five',\n",
       "  'members',\n",
       "  'of',\n",
       "  'the',\n",
       "  '<UNK>'],\n",
       " ['then', 'what', 'do', 'you', 'suggest', 'don', 'sanchez'],\n",
       " ['he', 'must', 'be', 'replaced'],\n",
       " ['i', 'know', 'i', 'should', 'not', 'tolerate', 'his', '<UNK>'],\n",
       " ['then', 'why'],\n",
       " ['are', 'you', 'my', 'attorney', 'i', '<UNK>', 'i', 'insane'],\n",
       " ['i', 'not', 'your', 'lawyer', 'until', 'i', 'see', 'the', 'money'],\n",
       " ['oh', 'no', 'no', 'shit'],\n",
       " ['<UNK>',\n",
       "  'take',\n",
       "  'it',\n",
       "  'easy',\n",
       "  'stay',\n",
       "  'with',\n",
       "  'me',\n",
       "  'sit',\n",
       "  'down',\n",
       "  'what',\n",
       "  'do',\n",
       "  'you',\n",
       "  'need',\n",
       "  'what',\n",
       "  'are',\n",
       "  'you',\n",
       "  'looking',\n",
       "  'for'],\n",
       " ['do', 'not', 'say', 'anything'],\n",
       " ['where', 'are', 'we', 'going'],\n",
       " ['i', 'coming', 'with', 'you'],\n",
       " ['yes', 'yes', 'come', 'with', 'me'],\n",
       " ['i',\n",
       "  'brought',\n",
       "  'you',\n",
       "  'some',\n",
       "  'letters',\n",
       "  'it',\n",
       "  'really',\n",
       "  'fan',\n",
       "  'mail',\n",
       "  'women',\n",
       "  'mostly',\n",
       "  'one',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'you',\n",
       "  'clothes',\n",
       "  'another',\n",
       "  'sent',\n",
       "  'a',\n",
       "  'check',\n",
       "  'another',\n",
       "  'wants',\n",
       "  'a',\n",
       "  'check'],\n",
       " ['you', 'bring', 'the', 'cigarettes'],\n",
       " ['delusions', 'and', 'paranoia'],\n",
       " ['i', 'was', 'all', 'of', 'these'],\n",
       " ['well',\n",
       "  'you',\n",
       "  'did',\n",
       "  'not',\n",
       "  'appreciate',\n",
       "  'the',\n",
       "  '<UNK>',\n",
       "  'of',\n",
       "  'it',\n",
       "  'until',\n",
       "  'recently',\n",
       "  'no',\n",
       "  'question',\n",
       "  'about',\n",
       "  'that'],\n",
       " ['what', 'about', '<UNK>'],\n",
       " ['disappeared',\n",
       "  'they',\n",
       "  'are',\n",
       "  'looking',\n",
       "  'everywhere',\n",
       "  'maybe',\n",
       "  'he',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  '<UNK>'],\n",
       " ['no', 'he', 'is', 'here', 'shit'],\n",
       " ['do', 'not', 'worry', 'about', 'him', 'think', 'about', 'yourself'],\n",
       " ['what', 'about', 'my', 'movie', 'rights', 'book', 'rights'],\n",
       " ['look',\n",
       "  'i',\n",
       "  'have',\n",
       "  'not',\n",
       "  'really',\n",
       "  '<UNK>',\n",
       "  'on',\n",
       "  'that',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'thing'],\n",
       " ['what', 'your', 'cut', 'how', 'much'],\n",
       " ['i', 'would', 'say', 'half', 'half', 'is', 'fair'],\n",
       " ['no', 'no', 'way'],\n",
       " ['but', 'it'],\n",
       " ['<UNK>',\n",
       "  'no',\n",
       "  'more',\n",
       "  'or',\n",
       "  'i',\n",
       "  'call',\n",
       "  'another',\n",
       "  'lawyer',\n",
       "  'this',\n",
       "  'is',\n",
       "  'the',\n",
       "  'biggest',\n",
       "  'case',\n",
       "  'of',\n",
       "  'your',\n",
       "  'life',\n",
       "  'do',\n",
       "  'not',\n",
       "  'try',\n",
       "  'to',\n",
       "  'negotiate',\n",
       "  'thirty',\n",
       "  'percent',\n",
       "  'say',\n",
       "  'yes',\n",
       "  'or',\n",
       "  'no'],\n",
       " ['this',\n",
       "  'is',\n",
       "  'not',\n",
       "  'about',\n",
       "  'money',\n",
       "  '<UNK>',\n",
       "  'i',\n",
       "  'need',\n",
       "  'your',\n",
       "  'trust',\n",
       "  'in',\n",
       "  'me'],\n",
       " ['what', 'else', 'do', 'you', 'need'],\n",
       " ['i',\n",
       "  'need',\n",
       "  'to',\n",
       "  'know',\n",
       "  'about',\n",
       "  'your',\n",
       "  'background',\n",
       "  'i',\n",
       "  'need',\n",
       "  'to',\n",
       "  'know',\n",
       "  'about',\n",
       "  'your',\n",
       "  '<UNK>',\n",
       "  'why',\n",
       "  'you',\n",
       "  'are',\n",
       "  'here'],\n",
       " ['tell',\n",
       "  'me',\n",
       "  'about',\n",
       "  'yourself',\n",
       "  'what',\n",
       "  'you',\n",
       "  'did',\n",
       "  'as',\n",
       "  'a',\n",
       "  'young',\n",
       "  'boy',\n",
       "  'what',\n",
       "  'your',\n",
       "  'parents',\n",
       "  'were',\n",
       "  'like'],\n",
       " ['my',\n",
       "  'father',\n",
       "  'always',\n",
       "  '<UNK>',\n",
       "  'me',\n",
       "  'killed',\n",
       "  'my',\n",
       "  '<UNK>',\n",
       "  'and',\n",
       "  'my',\n",
       "  'mother',\n",
       "  'was',\n",
       "  'blind'],\n",
       " ['your', 'mother', 'was', 'blind'],\n",
       " ['yeah',\n",
       "  'she',\n",
       "  'went',\n",
       "  'blind',\n",
       "  'giving',\n",
       "  'birth',\n",
       "  'to',\n",
       "  'me',\n",
       "  'she',\n",
       "  'went',\n",
       "  'to',\n",
       "  'fucking',\n",
       "  'black',\n",
       "  'market',\n",
       "  'doctor',\n",
       "  'to',\n",
       "  '<UNK>',\n",
       "  'me'],\n",
       " ['back', 'in', 'the', 'czech', '<UNK>'],\n",
       " ['yeah',\n",
       "  'yeah',\n",
       "  'bad',\n",
       "  'doctor',\n",
       "  'gave',\n",
       "  'her',\n",
       "  'bad',\n",
       "  'drugs',\n",
       "  'which',\n",
       "  'made',\n",
       "  'her',\n",
       "  'go',\n",
       "  'blind',\n",
       "  'and',\n",
       "  'my',\n",
       "  'father',\n",
       "  'blamed',\n",
       "  'me',\n",
       "  'for',\n",
       "  'her',\n",
       "  '<UNK>'],\n",
       " ['your', 'father', 'blamed', 'you', 'for', 'your', 'mother', '<UNK>'],\n",
       " ['that',\n",
       "  'what',\n",
       "  'he',\n",
       "  'did',\n",
       "  'to',\n",
       "  'me',\n",
       "  'he',\n",
       "  'put',\n",
       "  'cigarettes',\n",
       "  'out',\n",
       "  'on',\n",
       "  'me'],\n",
       " ['your', 'father', 'put', 'cigarettes', 'out', 'on', 'you'],\n",
       " ['out', 'on', 'my', 'back', 'when', 'i', 'was', 'a', 'small', 'boy'],\n",
       " ['i', '<UNK>', 'do', 'not', 'you', 'think'],\n",
       " ['so',\n",
       "  'we',\n",
       "  'kill',\n",
       "  'someone',\n",
       "  'famous',\n",
       "  'and',\n",
       "  'if',\n",
       "  'we',\n",
       "  'are',\n",
       "  'caught',\n",
       "  'we',\n",
       "  'are',\n",
       "  'sent',\n",
       "  'to',\n",
       "  'mental',\n",
       "  'hospital'],\n",
       " ['alright', 'that', 'a', '<UNK>', 'homicide'],\n",
       " ['now', 'i', 'become', 'custody', 'of', 'police', 'department'],\n",
       " ['if',\n",
       "  'you',\n",
       "  'cooperate',\n",
       "  'with',\n",
       "  'the',\n",
       "  'da',\n",
       "  'maybe',\n",
       "  'they',\n",
       "  'will',\n",
       "  'help',\n",
       "  'you',\n",
       "  'with',\n",
       "  'your',\n",
       "  'situation'],\n",
       " ['i', 'will', 'if', 'they', 'do', 'not', 'send', 'me', 'back'],\n",
       " ['are', 'you', 'married'],\n",
       " ['divorced'],\n",
       " ['i', 'ca', 'not', 'take', 'you', 'to', 'my', 'place'],\n",
       " ['the',\n",
       "  'men',\n",
       "  'are',\n",
       "  'out',\n",
       "  'of',\n",
       "  'quarters',\n",
       "  'practicing',\n",
       "  'putting',\n",
       "  'out',\n",
       "  'fires'],\n",
       " ['so', 'the', 'station', 'is', 'empty'],\n",
       " ['you', 'considered', 'becoming', 'a', 'prostitute'],\n",
       " ['yes', 'i', 'considered', 'it'],\n",
       " ['did', 'you', 'ever', 'turn', 'tricks', 'before'],\n",
       " ['no'],\n",
       " ['what', 'about', 'back', 'home'],\n",
       " ['so', 'you', 'were', 'never', 'a', 'prostitute'],\n",
       " ['what', 'are', 'you', 'asking', 'me'],\n",
       " ['i', 'not', 'a', 'whore', 'i', 'not', 'a', 'whore'],\n",
       " ['i', 'know'],\n",
       " ['you',\n",
       "  'do',\n",
       "  'not',\n",
       "  'know',\n",
       "  'i',\n",
       "  'sorry',\n",
       "  'i',\n",
       "  'was',\n",
       "  'desperate',\n",
       "  'that',\n",
       "  'not',\n",
       "  'me',\n",
       "  'i',\n",
       "  'shot',\n",
       "  'a',\n",
       "  'cop',\n",
       "  'can',\n",
       "  'you',\n",
       "  'imagine',\n",
       "  'what',\n",
       "  'they',\n",
       "  'will',\n",
       "  'do',\n",
       "  'to',\n",
       "  'me',\n",
       "  'when',\n",
       "  'i',\n",
       "  'got',\n",
       "  'to',\n",
       "  'prison'],\n",
       " ['are', 'you', 'alright'],\n",
       " ['i', 'still', 'ca', 'not', 'believe', 'eddie', 'gone'],\n",
       " ['is', 'he', 'your', 'boyfriend'],\n",
       " ['<UNK>', 'he', 'gay', 'are', 'you', 'jealous'],\n",
       " ['if', 'i', 'was', 'your', 'boyfriend', 'i', 'might', 'be'],\n",
       " ['a',\n",
       "  'good',\n",
       "  'immigration',\n",
       "  'lawyer',\n",
       "  'could',\n",
       "  'stall',\n",
       "  'the',\n",
       "  'process',\n",
       "  'eddie',\n",
       "  'recommended',\n",
       "  'one'],\n",
       " ['no', 'matter', 'what', 'happens', 'i', 'glad', 'i', 'met', 'you'],\n",
       " ['you', 'better', 'get', 'packed'],\n",
       " ['do', 'you', 'have', 'coffee'],\n",
       " ['in', 'the', 'kitchen'],\n",
       " ['i', 'will', 'make', 'some', 'for', 'us'],\n",
       " ['what', 'are', 'you', 'doing'],\n",
       " ['forget',\n",
       "  'about',\n",
       "  'me',\n",
       "  'you',\n",
       "  'have',\n",
       "  'enough',\n",
       "  'problems',\n",
       "  'of',\n",
       "  'your',\n",
       "  'own'],\n",
       " ['do', 'you', 'really', 'want', 'me', 'to', 'forget', 'about', 'you'],\n",
       " ['i', 'do', 'not', 'want', 'to', 'drag', 'you', 'down', 'with', 'me'],\n",
       " ['i',\n",
       "  'told',\n",
       "  'your',\n",
       "  'partner',\n",
       "  'i',\n",
       "  'ca',\n",
       "  'not',\n",
       "  'help',\n",
       "  'i',\n",
       "  'did',\n",
       "  'not',\n",
       "  'see',\n",
       "  'anything'],\n",
       " [\"c'mon\",\n",
       "  'start',\n",
       "  'at',\n",
       "  'the',\n",
       "  'beginning',\n",
       "  'you',\n",
       "  'know',\n",
       "  'these',\n",
       "  'people'],\n",
       " ['<UNK>',\n",
       "  'was',\n",
       "  'a',\n",
       "  'friend',\n",
       "  'of',\n",
       "  'mine',\n",
       "  'my',\n",
       "  'shower',\n",
       "  'was',\n",
       "  'broken',\n",
       "  'she',\n",
       "  'let',\n",
       "  'me',\n",
       "  'use',\n",
       "  'theirs'],\n",
       " ['whether',\n",
       "  'you',\n",
       "  'tell',\n",
       "  'us',\n",
       "  'or',\n",
       "  'not',\n",
       "  'we',\n",
       "  'will',\n",
       "  'find',\n",
       "  'out',\n",
       "  'better',\n",
       "  'if',\n",
       "  'it',\n",
       "  'comes',\n",
       "  'from',\n",
       "  'you'],\n",
       " ['if', 'i', 'tell', 'you', 'will', 'you', 'arrest', 'me'],\n",
       " ['are',\n",
       "  'you',\n",
       "  'here',\n",
       "  '<UNK>',\n",
       "  'do',\n",
       "  'not',\n",
       "  'worry',\n",
       "  'about',\n",
       "  'that',\n",
       "  'we',\n",
       "  'will',\n",
       "  'talk',\n",
       "  'to',\n",
       "  'immigration',\n",
       "  'they',\n",
       "  'wo',\n",
       "  'not',\n",
       "  '<UNK>',\n",
       "  'you'],\n",
       " ['a', 'cop'],\n",
       " ['i',\n",
       "  'from',\n",
       "  'a',\n",
       "  'small',\n",
       "  'town',\n",
       "  'in',\n",
       "  '<UNK>',\n",
       "  'like',\n",
       "  'the',\n",
       "  'south',\n",
       "  'here',\n",
       "  'the',\n",
       "  'police',\n",
       "  'is',\n",
       "  'right',\n",
       "  'a',\n",
       "  'civilian',\n",
       "  'is',\n",
       "  'wrong',\n",
       "  'so',\n",
       "  'i',\n",
       "  '<UNK>'],\n",
       " ['look',\n",
       "  'we',\n",
       "  'can',\n",
       "  'help',\n",
       "  'you',\n",
       "  'but',\n",
       "  'right',\n",
       "  'now',\n",
       "  'we',\n",
       "  'have',\n",
       "  'to',\n",
       "  'deal',\n",
       "  'with',\n",
       "  'what',\n",
       "  'happening',\n",
       "  'here',\n",
       "  'tell',\n",
       "  'us',\n",
       "  'the',\n",
       "  'truth',\n",
       "  'is',\n",
       "  'that',\n",
       "  'the',\n",
       "  'truth'],\n",
       " ['oh'],\n",
       " ['it', 'was', 'my', 'decision', 'not', 'his'],\n",
       " ['well',\n",
       "  'i',\n",
       "  'the',\n",
       "  'deputy',\n",
       "  'chief',\n",
       "  'fire',\n",
       "  'marshall',\n",
       "  'and',\n",
       "  'every',\n",
       "  'now',\n",
       "  'and',\n",
       "  'then',\n",
       "  'i',\n",
       "  'would',\n",
       "  'like',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<UNK>',\n",
       "  'in',\n",
       "  'decisions'],\n",
       " ['look',\n",
       "  'after',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  'me',\n",
       "  'you',\n",
       "  'can',\n",
       "  'do',\n",
       "  'the',\n",
       "  'press',\n",
       "  'conference',\n",
       "  'how',\n",
       "  'about',\n",
       "  'that',\n",
       "  'the',\n",
       "  'case',\n",
       "  'is',\n",
       "  'all',\n",
       "  'yours'],\n",
       " ['oh', 'yeah', 'alright'],\n",
       " ['i', 'ready', 'to', 'be', '<UNK>', 'excuse', 'us'],\n",
       " ['who', 'did', 'cause', 'and', 'origin'],\n",
       " ['who', 'do', 'you', 'think', 'chief'],\n",
       " ['then', 'why', 'did', 'not', 'you', 'talk', 'to', 'the', 'reporter'],\n",
       " ['ladder',\n",
       "  'was',\n",
       "  'on',\n",
       "  'the',\n",
       "  'rock',\n",
       "  'for',\n",
       "  'training',\n",
       "  'we',\n",
       "  'stopped',\n",
       "  'there',\n",
       "  'so',\n",
       "  'she',\n",
       "  'could',\n",
       "  'get',\n",
       "  'cleaned',\n",
       "  'up'],\n",
       " ['what', 'do', 'you', 'mean', 'up'],\n",
       " ['i', 'let', 'her', 'take', 'a', 'shower'],\n",
       " ['a', 'shower', 'did', 'you', 'take', 'one', 'too'],\n",
       " ['chief', 'mind', 'if', 'i', 'take', 'her'],\n",
       " ['the',\n",
       "  'public',\n",
       "  'does',\n",
       "  'not',\n",
       "  'have',\n",
       "  'any',\n",
       "  'idea',\n",
       "  'what',\n",
       "  'we',\n",
       "  'do',\n",
       "  'and',\n",
       "  'now',\n",
       "  'you',\n",
       "  'are',\n",
       "  'going',\n",
       "  'to',\n",
       "  'define',\n",
       "  'our',\n",
       "  'image',\n",
       "  'this',\n",
       "  'is',\n",
       "  'going',\n",
       "  'to',\n",
       "  'be',\n",
       "  'our',\n",
       "  '<UNK>',\n",
       "  'king'],\n",
       " ['what',\n",
       "  'was',\n",
       "  'i',\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'do',\n",
       "  'the',\n",
       "  'guy',\n",
       "  'tried',\n",
       "  'to',\n",
       "  'mug',\n",
       "  'me',\n",
       "  'i',\n",
       "  'was',\n",
       "  'gon',\n",
       "  'na',\n",
       "  'send',\n",
       "  'a',\n",
       "  'cop',\n",
       "  'back',\n",
       "  'i',\n",
       "  'just',\n",
       "  'forgot'],\n",
       " ['forgot', 'you', '<UNK>', 'a', 'civilian', 'to', 'a', 'tree'],\n",
       " ['chief',\n",
       "  'i',\n",
       "  'know',\n",
       "  'i',\n",
       "  'screwed',\n",
       "  'up',\n",
       "  'but',\n",
       "  'this',\n",
       "  'guy',\n",
       "  'was',\n",
       "  'no',\n",
       "  'innocent',\n",
       "  'civilian'],\n",
       " ['well',\n",
       "  'this',\n",
       "  'is',\n",
       "  'gon',\n",
       "  'na',\n",
       "  'end',\n",
       "  'your',\n",
       "  'career',\n",
       "  'and',\n",
       "  'probably',\n",
       "  'mine'],\n",
       " ['but', 'chief', 'over', 'this'],\n",
       " ['do',\n",
       "  'not',\n",
       "  'you',\n",
       "  'guys',\n",
       "  'understand',\n",
       "  'it',\n",
       "  'all',\n",
       "  'about',\n",
       "  'image',\n",
       "  'the',\n",
       "  'better',\n",
       "  'we',\n",
       "  'look',\n",
       "  'the',\n",
       "  'more',\n",
       "  'money',\n",
       "  'i',\n",
       "  'get',\n",
       "  'to',\n",
       "  'pay',\n",
       "  'you',\n",
       "  'guys',\n",
       "  'overtime'],\n",
       " ['yeah', 'right'],\n",
       " ['what', 'was', 'that', '<UNK>'],\n",
       " ['i',\n",
       "  'said',\n",
       "  'yeah',\n",
       "  'you',\n",
       "  'are',\n",
       "  'right',\n",
       "  'chief',\n",
       "  'as',\n",
       "  'soon',\n",
       "  'as',\n",
       "  'we',\n",
       "  'get',\n",
       "  'somethin',\n",
       "  'we',\n",
       "  'will',\n",
       "  'let',\n",
       "  'you',\n",
       "  'alert',\n",
       "  'the',\n",
       "  'media'],\n",
       " ['did', 'the', 'da', '<UNK>', 'her', 'deposition'],\n",
       " ['yeah', 'he', 'finished', 'awhile', 'ago'],\n",
       " ['alright',\n",
       "  'swing',\n",
       "  'by',\n",
       "  'her',\n",
       "  'apartment',\n",
       "  'let',\n",
       "  'her',\n",
       "  'pick',\n",
       "  'up',\n",
       "  'her',\n",
       "  'clothes',\n",
       "  'and',\n",
       "  'take',\n",
       "  'her',\n",
       "  'straight',\n",
       "  'to',\n",
       "  'hoover',\n",
       "  'street',\n",
       "  'you',\n",
       "  'got',\n",
       "  'that'],\n",
       " ['coffee', 'for', 'me', 'i', 'got', 'ta', 'slow', 'down'],\n",
       " ['vodka', '<UNK>'],\n",
       " ['i', 'gon', 'na', 'propose'],\n",
       " ['when'],\n",
       " ['tomorrow', 'at', 'lunch'],\n",
       " ['what', 'he', 'looking', 'for'],\n",
       " ['where', 'is', 'she'],\n",
       " ['takin', 'a', 'bath'],\n",
       " ['any', 'id'],\n",
       " ['sorry', 'pd', 'only'],\n",
       " ['only', 'one', 'guys', 'checked', 'in'],\n",
       " ['yeah'],\n",
       " ['the',\n",
       "  'other',\n",
       "  'side',\n",
       "  'of',\n",
       "  'the',\n",
       "  'street',\n",
       "  'the',\n",
       "  'guy',\n",
       "  'with',\n",
       "  'the',\n",
       "  '<UNK>',\n",
       "  'do',\n",
       "  'not',\n",
       "  'look',\n",
       "  'put',\n",
       "  'her',\n",
       "  'in',\n",
       "  'the',\n",
       "  'car',\n",
       "  'stay',\n",
       "  'this',\n",
       "  'side'],\n",
       " ['are', 'you', 'hit'],\n",
       " ['he',\n",
       "  'got',\n",
       "  'my',\n",
       "  'gun',\n",
       "  'motherfucker',\n",
       "  'was',\n",
       "  '<UNK>',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'time'],\n",
       " ['who', 'there'],\n",
       " ['police',\n",
       "  'we',\n",
       "  'would',\n",
       "  'like',\n",
       "  'to',\n",
       "  'ask',\n",
       "  'you',\n",
       "  'a',\n",
       "  'few',\n",
       "  'questions'],\n",
       " ['i',\n",
       "  'have',\n",
       "  'nothin',\n",
       "  'to',\n",
       "  'say',\n",
       "  'if',\n",
       "  'you',\n",
       "  'wan',\n",
       "  'na',\n",
       "  'contact',\n",
       "  'my',\n",
       "  'attorney'],\n",
       " ['what', 'wrong'],\n",
       " ['we',\n",
       "  'do',\n",
       "  'not',\n",
       "  'have',\n",
       "  'her',\n",
       "  'id',\n",
       "  'yet',\n",
       "  'but',\n",
       "  'one',\n",
       "  'of',\n",
       "  'your',\n",
       "  'girls',\n",
       "  'was',\n",
       "  'killed',\n",
       "  'last',\n",
       "  'night',\n",
       "  'at',\n",
       "  'the',\n",
       "  'king',\n",
       "  'edward',\n",
       "  'hotel'],\n",
       " ['yeah',\n",
       "  'he',\n",
       "  'wanted',\n",
       "  'a',\n",
       "  'girl',\n",
       "  'from',\n",
       "  '<UNK>',\n",
       "  'but',\n",
       "  'i',\n",
       "  'sent',\n",
       "  'him',\n",
       "  'honey',\n",
       "  'once',\n",
       "  'they',\n",
       "  'get',\n",
       "  'there',\n",
       "  'you',\n",
       "  'know',\n",
       "  'it',\n",
       "  'does',\n",
       "  'not',\n",
       "  'really',\n",
       "  'matter',\n",
       "  'honey',\n",
       "  'was',\n",
       "  'killed',\n",
       "  'poor',\n",
       "  'girl'],\n",
       " ['do', 'you', 'have', 'any', 'czech', 'girls', 'working', 'for', 'you'],\n",
       " ['no'],\n",
       " ['boy', 'she', 'so', 'popular', 'all', 'the', 'sudden'],\n",
       " ['what', 'are', 'you', 'saying'],\n",
       " ['he',\n",
       "  'said',\n",
       "  'he',\n",
       "  'was',\n",
       "  'her',\n",
       "  'cousin',\n",
       "  'i',\n",
       "  'told',\n",
       "  'him',\n",
       "  'where',\n",
       "  'she',\n",
       "  'works',\n",
       "  'they',\n",
       "  'were',\n",
       "  'just',\n",
       "  'here'],\n",
       " ['describe', 'him'],\n",
       " ['tall',\n",
       "  '<UNK>',\n",
       "  'scary',\n",
       "  'eyes',\n",
       "  'second',\n",
       "  'guy',\n",
       "  'with',\n",
       "  'him',\n",
       "  'was',\n",
       "  'shorter',\n",
       "  'with',\n",
       "  'a',\n",
       "  '<UNK>',\n",
       "  'build',\n",
       "  'and',\n",
       "  'he',\n",
       "  'would',\n",
       "  'not',\n",
       "  'turn',\n",
       "  'his',\n",
       "  '<UNK>',\n",
       "  'off',\n",
       "  'me'],\n",
       " ['he', 'had', 'a', '<UNK>', 'where', 'is', 'she', 'quickly'],\n",
       " ['hey',\n",
       "  'that',\n",
       "  'great',\n",
       "  'you',\n",
       "  'guys',\n",
       "  'got',\n",
       "  'it',\n",
       "  'all',\n",
       "  'wrapped',\n",
       "  'up',\n",
       "  'but',\n",
       "  'you',\n",
       "  'do',\n",
       "  'not',\n",
       "  'mind',\n",
       "  'if',\n",
       "  'we',\n",
       "  'go',\n",
       "  'through',\n",
       "  'the',\n",
       "  'routine',\n",
       "  'it',\n",
       "  'gives',\n",
       "  'us',\n",
       "  'somethin',\n",
       "  'to',\n",
       "  'do'],\n",
       " ['you', 'know', 'what', 'that', 'is', 'right'],\n",
       " ['no', 'what', 'is', 'it'],\n",
       " ['it',\n",
       "  'your',\n",
       "  'crime',\n",
       "  'scene',\n",
       "  'now',\n",
       "  'you',\n",
       "  'can',\n",
       "  'do',\n",
       "  'what',\n",
       "  'you',\n",
       "  'want'],\n",
       " ['watch', 'the', 'news'],\n",
       " ['nah', 'i', 'musta', 'missed', 'it'],\n",
       " ['well',\n",
       "  'just',\n",
       "  'so',\n",
       "  'you',\n",
       "  'know',\n",
       "  'i',\n",
       "  'gave',\n",
       "  'you',\n",
       "  'guys',\n",
       "  'the',\n",
       "  'credit'],\n",
       " ['well',\n",
       "  'just',\n",
       "  'so',\n",
       "  'you',\n",
       "  'know',\n",
       "  'i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'care',\n",
       "  'about',\n",
       "  'that',\n",
       "  'stuff'],\n",
       " ['nah', 'why', 'should', 'you'],\n",
       " ['i', 'do', 'not', 'even', 'watch', 'tv'],\n",
       " ['did', 'you', 'get', 'a', 'report', 'from', 'the', 'me'],\n",
       " ['sure',\n",
       "  'but',\n",
       "  'i',\n",
       "  'would',\n",
       "  'like',\n",
       "  'to',\n",
       "  'ask',\n",
       "  'you',\n",
       "  'something',\n",
       "  'you',\n",
       "  'got',\n",
       "  'a',\n",
       "  'problem',\n",
       "  'with',\n",
       "  'me'],\n",
       " ['the',\n",
       "  'super',\n",
       "  'said',\n",
       "  'he',\n",
       "  'would',\n",
       "  'seen',\n",
       "  'her',\n",
       "  'before',\n",
       "  'but',\n",
       "  'she',\n",
       "  'did',\n",
       "  'not',\n",
       "  'live',\n",
       "  'here'],\n",
       " ['pretty'],\n",
       " ['hmmmm'],\n",
       " ['maybe',\n",
       "  'you',\n",
       "  'do',\n",
       "  'not',\n",
       "  'care',\n",
       "  'about',\n",
       "  'that',\n",
       "  'either',\n",
       "  '<UNK>',\n",
       "  'suspect',\n",
       "  'i',\n",
       "  'have',\n",
       "  'had',\n",
       "  'in',\n",
       "  'awhile'],\n",
       " ['eastern', 'europe', 'like', 'what', '<UNK>', '<UNK>'],\n",
       " ['i', 'will', 'come', 'with', 'you'],\n",
       " ['there',\n",
       "  'was',\n",
       "  'not',\n",
       "  'a',\n",
       "  'fire',\n",
       "  'there',\n",
       "  'will',\n",
       "  'be',\n",
       "  'nothing',\n",
       "  'for',\n",
       "  'you',\n",
       "  'to',\n",
       "  'do'],\n",
       " ['i',\n",
       "  'can',\n",
       "  'watch',\n",
       "  'you',\n",
       "  'eddie',\n",
       "  'maybe',\n",
       "  'i',\n",
       "  'will',\n",
       "  'learn',\n",
       "  'something'],\n",
       " ['this', 'is', 'not', 'homicide', 'school'],\n",
       " ['my',\n",
       "  'parents',\n",
       "  'are',\n",
       "  'from',\n",
       "  '<UNK>',\n",
       "  'i',\n",
       "  'can',\n",
       "  'help',\n",
       "  'with',\n",
       "  'the',\n",
       "  'eastern',\n",
       "  'european',\n",
       "  'angle'],\n",
       " ['you', 'are', 'polish'],\n",
       " ['my', 'folks', 'are'],\n",
       " ['you', 'goin', 'to', 'the', 'escort', 'service'],\n",
       " ['you', 'got', 'any', 'better', 'ideas'],\n",
       " ['mind', 'if', 'i', 'ride', 'along', 'with', 'you'],\n",
       " ['this', 'has', 'nothing', 'to', 'do', 'with', 'your', 'fire'],\n",
       " ['i', 'will', 'let', 'you', 'know', 'what', 'happens'],\n",
       " ['this',\n",
       "  'is',\n",
       "  'ridiculous',\n",
       "  'i',\n",
       "  'not',\n",
       "  'gon',\n",
       "  'na',\n",
       "  'be',\n",
       "  'in',\n",
       "  'your',\n",
       "  'way',\n",
       "  'we',\n",
       "  'can',\n",
       "  'talk',\n",
       "  'the',\n",
       "  'case',\n",
       "  'over'],\n",
       " ['tell',\n",
       "  'you',\n",
       "  'what',\n",
       "  'i',\n",
       "  'will',\n",
       "  'flip',\n",
       "  'you',\n",
       "  'a',\n",
       "  'coin',\n",
       "  'if',\n",
       "  'you',\n",
       "  'win',\n",
       "  'you',\n",
       "  'can',\n",
       "  'come',\n",
       "  'with',\n",
       "  'me',\n",
       "  'if',\n",
       "  'you',\n",
       "  'do',\n",
       "  'not',\n",
       "  'win',\n",
       "  'you',\n",
       "  'do',\n",
       "  'not',\n",
       "  'come'],\n",
       " ['two', 'heads'],\n",
       " ['leon', 'meet', 'us', 'at', 'and', 'madison', 'hair', 'salon', '<UNK>'],\n",
       " ['you', 'thirsty'],\n",
       " ['i', 'on', 'duty'],\n",
       " ['so',\n",
       "  'am',\n",
       "  'i',\n",
       "  'alright',\n",
       "  'i',\n",
       "  'will',\n",
       "  'go',\n",
       "  'inside',\n",
       "  'and',\n",
       "  'you',\n",
       "  'cover',\n",
       "  'the',\n",
       "  'back'],\n",
       " ['i',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'run',\n",
       "  'up',\n",
       "  'to',\n",
       "  'a',\n",
       "  'building',\n",
       "  'on',\n",
       "  'fire',\n",
       "  'kick',\n",
       "  'in',\n",
       "  'the',\n",
       "  'door',\n",
       "  'rush',\n",
       "  'into',\n",
       "  'the',\n",
       "  'smoke',\n",
       "  'and',\n",
       "  'save',\n",
       "  'a',\n",
       "  'kid'],\n",
       " ['what', 'are', 'you', 'hiding', 'why', 'are', 'you', 'afraid'],\n",
       " ['she',\n",
       "  'just',\n",
       "  'saw',\n",
       "  'two',\n",
       "  'of',\n",
       "  'her',\n",
       "  'friends',\n",
       "  'killed',\n",
       "  'they',\n",
       "  'probably',\n",
       "  'threatened',\n",
       "  'her'],\n",
       " ['why', 'not'],\n",
       " ['she', 'fucked', 'even', 'if', 'that', 'story', 'is', 'true'],\n",
       " ['look',\n",
       "  'let',\n",
       "  'me',\n",
       "  'talk',\n",
       "  'to',\n",
       "  'her',\n",
       "  'any',\n",
       "  'leads',\n",
       "  'i',\n",
       "  'get',\n",
       "  'they',\n",
       "  'are',\n",
       "  'all',\n",
       "  'yours',\n",
       "  'just',\n",
       "  'let',\n",
       "  'me',\n",
       "  'have',\n",
       "  'a',\n",
       "  'first',\n",
       "  'crack',\n",
       "  'at',\n",
       "  'her'],\n",
       " ['you', 'wan', 'na', 'talk', 'to', 'her', 'alone'],\n",
       " ['yeah'],\n",
       " ['what', 'would', 'your', 'girlfriend', 'think', 'of', 'that'],\n",
       " ['i', 'do', 'not', 'have', 'a', 'girlfriend'],\n",
       " ['my', 'point', 'exactly'],\n",
       " ['i', 'serious', 'here'],\n",
       " ['so', 'am', 'i'],\n",
       " [\"c'mon\",\n",
       "  'you',\n",
       "  'intimidate',\n",
       "  'her',\n",
       "  'you',\n",
       "  'are',\n",
       "  'a',\n",
       "  'celebrity',\n",
       "  'she',\n",
       "  'sees',\n",
       "  'me',\n",
       "  'differently'],\n",
       " ['you',\n",
       "  'are',\n",
       "  'her',\n",
       "  '<UNK>',\n",
       "  'is',\n",
       "  'she',\n",
       "  'the',\n",
       "  'kid',\n",
       "  'you',\n",
       "  'are',\n",
       "  'gon',\n",
       "  'na',\n",
       "  'save',\n",
       "  'from',\n",
       "  'the',\n",
       "  'burning',\n",
       "  'building'],\n",
       " ['hey', 'i', 'a', 'professional'],\n",
       " ['look', 'eddie', 'i', 'tellin', 'you', 'i', 'did', 'not', 'touch', 'her'],\n",
       " ['well',\n",
       "  'you',\n",
       "  'shoulda',\n",
       "  'because',\n",
       "  'nobody',\n",
       "  'gon',\n",
       "  'na',\n",
       "  'believe',\n",
       "  'you',\n",
       "  'did',\n",
       "  'not',\n",
       "  'including',\n",
       "  'me'],\n",
       " ['i', 'took', 'her', 'there', 'for', 'a', 'shower', 'and', 'that', 'it'],\n",
       " ['i',\n",
       "  'told',\n",
       "  'you',\n",
       "  'you',\n",
       "  'know',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'i',\n",
       "  'was',\n",
       "  'doing',\n",
       "  'the',\n",
       "  'right',\n",
       "  'thing',\n",
       "  'you',\n",
       "  'know',\n",
       "  'i',\n",
       "  'think',\n",
       "  'she',\n",
       "  'innocent'],\n",
       " ['well',\n",
       "  'it',\n",
       "  'not',\n",
       "  'up',\n",
       "  'to',\n",
       "  'you',\n",
       "  'to',\n",
       "  'decide',\n",
       "  'whether',\n",
       "  'she',\n",
       "  'innocent',\n",
       "  'or',\n",
       "  'not',\n",
       "  'do',\n",
       "  'not',\n",
       "  'you',\n",
       "  'understand',\n",
       "  'that',\n",
       "  'why',\n",
       "  'you',\n",
       "  'are',\n",
       "  'a',\n",
       "  'professional'],\n",
       " ['so', 'who', 'nicky'],\n",
       " ['what', 'do', 'you', 'want'],\n",
       " ['your',\n",
       "  'opinion',\n",
       "  'you',\n",
       "  'see',\n",
       "  'they',\n",
       "  'going',\n",
       "  'to',\n",
       "  'make',\n",
       "  'a',\n",
       "  'movie',\n",
       "  'about',\n",
       "  'me',\n",
       "  'too',\n",
       "  'eddie',\n",
       "  'and',\n",
       "  'write',\n",
       "  'books'],\n",
       " ['what', 'your', '<UNK>'],\n",
       " ['i', 'kill', 'someone', 'famous'],\n",
       " ['then', 'do', 'it', 'asshole'],\n",
       " ['so',\n",
       "  '<UNK>',\n",
       "  'do',\n",
       "  'not',\n",
       "  'have',\n",
       "  'to',\n",
       "  'do',\n",
       "  're',\n",
       "  '<UNK>',\n",
       "  'they',\n",
       "  'going',\n",
       "  'to',\n",
       "  'have',\n",
       "  'real',\n",
       "  'movie',\n",
       "  'this',\n",
       "  'time'],\n",
       " ['detective', 'does', 'it', 'look', 'like', 'a', 'murder'],\n",
       " ['we',\n",
       "  'do',\n",
       "  'not',\n",
       "  'know',\n",
       "  'that',\n",
       "  'yet',\n",
       "  'it',\n",
       "  'much',\n",
       "  'too',\n",
       "  'early',\n",
       "  'there',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'to',\n",
       "  'be',\n",
       "  'done'],\n",
       " ['how', 'many', 'victims', 'are', 'up', 'there'],\n",
       " ['there', 'are', 'two', 'bodies', 'found', 'at', 'this', 'point'],\n",
       " ['can', 'we', 'go', 'up', 'to', 'the', 'crime', 'scene'],\n",
       " ['you', 'know', 'you', 'ca', 'not', 'do', 'that', \"c'mon\"],\n",
       " ['is', 'it', 'drug', 'related'],\n",
       " ['detective', 'can', 'you', 'tell', 'us', 'what', 'happened', 'here'],\n",
       " ['i',\n",
       "  'understand',\n",
       "  'but',\n",
       "  'i',\n",
       "  'noticed',\n",
       "  'that',\n",
       "  'the',\n",
       "  'fire',\n",
       "  'marshall',\n",
       "  'is',\n",
       "  'here',\n",
       "  'with',\n",
       "  'you',\n",
       "  'is',\n",
       "  'this',\n",
       "  'somehow',\n",
       "  'related',\n",
       "  'to',\n",
       "  'the',\n",
       "  'fire',\n",
       "  'department'],\n",
       " ['i',\n",
       "  'really',\n",
       "  'ca',\n",
       "  'not',\n",
       "  'give',\n",
       "  'out',\n",
       "  'any',\n",
       "  'information',\n",
       "  'right',\n",
       "  'now',\n",
       "  'at',\n",
       "  'this',\n",
       "  'point'],\n",
       " ['okay',\n",
       "  'but',\n",
       "  'i',\n",
       "  'do',\n",
       "  'understand',\n",
       "  'that',\n",
       "  'your',\n",
       "  'partner',\n",
       "  'leon',\n",
       "  'jackson',\n",
       "  'been',\n",
       "  'injured',\n",
       "  'is',\n",
       "  'that',\n",
       "  'correct'],\n",
       " ['he', 'was', 'hurt', 'but', 'not', 'seriously', 'he', 'will', 'be', 'fine'],\n",
       " ['do', 'you', 'have', 'the', 'suspect', 'in', 'custody'],\n",
       " ['um',\n",
       "  'now',\n",
       "  'is',\n",
       "  'not',\n",
       "  'a',\n",
       "  'good',\n",
       "  'time',\n",
       "  'okay',\n",
       "  'detective',\n",
       "  'jackson',\n",
       "  'hurt',\n",
       "  'he',\n",
       "  'fine',\n",
       "  'i',\n",
       "  'have',\n",
       "  'got',\n",
       "  'a',\n",
       "  'fire',\n",
       "  'marshall',\n",
       "  'shot',\n",
       "  'detective',\n",
       "  'jackson',\n",
       "  'is',\n",
       "  'hurt',\n",
       "  'but',\n",
       "  'not',\n",
       "  'seriously'],\n",
       " ['eddie', 'are', 'you', 'okay'],\n",
       " ['yeah', 'now', 'not', 'a', 'good', 'time'],\n",
       " ['alright'],\n",
       " ['alright'],\n",
       " ['alright'],\n",
       " ['alright'],\n",
       " ['hey', 'honey'],\n",
       " ['what',\n",
       "  'is',\n",
       "  'your',\n",
       "  'problem',\n",
       "  'why',\n",
       "  'would',\n",
       "  'you',\n",
       "  'snap',\n",
       "  'at',\n",
       "  'me',\n",
       "  'i',\n",
       "  'just',\n",
       "  'wanted',\n",
       "  'a',\n",
       "  'statement'],\n",
       " ['i',\n",
       "  'ca',\n",
       "  'not',\n",
       "  'i',\n",
       "  'ca',\n",
       "  'not',\n",
       "  'answer',\n",
       "  'you',\n",
       "  'just',\n",
       "  'because',\n",
       "  'you',\n",
       "  'want',\n",
       "  'me',\n",
       "  'to',\n",
       "  'answer',\n",
       "  'you'],\n",
       " ['you',\n",
       "  'did',\n",
       "  'not',\n",
       "  'have',\n",
       "  'to',\n",
       "  'embarrass',\n",
       "  'me',\n",
       "  'in',\n",
       "  'front',\n",
       "  'of',\n",
       "  'my',\n",
       "  'colleagues',\n",
       "  'you',\n",
       "  'could',\n",
       "  'give',\n",
       "  'me',\n",
       "  'something'],\n",
       " ['oh', 'i', 'sorry', 'did', 'i', 'embarrass', 'you', 'sweetheart', 'oh'],\n",
       " ['stop', 'it'],\n",
       " ['maybe',\n",
       "  'i',\n",
       "  'should',\n",
       "  'just',\n",
       "  'ya',\n",
       "  'know',\n",
       "  'turn',\n",
       "  'to',\n",
       "  'the',\n",
       "  'cameras',\n",
       "  'and',\n",
       "  'say',\n",
       "  'do',\n",
       "  'you',\n",
       "  'mind',\n",
       "  'if',\n",
       "  'we',\n",
       "  'just',\n",
       "  'work',\n",
       "  'something',\n",
       "  'out'],\n",
       " ['alright', 'alright', 'eddie', 'do', 'not', '<UNK>', 'me'],\n",
       " ['i', 'not'],\n",
       " ['yes',\n",
       "  'you',\n",
       "  'are',\n",
       "  'i',\n",
       "  'not',\n",
       "  'just',\n",
       "  'some',\n",
       "  'reporter',\n",
       "  'i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'just',\n",
       "  'stick',\n",
       "  'a',\n",
       "  '<UNK>',\n",
       "  'in',\n",
       "  'your',\n",
       "  'face',\n",
       "  'you',\n",
       "  'could',\n",
       "  'give',\n",
       "  'me',\n",
       "  'something'],\n",
       " ['yeah',\n",
       "  'well',\n",
       "  'you',\n",
       "  'took',\n",
       "  'the',\n",
       "  'camera',\n",
       "  'and',\n",
       "  'put',\n",
       "  'it',\n",
       "  'right',\n",
       "  'down',\n",
       "  'on',\n",
       "  'the',\n",
       "  'evidence',\n",
       "  'that',\n",
       "  'was'],\n",
       " ['that', 'was', 'good', 'you', 'were', 'holding', 'the', 'evidence'],\n",
       " ['you',\n",
       "  'were',\n",
       "  '<UNK>',\n",
       "  'you',\n",
       "  'did',\n",
       "  'not',\n",
       "  'give',\n",
       "  'a',\n",
       "  'shit',\n",
       "  'if',\n",
       "  'you',\n",
       "  'got',\n",
       "  'me',\n",
       "  'or',\n",
       "  'not'],\n",
       " ['well',\n",
       "  'who',\n",
       "  'was',\n",
       "  'it',\n",
       "  'that',\n",
       "  'taught',\n",
       "  'me',\n",
       "  'how',\n",
       "  'to',\n",
       "  'do',\n",
       "  'that',\n",
       "  'huh'],\n",
       " ['you', 'are', '<UNK>'],\n",
       " ['look',\n",
       "  'at',\n",
       "  'this',\n",
       "  'you',\n",
       "  'have',\n",
       "  'blood',\n",
       "  'on',\n",
       "  'your',\n",
       "  'shirt',\n",
       "  'whose',\n",
       "  'is',\n",
       "  'it'],\n",
       " ['could', 'be', 'leon'],\n",
       " ['do',\n",
       "  'not',\n",
       "  'worry',\n",
       "  'about',\n",
       "  'the',\n",
       "  'damn',\n",
       "  'phone',\n",
       "  'i',\n",
       "  'wo',\n",
       "  'not',\n",
       "  'answer',\n",
       "  'it'],\n",
       " ['answer', 'the', 'phone'],\n",
       " ['no', 'tell', 'me', 'what', 'you', 'want', 'to', 'say'],\n",
       " ['answer', 'it'],\n",
       " ['oh',\n",
       "  'my',\n",
       "  'gd',\n",
       "  'they',\n",
       "  'want',\n",
       "  'me',\n",
       "  'to',\n",
       "  'anchor',\n",
       "  'they',\n",
       "  'want',\n",
       "  'me',\n",
       "  'to',\n",
       "  'anchor',\n",
       "  'tonight'],\n",
       " ['that', 'good'],\n",
       " ['yeah'],\n",
       " ['well', 'that', 'great'],\n",
       " ['okay',\n",
       "  'that',\n",
       "  'is',\n",
       "  'great',\n",
       "  'but',\n",
       "  'i',\n",
       "  'ca',\n",
       "  'not',\n",
       "  'go',\n",
       "  'now',\n",
       "  'we',\n",
       "  'are',\n",
       "  'in',\n",
       "  'the',\n",
       "  'middle',\n",
       "  'of',\n",
       "  'something',\n",
       "  'here'],\n",
       " ['no', 'go', 'ahead', 'you', 'are', 'gon', 'na', 'be', 'great'],\n",
       " ['no',\n",
       "  'no',\n",
       "  'listen',\n",
       "  'to',\n",
       "  'me',\n",
       "  'here',\n",
       "  'i',\n",
       "  'want',\n",
       "  'to',\n",
       "  'know',\n",
       "  'what',\n",
       "  'you',\n",
       "  'are',\n",
       "  'talking',\n",
       "  'about',\n",
       "  'you',\n",
       "  'know',\n",
       "  'the',\n",
       "  'shoe',\n",
       "  'thing',\n",
       "  'and',\n",
       "  'the',\n",
       "  'marriages',\n",
       "  'and'],\n",
       " ['i',\n",
       "  'will',\n",
       "  'tell',\n",
       "  'you',\n",
       "  'tonight',\n",
       "  'let',\n",
       "  'do',\n",
       "  'it',\n",
       "  'tonight',\n",
       "  'as',\n",
       "  'soon',\n",
       "  'as',\n",
       "  'you',\n",
       "  'get',\n",
       "  'back',\n",
       "  'we',\n",
       "  'will',\n",
       "  'talk',\n",
       "  'we',\n",
       "  'will',\n",
       "  'talk'],\n",
       " ['yeah',\n",
       "  'i',\n",
       "  'will',\n",
       "  'do',\n",
       "  'that',\n",
       "  'as',\n",
       "  'long',\n",
       "  'as',\n",
       "  'you',\n",
       "  'are',\n",
       "  'not',\n",
       "  '<UNK>',\n",
       "  'me'],\n",
       " ['<UNK>', 'you', 'nay', 'i', 'love', 'you'],\n",
       " ['okay', 'til', 'tonight'],\n",
       " ['tonight'],\n",
       " ['you', 'promise'],\n",
       " ['yeah', 'yeah', 'good', 'thing'],\n",
       " ['okay'],\n",
       " ['see', 'you', 'later', 'good', 'luck'],\n",
       " ['thank', 'you'],\n",
       " ['i',\n",
       "  'think',\n",
       "  'you',\n",
       "  'are',\n",
       "  'getting',\n",
       "  'a',\n",
       "  'little',\n",
       "  '<UNK>',\n",
       "  'there',\n",
       "  'eddie'],\n",
       " ['so', 'what', 'unique'],\n",
       " ['he',\n",
       "  'from',\n",
       "  '<UNK>',\n",
       "  'his',\n",
       "  'girlfriend',\n",
       "  'was',\n",
       "  'taking',\n",
       "  'too',\n",
       "  'long',\n",
       "  'to',\n",
       "  'put',\n",
       "  'her',\n",
       "  'makeup',\n",
       "  'on',\n",
       "  'they',\n",
       "  'were',\n",
       "  'late',\n",
       "  'for',\n",
       "  'a',\n",
       "  'party',\n",
       "  'stabbed',\n",
       "  'her',\n",
       "  'with',\n",
       "  'a',\n",
       "  'beer',\n",
       "  'bottle'],\n",
       " ['that', 'unique'],\n",
       " ['i',\n",
       "  'hope',\n",
       "  'this',\n",
       "  'prick',\n",
       "  'does',\n",
       "  'not',\n",
       "  'run',\n",
       "  'my',\n",
       "  'knees',\n",
       "  'are',\n",
       "  'killing',\n",
       "  'me',\n",
       "  'stay',\n",
       "  'behind',\n",
       "  'me'],\n",
       " ['ready'],\n",
       " ['keep', 'them', 'out', 'of', 'my', 'way'],\n",
       " ['okay', 'you', 'ready'],\n",
       " ['any', 'chance', 'we', 'can', 'do', 'that', 'again'],\n",
       " ['okay',\n",
       "  'you',\n",
       "  'work',\n",
       "  'in',\n",
       "  'a',\n",
       "  'vodka',\n",
       "  'factory',\n",
       "  'i',\n",
       "  'understand',\n",
       "  'that',\n",
       "  'and',\n",
       "  'what',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'work',\n",
       "  'do',\n",
       "  'you',\n",
       "  'do'],\n",
       " ['i', 'am', 'butcher'],\n",
       " ['you',\n",
       "  'are',\n",
       "  'a',\n",
       "  'butcher',\n",
       "  'what',\n",
       "  'do',\n",
       "  'you',\n",
       "  'use',\n",
       "  'pig',\n",
       "  '<UNK>',\n",
       "  'for'],\n",
       " ['you', 'stuff', '<UNK>', 'in', 'it'],\n",
       " ['and', 'what', 'do', 'you', 'do', 'with', 'the', 'bones'],\n",
       " ['are', 'you', 'married'],\n",
       " ['come',\n",
       "  'to',\n",
       "  'broadway',\n",
       "  'do',\n",
       "  'not',\n",
       "  'bring',\n",
       "  'the',\n",
       "  'police',\n",
       "  'come',\n",
       "  'alone',\n",
       "  'or',\n",
       "  'you',\n",
       "  'will',\n",
       "  'be',\n",
       "  'in',\n",
       "  'my',\n",
       "  'next',\n",
       "  'film'],\n",
       " ['look',\n",
       "  'asshole',\n",
       "  'i',\n",
       "  'have',\n",
       "  'been',\n",
       "  'threatened',\n",
       "  'by',\n",
       "  'better',\n",
       "  'than',\n",
       "  'you'],\n",
       " ['no', 'i', 'the', 'best', 'that', 'ever', 'threatened', 'you'],\n",
       " ['i',\n",
       "  'will',\n",
       "  'meet',\n",
       "  'you',\n",
       "  'on',\n",
       "  'one',\n",
       "  'condition',\n",
       "  'i',\n",
       "  'get',\n",
       "  '<UNK>',\n",
       "  'and',\n",
       "  'you',\n",
       "  'surrender',\n",
       "  'to',\n",
       "  'me'],\n",
       " ['we',\n",
       "  'will',\n",
       "  'talk',\n",
       "  'about',\n",
       "  'that',\n",
       "  'four',\n",
       "  \"o'clock\",\n",
       "  'gives',\n",
       "  'you',\n",
       "  'time',\n",
       "  'to',\n",
       "  'go',\n",
       "  'to',\n",
       "  'bank',\n",
       "  'three',\n",
       "  'hundred',\n",
       "  'thousand',\n",
       "  'dollars'],\n",
       " ['what', 'it', 'does', 'not', 'work', 'that', 'way'],\n",
       " ['if',\n",
       "  'you',\n",
       "  'do',\n",
       "  'not',\n",
       "  'want',\n",
       "  'my',\n",
       "  'film',\n",
       "  'i',\n",
       "  'will',\n",
       "  'call',\n",
       "  'another',\n",
       "  'show',\n",
       "  'and',\n",
       "  'they',\n",
       "  'will',\n",
       "  'show',\n",
       "  'it'],\n",
       " ['wait', 'a', 'minute', 'wait', 'a', 'minute'],\n",
       " ['were',\n",
       "  'you',\n",
       "  'a',\n",
       "  'fireman',\n",
       "  'that',\n",
       "  'how',\n",
       "  'you',\n",
       "  'knew',\n",
       "  'how',\n",
       "  'to',\n",
       "  'rig',\n",
       "  'the',\n",
       "  'apartment'],\n",
       " ['my',\n",
       "  'father',\n",
       "  'was',\n",
       "  'he',\n",
       "  'gave',\n",
       "  'me',\n",
       "  'many',\n",
       "  'lessons',\n",
       "  'about',\n",
       "  'fire',\n",
       "  'now',\n",
       "  'it',\n",
       "  'my',\n",
       "  'friend'],\n",
       " ['you',\n",
       "  'ca',\n",
       "  'not',\n",
       "  'kill',\n",
       "  'me',\n",
       "  'you',\n",
       "  'are',\n",
       "  'not',\n",
       "  'a',\n",
       "  'cop',\n",
       "  'just',\n",
       "  'fireman',\n",
       "  'with',\n",
       "  'a',\n",
       "  'gun',\n",
       "  'i',\n",
       "  'bet',\n",
       "  'you',\n",
       "  'never',\n",
       "  'shot',\n",
       "  'anybody',\n",
       "  'in',\n",
       "  'your',\n",
       "  'life'],\n",
       " [\"c'mon\",\n",
       "  'pull',\n",
       "  'the',\n",
       "  'trigger',\n",
       "  'do',\n",
       "  'it',\n",
       "  'oh',\n",
       "  'look',\n",
       "  'you',\n",
       "  'are',\n",
       "  'sweating',\n",
       "  'you',\n",
       "  'do',\n",
       "  'not',\n",
       "  'have',\n",
       "  'the',\n",
       "  'balls'],\n",
       " ['where', 'your', 'partner'],\n",
       " ['tell', 'him', 'to', 'put', 'his', 'gun', 'down'],\n",
       " ['let', 'her', 'go', 'let', 'her', 'go'],\n",
       " ['hi', 'i', 'honey'],\n",
       " ['where', 'czech', 'girl'],\n",
       " ['now',\n",
       "  'i',\n",
       "  'like',\n",
       "  'to',\n",
       "  'get',\n",
       "  'business',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'way',\n",
       "  'before',\n",
       "  'we',\n",
       "  'get',\n",
       "  'down',\n",
       "  'to',\n",
       "  'pleasure',\n",
       "  'why',\n",
       "  'do',\n",
       "  '<UNK>',\n",
       "  'put',\n",
       "  'my',\n",
       "  'money',\n",
       "  'on',\n",
       "  'the',\n",
       "  '<UNK>'],\n",
       " ['it',\n",
       "  'an',\n",
       "  '<UNK>',\n",
       "  'service',\n",
       "  'run',\n",
       "  'out',\n",
       "  'of',\n",
       "  'an',\n",
       "  'apartment',\n",
       "  'i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'meet',\n",
       "  'the',\n",
       "  'other',\n",
       "  'girls',\n",
       "  'are',\n",
       "  'not',\n",
       "  'you',\n",
       "  'gon',\n",
       "  'na',\n",
       "  'get',\n",
       "  'undressed'],\n",
       " ['where', 'is', 'escort', 'service'],\n",
       " ['that',\n",
       "  'confidential',\n",
       "  'could',\n",
       "  'you',\n",
       "  'put',\n",
       "  'the',\n",
       "  'money',\n",
       "  'on',\n",
       "  'the',\n",
       "  '<UNK>'],\n",
       " ['listen',\n",
       "  'to',\n",
       "  'me',\n",
       "  'i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'want',\n",
       "  'sex',\n",
       "  'just',\n",
       "  'give',\n",
       "  'me',\n",
       "  'the',\n",
       "  'address',\n",
       "  'and',\n",
       "  'then',\n",
       "  'you',\n",
       "  'go'],\n",
       " ['give', 'me', 'the', 'address'],\n",
       " ['next', 'could', 'i', 'see', 'your', 'documents', 'please'],\n",
       " ['what',\n",
       "  'is',\n",
       "  'your',\n",
       "  'intended',\n",
       "  'purpose',\n",
       "  'of',\n",
       "  'your',\n",
       "  'visit',\n",
       "  'to',\n",
       "  'the',\n",
       "  'united',\n",
       "  'states'],\n",
       " ['two', 'weeks', 'holiday'],\n",
       " ['how', 'much', 'money', 'are', 'you', 'carrying', 'with', 'you'],\n",
       " ['i', 'have', '<UNK>', 'dollars'],\n",
       " ['is', 'he', 'with', 'you', 'are', 'you', 'travelling', 'together'],\n",
       " ['yes'],\n",
       " ['please', 'join', 'us', 'come', 'on', 'forward'],\n",
       " ['is', 'there', 'a', 'problem'],\n",
       " ['we', 'are', 'both', 'from', 'prague'],\n",
       " ['how', 'long', 'are', 'you', 'planning', 'to', 'stay'],\n",
       " ['two', 'weeks'],\n",
       " ['i', 'would', 'like', 'to', 'speak', 'for', 'himself', 'okay'],\n",
       " ['who', 'is', 'he'],\n",
       " ['this', 'all', 'you', 'want'],\n",
       " ['do',\n",
       "  'you',\n",
       "  'know',\n",
       "  'how',\n",
       "  'much',\n",
       "  'killer',\n",
       "  'gets',\n",
       "  'for',\n",
       "  'movie',\n",
       "  'rights'],\n",
       " ['in', 'here', 'says', 'he', 'wants', 'a', 'million'],\n",
       " ['just',\n",
       "  'do',\n",
       "  'what',\n",
       "  'i',\n",
       "  'do',\n",
       "  'say',\n",
       "  'the',\n",
       "  'same',\n",
       "  'thing',\n",
       "  'i',\n",
       "  'say',\n",
       "  'do',\n",
       "  'not',\n",
       "  'open',\n",
       "  'your',\n",
       "  'mouth'],\n",
       " ['do', 'not', 'fool', 'around'],\n",
       " ['did', 'you', 'hear', 'what', 'i', 'said'],\n",
       " ['look', 'times', 'square', 'just', 'like', 'in', 'the', 'movies'],\n",
       " ['do', 'not', 'speak', 'russian'],\n",
       " ['look',\n",
       "  'new',\n",
       "  '<UNK>',\n",
       "  'color',\n",
       "  '<UNK>',\n",
       "  'image',\n",
       "  '<UNK>',\n",
       "  '<UNK>',\n",
       "  'night',\n",
       "  'vision'],\n",
       " ['turn', 'that', 'off', 'get', 'the', 'bags'],\n",
       " ['why', 'should', 'i', 'carry', 'your', 'bag', 'i', 'am', 'not', 'a', 'dog'],\n",
       " ['what'],\n",
       " ['turn', 'that', 'fucking', 'thing', 'off'],\n",
       " ['speak', 'english'],\n",
       " ['you', 'said', 'speak', 'czech'],\n",
       " ['how', 'you', 'erase', 'this'],\n",
       " ['whore'],\n",
       " ['get', 'in', 'the', 'bathroom'],\n",
       " ['whatever', 'we', 'do', 'we', 'fuck', 'her', 'right'],\n",
       " ['got',\n",
       "  'ta',\n",
       "  'light',\n",
       "  'the',\n",
       "  'scene',\n",
       "  'better',\n",
       "  'now',\n",
       "  'it',\n",
       "  'more',\n",
       "  '<UNK>',\n",
       "  'like',\n",
       "  'a',\n",
       "  'scene',\n",
       "  'from',\n",
       "  'the',\n",
       "  'third',\n",
       "  'man'],\n",
       " ['shut', 'up'],\n",
       " ['oh', 'shit', 'i', 'hate', 'looking', 'at', 'that'],\n",
       " ['what', 'is', 'it'],\n",
       " ['the',\n",
       "  'video',\n",
       "  'of',\n",
       "  '<UNK>',\n",
       "  'and',\n",
       "  '<UNK>',\n",
       "  'i',\n",
       "  'told',\n",
       "  'you',\n",
       "  'to',\n",
       "  'erase',\n",
       "  'it'],\n",
       " ['i', 'did'],\n",
       " ['and',\n",
       "  'the',\n",
       "  'whore',\n",
       "  'murder',\n",
       "  'you',\n",
       "  'did',\n",
       "  'not',\n",
       "  'erase',\n",
       "  'that',\n",
       "  'either',\n",
       "  'did',\n",
       "  'you',\n",
       "  'do',\n",
       "  'not',\n",
       "  'lie',\n",
       "  'i',\n",
       "  'wo',\n",
       "  'not',\n",
       "  'be',\n",
       "  'angry'],\n",
       " ['why', 'not'],\n",
       " ['what', 'is', 'that'],\n",
       " ['let', 'me', 'get', 'a', 'shot', 'of', 'it'],\n",
       " ['sit', 'down'],\n",
       " ['okay', 'he', 'has', 'nothing', 'to', 'say', 'start', 'the', 'camera'],\n",
       " ['you',\n",
       "  'are',\n",
       "  'success',\n",
       "  'story',\n",
       "  'i',\n",
       "  'am',\n",
       "  'success',\n",
       "  'story',\n",
       "  'why',\n",
       "  'do',\n",
       "  'you',\n",
       "  'say',\n",
       "  'i',\n",
       "  'and',\n",
       "  'not',\n",
       "  'we'],\n",
       " ['in',\n",
       "  'movie',\n",
       "  'they',\n",
       "  'make',\n",
       "  'of',\n",
       "  'us',\n",
       "  'who',\n",
       "  'do',\n",
       "  'you',\n",
       "  'think',\n",
       "  'would',\n",
       "  'act',\n",
       "  'me'],\n",
       " ['i', 'serious'],\n",
       " ['this',\n",
       "  'is',\n",
       "  'my',\n",
       "  'project',\n",
       "  'i',\n",
       "  'say',\n",
       "  'i',\n",
       "  'am',\n",
       "  'the',\n",
       "  'director',\n",
       "  'you',\n",
       "  'are',\n",
       "  'the',\n",
       "  'talent',\n",
       "  'you',\n",
       "  'wait',\n",
       "  'for',\n",
       "  'me',\n",
       "  'to',\n",
       "  'say',\n",
       "  'and'],\n",
       " ['i',\n",
       "  'told',\n",
       "  'you',\n",
       "  'to',\n",
       "  'cut',\n",
       "  'that',\n",
       "  'out',\n",
       "  'before',\n",
       "  'we',\n",
       "  'handed',\n",
       "  'in',\n",
       "  'the',\n",
       "  'tape'],\n",
       " ['i',\n",
       "  'serious',\n",
       "  'this',\n",
       "  'this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'great',\n",
       "  'american',\n",
       "  'film',\n",
       "  'full',\n",
       "  'of',\n",
       "  'violence',\n",
       "  'and',\n",
       "  'sex',\n",
       "  'and',\n",
       "  'i',\n",
       "  'want',\n",
       "  'my',\n",
       "  'credit'],\n",
       " ['credit'],\n",
       " ['yes',\n",
       "  'before',\n",
       "  'we',\n",
       "  'hand',\n",
       "  'in',\n",
       "  'the',\n",
       "  'next',\n",
       "  'video',\n",
       "  'i',\n",
       "  'put',\n",
       "  '<UNK>',\n",
       "  'on',\n",
       "  'it',\n",
       "  'and',\n",
       "  'my',\n",
       "  'credit',\n",
       "  'is',\n",
       "  'going',\n",
       "  'to',\n",
       "  'read',\n",
       "  'directed',\n",
       "  'by',\n",
       "  '<UNK>',\n",
       "  '<UNK>'],\n",
       " ['you', 'got', 'that'],\n",
       " ['no', 'i', 'do', 'not', 'get', 'that'],\n",
       " ['traitor'],\n",
       " ['<UNK>'],\n",
       " ['your',\n",
       "  'sister',\n",
       "  'said',\n",
       "  'she',\n",
       "  'did',\n",
       "  'not',\n",
       "  'know',\n",
       "  'where',\n",
       "  'you',\n",
       "  'were',\n",
       "  'so',\n",
       "  'you',\n",
       "  'should',\n",
       "  'not',\n",
       "  'write',\n",
       "  'to',\n",
       "  'her',\n",
       "  'with',\n",
       "  'return',\n",
       "  'address',\n",
       "  'if',\n",
       "  'you',\n",
       "  'are',\n",
       "  'hiding'],\n",
       " ['did', 'you', 'hurt', 'her'],\n",
       " ['we', 'spent', 'it'],\n",
       " ['ha', 'ha'],\n",
       " ['i', 'can', 'get', 'you', 'a', 'job'],\n",
       " ['a', 'job'],\n",
       " ['yes', 'the', 'money', 'is', 'good'],\n",
       " ['as', 'a', 'plumber'],\n",
       " ['it', 'easy', 'to', 'learn'],\n",
       " ['a',\n",
       "  'job',\n",
       "  'as',\n",
       "  'a',\n",
       "  'plumber',\n",
       "  'you',\n",
       "  'think',\n",
       "  'i',\n",
       "  'come',\n",
       "  'to',\n",
       "  'america',\n",
       "  'to',\n",
       "  'work'],\n",
       " ['we', 'started', 'over', 'you', 'can', 'too'],\n",
       " ['robert'],\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "embedding_size = 1024\n",
    "model = Word2Vec(sentences=combined_corpus, size=embedding_size, window=5, min_count=1, workers=4, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.40502122, -0.24809213,  0.2764158 , ...,  0.12954776,\n",
       "        0.29284447, -0.16635768], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['well']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordVecs = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8101"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "word_vecs = np.zeros((len(model.wv.vocab),1024))\n",
    "for i,word in enumerate(model.wv.index2word):\n",
    "        word_vecs[i] = model[word]\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8101"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8101"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions_vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add EOS tokens to target data now that the embeddings have been trained\n",
    "for i in range(len(answers_int)):\n",
    "    answers_text[i] += \" \" + EOS\n",
    "    answers_int[i].append(METATOKEN_INDEX)\n",
    "    \n",
    "    #answers_int[i].append(answers_vocab_to_int[EOS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197194\n",
      "197194\n",
      "\n",
      "[4516]\n",
      "[2, 116, 15, 4516, 1, 56, 2, 2884, 12, 6, 2397, 8100, 4822, 12, 1929, 26, 559, 1, 71, 3, 625, 331, 44, 98, 8101]\n",
      "\n",
      "[54]\n",
      "[8100, 2523, 44, 277, 4, 27, 101, 2375, 76, 44, 561, 518, 310, 87, 5, 25, 29, 35, 44, 41, 466, 12, 5, 85, 89, 8101]\n",
      "\n",
      "[37]\n",
      "[66, 8101]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort questions and answers by the length of questions.\n",
    "# This will reduce the amount of padding during training\n",
    "# Which should speed up training and help to reduce the loss\n",
    "\n",
    "max_source_line_length = max( [len(sentence) for sentence in questions_int])\n",
    "max_targ_line_length = max([len(sentence) for sentence in answers_int])\n",
    "max_line_length = max(max_source_line_length, max_targ_line_length)\n",
    "\n",
    "sorted_questions = []\n",
    "sorted_answers = []\n",
    "\n",
    "for length in range(1, max_line_length+1):\n",
    "    for i in enumerate(questions_int):\n",
    "        if len(i[1]) == length:\n",
    "            sorted_questions.append(questions_int[i[0]])\n",
    "            sorted_answers.append(answers_int[i[0]])\n",
    "\n",
    "print(len(sorted_questions))\n",
    "print(len(sorted_answers))\n",
    "print()\n",
    "for i in range(3):\n",
    "    print(sorted_questions[i])\n",
    "    print(sorted_answers[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "np.save('word_Vecs.npy',word_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXME: This really should be something like \"preprocess_targets\"\n",
    "def process_decoding_input(target_data, vocab_to_int, batch_size):\n",
    "    '''Remove the last word id from each batch and concat the <GO> to the begining of each batch'''\n",
    "    ending = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "    dec_input = tf.concat( [tf.fill([batch_size, 1], METATOKEN_INDEX), ending], 1)\n",
    "    #dec_input = tf.concat([tf.fill([batch_size, 1], vocab_to_int[GO]), ending], 1)\n",
    "    return dec_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_cell(rnn_size, keep_prob):\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "    return tf.contrib.rnn.DropoutWrapper(lstm, input_keep_prob=keep_prob)\n",
    "\n",
    "def multi_dropout_cell(rnn_size, keep_prob, num_layers):    \n",
    "    return tf.contrib.rnn.MultiRNNCell( [dropout_cell(rnn_size, keep_prob) for _ in range(num_layers)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob, sequence_lengths):\n",
    "    \"\"\"\n",
    "    Create the encoding layer\n",
    "    \n",
    "    Returns a tuple `(outputs, output_states)` where\n",
    "      outputs is a 2-tuple of vectors of dimensions [sequence_length, rnn_size] for the forward and backward passes\n",
    "      output_states is a 2-tupe of the final hidden states of the forward and backward passes\n",
    "    \n",
    "    \"\"\"\n",
    "    forward_cell = multi_dropout_cell(rnn_size, keep_prob, num_layers)\n",
    "    backward_cell = multi_dropout_cell(rnn_size, keep_prob, num_layers)\n",
    "    outputs, states = tf.nn.bidirectional_dynamic_rnn(cell_fw = forward_cell,\n",
    "                                                   cell_bw = backward_cell,\n",
    "                                                   sequence_length = sequence_lengths,\n",
    "                                                   inputs = rnn_inputs, \n",
    "                                                   dtype=tf.float64)\n",
    "    return outputs, states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_layer(enc_state, enc_outputs, dec_embed_input, dec_embeddings, #Inputs\n",
    "                        rnn_size, num_layers, output_layer, #Architecture\n",
    "                        keep_prob, beam_width, #Hypeparameters\n",
    "                        target_lengths, batch_size,\n",
    "                        vocab_to_int): \n",
    "    \n",
    "    print(enc_state)\n",
    "    print(enc_outputs)\n",
    "    print(dec_embed_input)\n",
    "    print(dec_embeddings)\n",
    "    print(output_layer.dtype)\n",
    "    \n",
    "    with tf.variable_scope(\"decoding\", reuse=tf.AUTO_REUSE) as decoding_scope:\n",
    "        dec_cell = multi_dropout_cell(rnn_size, keep_prob, num_layers)\n",
    "        init_dec_state_size = batch_size\n",
    "        #TRAINING\n",
    "        train_attn = tf.contrib.seq2seq.BahdanauAttention(num_units=dec_cell.output_size, memory=enc_outputs,dtype=tf.float64)\n",
    "        \n",
    "        train_cell = tf.contrib.seq2seq.AttentionWrapper(dec_cell, train_attn,\n",
    "                                                    attention_layer_size=dec_cell.output_size)\n",
    "        \n",
    "        \n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(dec_embed_input, target_lengths, time_major=False)\n",
    "        train_decoder = tf.contrib.seq2seq.BasicDecoder(train_cell, helper,\n",
    "                            train_cell.zero_state(init_dec_state_size, tf.float64).clone(cell_state=enc_state),\n",
    "                            output_layer = output_layer)\n",
    "        outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(train_decoder, scope=decoding_scope)\n",
    "        logits = outputs.rnn_output\n",
    "\n",
    "        #INFERENCE\n",
    "        #Tile inputs\n",
    "        enc_state = tf.contrib.seq2seq.tile_batch(enc_state, beam_width)\n",
    "        enc_outputs = tf.contrib.seq2seq.tile_batch(enc_outputs, beam_width)\n",
    "        init_dec_state_size *= beam_width\n",
    "        \n",
    "        infer_attn = tf.contrib.seq2seq.BahdanauAttention(num_units=dec_cell.output_size, memory=enc_outputs,dtype=tf.float64)\n",
    "        infer_cell = tf.contrib.seq2seq.AttentionWrapper(dec_cell, infer_attn,\n",
    "                                                    attention_layer_size=dec_cell.output_size)\n",
    "        \n",
    "        \n",
    "        start_tokens = tf.tile( [METATOKEN_INDEX], [batch_size]) #Not by batch_size*beam_width, strangely\n",
    "        end_token = METATOKEN_INDEX #FIXME: Does decoding end upon reading, or generating, the end_token?\n",
    "        \n",
    "        #start_tokens = tf.tile([vocab_to_int[\"<GO>\"]], [batch_size])\n",
    "        #end_token = vocab_to_int[\"<EOS>\"]\n",
    "        \n",
    "        decoder = tf.contrib.seq2seq.BeamSearchDecoder(cell = infer_cell,\n",
    "            embedding = dec_embeddings,\n",
    "            start_tokens = start_tokens, \n",
    "            end_token = end_token,\n",
    "            beam_width = beam_width,\n",
    "            initial_state = infer_cell.zero_state(init_dec_state_size, tf.float64).clone(cell_state=enc_state),\n",
    "            output_layer = output_layer\n",
    "        )  \n",
    "        print(decoder)\n",
    "        final_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, scope=decoding_scope)\n",
    "        \n",
    "        ids = final_decoder_output.predicted_ids\n",
    "        beams = ids\n",
    "                \n",
    "    return logits, beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_model(wordVecs,input_data, target_data, keep_prob, batch_size,\n",
    "                  source_lengths, target_sequence_lengths,\n",
    "                  answers_vocab_size, questions_vocab_size, enc_embedding_size, dec_embedding_size,\n",
    "                  rnn_size, num_layers, beam_width, \n",
    "                  questions_vocab_to_int):\n",
    "    \n",
    "    '''   \n",
    "    enc_embed_input = tf.contrib.layers.embed_sequence(input_data, \n",
    "                                                       questions_vocab_size, \n",
    "                                                       enc_embedding_size,\n",
    "                                                       initializer = tf.random_uniform_initializer(0,1))\n",
    "    '''\n",
    "    W = tf.Variable(wordVecs,trainable=False,name=\"W\")\n",
    "    enc_embed_input = tf.nn.embedding_lookup(W, input_data)\n",
    "    enc_outputs, enc_states = encoding_layer(enc_embed_input, rnn_size, num_layers, keep_prob, source_lengths)    \n",
    "    concatenated_enc_output = tf.concat(enc_outputs, -1)\n",
    "    init_dec_state = enc_states[0]    \n",
    "    \n",
    "    \n",
    "    dec_input = process_decoding_input(target_data, questions_vocab_to_int, batch_size)\n",
    "    dec_embeddings = W \n",
    "    dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)\n",
    "    \n",
    "    output_layer = tf.layers.Dense(answers_vocab_size,bias_initializer=tf.zeros_initializer(),activation=tf.nn.relu)\n",
    "    logits, beams = decoding_layer(init_dec_state,\n",
    "                            concatenated_enc_output,\n",
    "                            dec_embed_input,\n",
    "                            dec_embeddings,\n",
    "                            rnn_size, \n",
    "                            num_layers,\n",
    "                            output_layer,\n",
    "                            keep_prob,\n",
    "                            beam_width,\n",
    "                            target_sequence_lengths, \n",
    "                            batch_size,\n",
    "                            answers_vocab_to_int,\n",
    "                            )\n",
    "    \n",
    "    \n",
    "    return logits, beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8102, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Set the Hyperparameters\n",
    "\n",
    "#Network Architecture\n",
    "rnn_size = 128\n",
    "num_layers = 2\n",
    "encoding_embedding_size = embedding_size\n",
    "decoding_embedding_size = embedding_size\n",
    "\n",
    "#Training\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "learning_rate_decay = 0.3\n",
    "min_learning_rate = 0.00001\n",
    "keep_probability = 0.75\n",
    "vocab_size = len(answers_vocab_to_int)\n",
    "#Decoding\n",
    "beam_width = 10\n",
    "\n",
    "wordVecs = np.load('word_Vecs.npy')\n",
    "metatoken_embedding = np.zeros((1, embedding_size), dtype=wordVecs.dtype)\n",
    "wordVecsWithMeta = np.concatenate( (wordVecs, metatoken_embedding), axis=0 )\n",
    "\n",
    "print(wordVecsWithMeta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8101"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8101"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions_vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wordVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inputs(batch_size):\n",
    "    '''Create palceholders for inputs to the model'''\n",
    "    input_data = tf.placeholder(tf.int32, [batch_size, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [batch_size, None], name='targets')\n",
    "    lr = tf.placeholder(tf.float64, name='learning_rate')\n",
    "    keep_prob = tf.placeholder(tf.float64, name='keep_prob')\n",
    "\n",
    "    return input_data, targets, lr, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(128, 128) dtype=float64>, h=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_4:0' shape=(128, 128) dtype=float64>), LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_5:0' shape=(128, 128) dtype=float64>, h=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_6:0' shape=(128, 128) dtype=float64>))\n",
      "Tensor(\"concat:0\", shape=(128, ?, 256), dtype=float64)\n",
      "Tensor(\"embedding_lookup_1:0\", shape=(128, ?, 1024), dtype=float64)\n",
      "<tf.Variable 'W:0' shape=(8102, 1024) dtype=float64_ref>\n",
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "dtype <dtype: 'float32'> of on_value does not match dtype parameter <dtype: 'float64'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-1ea4aaf487c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtarget_sequence_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers_vocab_to_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions_vocab_to_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     encoding_embedding_size, decoding_embedding_size, rnn_size, num_layers, beam_width, questions_vocab_to_int)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Find the shape of the input data for sequence_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-fb0de7b32ca0>\u001b[0m in \u001b[0;36mseq2seq_model\u001b[0;34m(wordVecs, input_data, target_data, keep_prob, batch_size, source_lengths, target_sequence_lengths, answers_vocab_size, questions_vocab_size, enc_embedding_size, dec_embedding_size, rnn_size, num_layers, beam_width, questions_vocab_to_int)\u001b[0m\n\u001b[1;32m     34\u001b[0m                             \u001b[0mtarget_sequence_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                             \u001b[0manswers_vocab_to_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                             )\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-111-2f3616bc0832>\u001b[0m in \u001b[0;36mdecoding_layer\u001b[0;34m(enc_state, enc_outputs, dec_embed_input, dec_embeddings, rnn_size, num_layers, output_layer, keep_prob, beam_width, target_lengths, batch_size, vocab_to_int)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0moutput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         )    \n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mfinal_decoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoding_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_decoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\u001b[0m in \u001b[0;36mdynamic_decode\u001b[0;34m(decoder, output_time_major, impute_finished, maximum_iterations, parallel_iterations, swap_memory, scope)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"maximum_iterations must be a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0minitial_finished\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     zero_outputs = _create_zero_outputs(decoder.output_size,\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mon_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0moff_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         dtype=nest.flatten(self._initial_cell_state)[0].dtype)\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     initial_state = BeamSearchDecoderState(\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(indices, depth, on_value, off_value, axis, dtype, name)\u001b[0m\n\u001b[1;32m   2444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mon_exists\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mon_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m           raise TypeError(\"dtype {0} of on_value does not match \"\n\u001b[0;32m-> 2446\u001b[0;31m                           \"dtype parameter {1}\".format(on_dtype, dtype))\n\u001b[0m\u001b[1;32m   2447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moff_exists\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moff_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m           raise TypeError(\"dtype {0} of off_value does not match \"\n",
      "\u001b[0;31mTypeError\u001b[0m: dtype <dtype: 'float32'> of on_value does not match dtype parameter <dtype: 'float64'>"
     ]
    }
   ],
   "source": [
    "# Reset the graph to ensure that it is ready for training\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "# Placeholders for feed_dict    \n",
    "input_data, targets, lr, keep_prob = model_inputs(batch_size)\n",
    "\n",
    "source_lengths = tf.placeholder(tf.int32, [batch_size], name=\"source_lengths\")\n",
    "max_sequence_length_batch = tf.placeholder(tf.int32)\n",
    "\n",
    "input_shape = tf.shape(input_data)\n",
    "target_sequence_lengths = tf.fill([input_shape[0]], max_sequence_length_batch)\n",
    "\n",
    "# Create the training and inference logits\n",
    "#FIXME: Change \"batch_size\" to input_shape[0]?\n",
    "train_logits, beams = \\\n",
    "seq2seq_model(wordVecsWithMeta,input_data,\n",
    "              #tf.reverse(input_data, [-1]),\n",
    "              targets, keep_prob, batch_size,\n",
    "              source_lengths,\n",
    "    target_sequence_lengths, \n",
    "    len(answers_vocab_to_int), len(questions_vocab_to_int),\n",
    "    encoding_embedding_size, decoding_embedding_size, rnn_size, num_layers, beam_width, questions_vocab_to_int)\n",
    "\n",
    "# Find the shape of the input data for sequence_loss\n",
    "with tf.name_scope(\"optimization\"):\n",
    "\n",
    "    cost = tf.losses.huber_loss(\n",
    "                   train_logits,\n",
    "                   tf.one_hot(targets,len(answers_vocab_to_int),axis=-1),\n",
    "                   delta=1.0,\n",
    "                   scope=None,\n",
    "                   loss_collection=tf.GraphKeys.LOSSES,\n",
    "                   reduction=tf.losses.Reduction.SUM_BY_NONZERO_WEIGHTS)\n",
    "\n",
    "   # cost=tf.reduce_mean(tf.nn.l2_loss(train_logits - tf.one_hot(targets,vocab_size,axis=-1)))\n",
    "    #cost = tf.reduce_mean(tf.square(tf.subtract(train_logits,targets)))\n",
    "    #cost = losses * tf.ones([batch_size, max_sequence_length_batch])\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "    # Gradient Clipping\n",
    "    gradients = optimizer.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]\n",
    "    train_op = optimizer.apply_gradients(capped_gradients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch, vocab_to_int):\n",
    "    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n",
    "    #pad_int = vocab_to_int[PAD]\n",
    "    pad_int = METATOKEN_INDEX\n",
    "    max_sentence_length = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [pad_int] * (max_sentence_length - len(sentence)) for sentence in sentence_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(questions, answers, batch_size):\n",
    "    \"\"\"Batch questions and answers together\"\"\"\n",
    "    for batch_i in range(0, len(questions)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "        questions_batch = questions[start_i:start_i + batch_size]\n",
    "        answers_batch = answers[start_i:start_i + batch_size]\n",
    "        \n",
    "        source_lengths = np.array( [len(sentence) for sentence in questions_batch] )\n",
    "        \n",
    "        pad_questions_batch = np.array(pad_sentence_batch(questions_batch, questions_vocab_to_int))\n",
    "        pad_answers_batch = np.array(pad_sentence_batch(answers_batch, answers_vocab_to_int))\n",
    "        yield source_lengths, pad_questions_batch, pad_answers_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167152\n",
      "29497\n"
     ]
    }
   ],
   "source": [
    "# Validate the training with 10% of the data\n",
    "train_valid_split = int(len(sorted_questions)*0.15)\n",
    "\n",
    "# Split the questions and answers into training and validating data\n",
    "train_questions = sorted_questions[train_valid_split:]\n",
    "train_answers = sorted_answers[train_valid_split:]\n",
    "\n",
    "valid_questions = sorted_questions[:train_valid_split]\n",
    "valid_answers = sorted_answers[:train_valid_split]\n",
    "\n",
    "print(len(train_questions))\n",
    "print(len(valid_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[15,30] = 8101 is not in [0, 7901)\n\t [[Node: embedding_lookup_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](W/read, concat_1, embedding_lookup_1/axis)]]\n\nCaused by op 'embedding_lookup_1', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-418-7cc5a8cb3578>\", line 22, in <module>\n    encoding_embedding_size, decoding_embedding_size, rnn_size, num_layers, beam_width, questions_vocab_to_int)\n  File \"<ipython-input-412-8cd018efcf6d>\", line 24, in seq2seq_model\n    dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 308, in embedding_lookup\n    transform_fn=None)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 131, in _embedding_lookup_and_transform\n    result = _clip(array_ops.gather(params[0], ids, name=name),\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2736, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3065, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[15,30] = 8101 is not in [0, 7901)\n\t [[Node: embedding_lookup_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](W/read, concat_1, embedding_lookup_1/axis)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[15,30] = 8101 is not in [0, 7901)\n\t [[Node: embedding_lookup_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](W/read, concat_1, embedding_lookup_1/axis)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-422-7be975ce027e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                  \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                  \u001b[0mmax_sequence_length_batch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0manswers_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                  keep_prob: keep_probability})\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[15,30] = 8101 is not in [0, 7901)\n\t [[Node: embedding_lookup_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](W/read, concat_1, embedding_lookup_1/axis)]]\n\nCaused by op 'embedding_lookup_1', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-418-7cc5a8cb3578>\", line 22, in <module>\n    encoding_embedding_size, decoding_embedding_size, rnn_size, num_layers, beam_width, questions_vocab_to_int)\n  File \"<ipython-input-412-8cd018efcf6d>\", line 24, in seq2seq_model\n    dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 308, in embedding_lookup\n    transform_fn=None)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 131, in _embedding_lookup_and_transform\n    result = _clip(array_ops.gather(params[0], ids, name=name),\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2736, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3065, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[15,30] = 8101 is not in [0, 7901)\n\t [[Node: embedding_lookup_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](W/read, concat_1, embedding_lookup_1/axis)]]\n"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "display_step = 100 # Check training loss after every 100 batches\n",
    "total_train_loss = 0 # Record the training loss for each display step\n",
    "\n",
    "#VALIDATION\n",
    "stop_early = 0 \n",
    "stop = 5 # If the validation loss does decrease in 5 consecutive checks, stop training\n",
    "validation_check = ((len(train_questions))//batch_size//2)-1 #Check validation loss every half-epoch\n",
    "summary_valid_loss = [] # Record the validation loss for saving improvements in the model\n",
    "\n",
    "\n",
    "checkpoint = \"./checkpoints/best_model.ckpt\" \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch_i in range(1, epochs+1):\n",
    "        for batch_i, (q_lengths, questions_batch, answers_batch) in enumerate(\n",
    "                batch_data(train_questions, train_answers, batch_size)):\n",
    "            #print(answers_batch)\n",
    "            start_time = time.time()\n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: questions_batch,\n",
    "                 targets: answers_batch,\n",
    "                 source_lengths: q_lengths,\n",
    "                 lr: learning_rate,\n",
    "                 max_sequence_length_batch: answers_batch.shape[1],\n",
    "                 keep_prob: keep_probability})\n",
    "\n",
    "            total_train_loss += loss\n",
    "            end_time = time.time()\n",
    "            batch_time = end_time - start_time\n",
    "            \n",
    "            total_train_loss += loss\n",
    "            end_time = time.time()\n",
    "            batch_time = end_time - start_time\n",
    "\n",
    "            if batch_i % display_step == 0:\n",
    "                print('Epoch {:>3}/{} Batch {:>4}/{} - Loss: {:>9.6f}, Seconds: {:>4.2f}'\n",
    "                      .format(epoch_i,\n",
    "                              epochs, \n",
    "                              batch_i, \n",
    "                              len(train_questions) // batch_size, \n",
    "                              total_train_loss / display_step, \n",
    "                              batch_time*display_step),\n",
    "                         flush=True)\n",
    "                total_train_loss = 0\n",
    "\n",
    "            if batch_i % validation_check == 0 and batch_i > 0:\n",
    "                total_valid_loss = 0\n",
    "                start_time = time.time()\n",
    "                for batch_ii, (q_lengths, questions_batch, answers_batch) in \\\n",
    "                        enumerate(batch_data(valid_questions, valid_answers, batch_size)):\n",
    "                    valid_loss = sess.run(\n",
    "                    cost, {input_data: questions_batch,\n",
    "                           targets: answers_batch,\n",
    "                           lr: learning_rate,\n",
    "                           source_lengths: q_lengths,\n",
    "                           max_sequence_length_batch: answers_batch.shape[1],\n",
    "                           keep_prob: 1})\n",
    "                    total_valid_loss += valid_loss\n",
    "                end_time = time.time()\n",
    "                batch_time = end_time - start_time\n",
    "                avg_valid_loss = total_valid_loss / (len(valid_questions) / batch_size)\n",
    "                print('Valid Loss: {:>9.6f}, Seconds: {:>5.2f}'.format(avg_valid_loss, batch_time), flush=True)\n",
    "\n",
    "                # Reduce learning rate, but not below its minimum value\n",
    "                learning_rate *= learning_rate_decay\n",
    "                if learning_rate < min_learning_rate:\n",
    "                    learning_rate = min_learning_rate\n",
    "\n",
    "                summary_valid_loss.append(avg_valid_loss)\n",
    "                if avg_valid_loss <= min(summary_valid_loss):\n",
    "                    print('New Record!') \n",
    "                    stop_early = 0\n",
    "                    saver = tf.train.Saver() \n",
    "                    saver.save(sess, checkpoint)\n",
    "\n",
    "                else:\n",
    "                    print(\"No Improvement.\")\n",
    "                    stop_early += 1\n",
    "                    if stop_early == stop:\n",
    "                        break\n",
    "    \n",
    "        if stop_early == stop:\n",
    "            print(\"Stopping Training.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_to_seq(question, vocab_to_int, int_to_vocab):\n",
    "    '''Prepare the question for the model'''\n",
    "        \n",
    "    cleaned_question = Corpus.clean_sequence(question)\n",
    "    return [vocab_to_int.get(word, vocab_to_int[UNK]) for word in cleaned_question]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question\n",
      "  Word Ids:      [666, 21, 3, 4558, 7018, 12, 8100]\n",
      "  Input Words: ['major', 'this', 'is', 'deeply', 'offensive', 'and', '<UNK>']\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/best_model.ckpt\n",
      "\n",
      "Answer 0\n",
      "  Word Ids:      [1, 8, 5, 22]\n",
      "  Response Words: ['i', 'do', 'not', 'know']\n",
      "\n",
      "Answer 1\n",
      "  Word Ids:      [1, 8, 5, 22, 8100]\n",
      "  Response Words: ['i', 'do', 'not', 'know', '<UNK>']\n",
      "\n",
      "Answer 2\n",
      "  Word Ids:      [1, 8, 5, 22, 7]\n",
      "  Response Words: ['i', 'do', 'not', 'know', 'it']\n",
      "\n",
      "Answer 3\n",
      "  Word Ids:      [1, 8, 5, 8, 5]\n",
      "  Response Words: ['i', 'do', 'not', 'do', 'not']\n",
      "\n",
      "Answer 4\n",
      "  Word Ids:      [1, 8, 5, 8, 5, 22]\n",
      "  Response Words: ['i', 'do', 'not', 'do', 'not', 'know']\n",
      "\n",
      "Answer 5\n",
      "  Word Ids:      [1, 8, 5, 8, 5, 22, 7]\n",
      "  Response Words: ['i', 'do', 'not', 'do', 'not', 'know', 'it']\n",
      "\n",
      "Answer 6\n",
      "  Word Ids:      [1, 8, 5, 8, 5, 22, 1, 18, 5]\n",
      "  Response Words: ['i', 'do', 'not', 'do', 'not', 'know', 'i', 'am', 'not']\n",
      "\n",
      "Answer 7\n",
      "  Word Ids:      [1, 8, 5, 8, 5, 22, 7, 3, 6, 8100]\n",
      "  Response Words: ['i', 'do', 'not', 'do', 'not', 'know', 'it', 'is', 'a', '<UNK>']\n",
      "\n",
      "Answer 8\n",
      "  Word Ids:      [1, 8, 5, 8, 5, 22, 7, 3, 2, 8100]\n",
      "  Response Words: ['i', 'do', 'not', 'do', 'not', 'know', 'it', 'is', 'the', '<UNK>']\n",
      "\n",
      "Answer 9\n",
      "  Word Ids:      [1, 8, 5, 8, 5, 22, 1, 18, 5, 8, 5, 22]\n",
      "  Response Words: ['i', 'do', 'not', 'do', 'not', 'know', 'i', 'am', 'not', 'do', 'not', 'know']\n"
     ]
    }
   ],
   "source": [
    "# Create your own input question\n",
    "#input_question = 'How are you?'\n",
    "\n",
    "# Use a question from the data as your input\n",
    "random = np.random.choice(len(sorted_questions))\n",
    "input_question = sorted_questions[random]\n",
    "\n",
    "# Prepare the question\n",
    "input_question = question_to_seq(input_question, questions_vocab_to_int, questions_int_to_vocab)\n",
    "\n",
    "# Pad the questions until it equals the max_line_length\n",
    "input_question = input_question + [questions_vocab_to_int[PAD]] * (max_line_length - len(input_question))\n",
    "# Add empty questions so the the input_data is the correct shape\n",
    "batch_shell = np.zeros((batch_size, max_line_length))\n",
    "# Set the first question to be out input question\n",
    "batch_shell[0] = input_question \n",
    "\n",
    "# Remove the padding from the Question and Answer\n",
    "#pad_q = questions_vocab_to_int[PAD]\n",
    "#pad_a = questions_vocab_to_int[EOS]\n",
    "pad_q = METATOKEN_INDEX\n",
    "pad_a = METATOKEN_INDEX\n",
    "    \n",
    "print('Question')\n",
    "print('  Word Ids:      {}'.format([i for i in input_question if i != pad_q]))\n",
    "print('  Input Words: {}'.format([questions_int_to_vocab[i] for i in input_question if i != pad_q]))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    # Run the model with the input question\n",
    "    saver.restore(sess, checkpoint)\n",
    "    beam_output = sess.run(beams, {input_data: batch_shell,\n",
    "                                   source_lengths: [len(input_question)] * batch_size,\n",
    "                                                keep_prob: 1.0})[0]\n",
    "\n",
    "\n",
    "for i in range(beam_width):\n",
    "    beam = beam_output[:, i]\n",
    "    print('\\nAnswer', i)\n",
    "    print('  Word Ids:      {}'.format([i for i in beam if i != pad_a]))\n",
    "    print('  Response Words: {}'.format([answers_int_to_vocab[i] for i in beam if i != pad_a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
