{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "#Local modules\n",
    "import models\n",
    "import training\n",
    "import loader\n",
    "import tf_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate = False #Don't relearn the Word2Vec embeddings\n",
    "data = loader.Loader(\"corpora/\", \"./word_Vecs.npy\", regenerate=regenerate) #Loads data and vanilla Word2Vec embeddings\n",
    "\n",
    "train_prompts_int = data.train_prompts_int\n",
    "train_answers_int = data.train_answers_int\n",
    "valid_prompts_int = data.valid_prompts_int\n",
    "valid_answers_int = data.valid_answers_int\n",
    "vocab2int         = data.vocab2int\n",
    "int2vocab         = data.int2vocab\n",
    "unk_int           = data.unk_int\n",
    "unk               = data.unk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing all model files to checkpoints/Jul02_15:17:18\n"
     ]
    }
   ],
   "source": [
    "time_string = time.strftime(\"%b%d_%H:%M:%S\")\n",
    "checkpoint_dir = os.path.join(\"checkpoints\", time_string)\n",
    "if not os.path.exists(checkpoint_dir): os.makedirs(checkpoint_dir)\n",
    "checkpoint_best = str(checkpoint_dir) + \"/\" + \"best_model.ckpt\"\n",
    "checkpoint_latest = str(checkpoint_dir) + \"/\" + \"latest_model.ckpt\"\n",
    "sys.stderr.write(\"Writing all model files to {}\\n\".format(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_eos(answers_int, eos_int):\n",
    "        return [sequence+[eos_int] for sequence in answers_int]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vecs_with_meta(wordVecs):\n",
    "    \"\"\"\n",
    "    wordVecs - an np array of word embeddings\n",
    "    Returns\n",
    "            (np array with the metatoken embeddings appended, the index of the metatoken embedding)\n",
    "    \"\"\"\n",
    "    embedding_size = wordVecs.shape[1] #Dynamically determine embedding size from loaded embedding file\n",
    "    metatoken_embedding = np.zeros((1, embedding_size), dtype=wordVecs.dtype)\n",
    "    wordVecsWithMeta = np.concatenate( (wordVecs, metatoken_embedding), axis=0 )\n",
    "    return wordVecsWithMeta, wordVecsWithMeta.shape[0]-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAD Appended Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor of shape [1024,256] and type float\n\t [[Node: decoding/attention_wrapper/bahdanau_attention/query_layer/kernel/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [1024,256] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'decoding/attention_wrapper/bahdanau_attention/query_layer/kernel/Adam/Initializer/zeros', defined at:\n  File \"/opt/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/opt/anaconda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/anaconda/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/opt/anaconda/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/opt/anaconda/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/opt/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-ca35ce30563a>\", line 24, in <module>\n    output_layer=output_layer, affect_strength = 0.5)\n  File \"/home/emines/EmotChatbot/models.py\", line 210, in __init__\n    self._train_op = self.optimizer.apply_gradients(capped_gradients)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 552, in apply_gradients\n    self._create_slots([_get_variable_for(v) for v in var_list])\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 131, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 984, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 179, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 153, in create_slot_with_initializer\n    dtype)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1297, in get_variable\n    constraint=constraint)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1093, in get_variable\n    constraint=constraint)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 439, in get_variable\n    constraint=constraint)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 408, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 800, in _get_single_variable\n    use_resource=use_resource)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2157, in variable\n    use_resource=use_resource)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2147, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2130, in default_variable_creator\n    constraint=constraint)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 337, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 784, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py\", line 99, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1601, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2583, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [1024,256] and type float\n\t [[Node: decoding/attention_wrapper/bahdanau_attention/query_layer/kernel/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [1024,256] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [1024,256] and type float\n\t [[Node: decoding/attention_wrapper/bahdanau_attention/query_layer/kernel/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [1024,256] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ca35ce30563a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         training.training_loop(sess, model, trainer, datasets, text_data,\n\u001b[1;32m     39\u001b[0m                                train_feeds, valid_feeds, min_epochs_before_validation=2)\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [1024,256] and type float\n\t [[Node: decoding/attention_wrapper/bahdanau_attention/query_layer/kernel/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [1024,256] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'decoding/attention_wrapper/bahdanau_attention/query_layer/kernel/Adam/Initializer/zeros', defined at:\n  File \"/opt/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/opt/anaconda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/anaconda/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/opt/anaconda/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/opt/anaconda/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/opt/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-ca35ce30563a>\", line 24, in <module>\n    output_layer=output_layer, affect_strength = 0.5)\n  File \"/home/emines/EmotChatbot/models.py\", line 210, in __init__\n    self._train_op = self.optimizer.apply_gradients(capped_gradients)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 552, in apply_gradients\n    self._create_slots([_get_variable_for(v) for v in var_list])\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 131, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 984, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 179, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 153, in create_slot_with_initializer\n    dtype)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1297, in get_variable\n    constraint=constraint)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1093, in get_variable\n    constraint=constraint)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 439, in get_variable\n    constraint=constraint)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 408, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 800, in _get_single_variable\n    use_resource=use_resource)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2157, in variable\n    use_resource=use_resource)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2147, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2130, in default_variable_creator\n    constraint=constraint)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 337, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 784, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py\", line 99, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1601, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2583, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [1024,256] and type float\n\t [[Node: decoding/attention_wrapper/bahdanau_attention/query_layer/kernel/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [1024,256] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "full_embeddings = data.load_vad(\"word_Vecs_VAD.npy\", regenerate=regenerate)\n",
    "(wordVecsWithMeta, metatoken) = word_vecs_with_meta(full_embeddings)\n",
    "go_token = metatoken\n",
    "eos_token = metatoken\n",
    "pad_token = metatoken\n",
    "\n",
    "\n",
    "train_answers_int = append_eos(train_answers_int, eos_token)\n",
    "valid_answers_int = append_eos(valid_answers_int, eos_token)\n",
    "\n",
    "#Just a class that makes it so we don't have to pass all 4 of these as separate parameters to functions\n",
    "datasets = tf_collections.Datasets(train_prompts_int=train_prompts_int,\n",
    "                        train_answers_int=train_answers_int,\n",
    "                        valid_prompts_int=valid_prompts_int,\n",
    "                        valid_answers_int=valid_answers_int\n",
    "                )\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "data_placeholders = models.create_placeholders()\n",
    "output_layer = tf.layers.Dense(len(wordVecsWithMeta),bias_initializer=tf.zeros_initializer(),\n",
    "                               activation=tf.nn.relu)\n",
    "model = models.VADAppended(data_placeholders, wordVecsWithMeta, go_token, eos_token,\n",
    "                           output_layer=output_layer, affect_strength = 0.5)\n",
    "\n",
    "\n",
    "xent_epochs = 12\n",
    "train_feeds = {model.keep_prob: 0.75}\n",
    "valid_feeds = {model.keep_prob: 1}\n",
    "\n",
    "trainer = training.Trainer(checkpoint_best, checkpoint_latest, max_epochs=xent_epochs)\n",
    "text_data = tf_collections.TextData(prompts_int2vocab=int2vocab,\n",
    "                                answers_int2vocab=int2vocab,\n",
    "                                unk_int=unk_int, eos_int=eos_token, pad_int=pad_token)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training.training_loop(sess, model, trainer, datasets, text_data,\n",
    "                               train_feeds, valid_feeds, min_epochs_before_validation=2)\n",
    "\n",
    "        affect_epochs = (trainer.epochs_completed // 4) + 1*(trainer.epochs_completed < 4)\n",
    "        total_epochs = trainer.epochs_completed + affect_epochs\n",
    "        train_feeds[model.train_affect] = True\n",
    "        sys.stderr.write(\"Switching from cross-entropy to maximum affective content . . .\\n\")\n",
    "\n",
    "        affect_trainer = training.Trainer(checkpoint_best, checkpoint_latest,\n",
    "                                epochs_completed=trainer.epochs_completed,\n",
    "                                max_epochs=total_epochs, saver=trainer.saver,\n",
    "                                best_valid_cost = trainer.best_valid_cost)\n",
    "\n",
    "        training.training_loop(sess, model, affect_trainer, datasets, text_data, train_feeds, valid_feeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aff2Vec Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfit=True #Use `False` for retrofitting\n",
    "    \n",
    "if counterfit:\n",
    "        full_embeddings = data.load_counterfit(\"word_Vecs_counterfit_affect.npy\",\n",
    "                                                    \"./w2v_counterfit_append_affect.bin\",\n",
    "                                                    regenerate=regenerate)\n",
    "else:\n",
    "        full_embeddings = data.load_counterfit(\"word_Vecs_retrofit_affect.npy\",\n",
    "                                                    \"./w2v_counterfit_append_affect.bin\",\n",
    "                                                    regenerate=regenerate)\n",
    "(wordVecsWithMeta, metatoken) = word_vecs_with_meta(full_embeddings)\n",
    "go_token = metatoken\n",
    "eos_token = metatoken\n",
    "pad_token = metatoken\n",
    "\n",
    "\n",
    "train_answers_int = append_eos(train_answers_int, eos_token)\n",
    "valid_answers_int = append_eos(valid_answers_int, eos_token)\n",
    "datasets = tf_collections.Datasets(train_prompts_int=train_prompts_int,\n",
    "                        train_answers_int=train_answers_int,\n",
    "                        valid_prompts_int=valid_prompts_int,\n",
    "                        valid_answers_int=valid_answers_int\n",
    "                )\n",
    "\n",
    "tf.reset_default_graph()\n",
    "data_placeholders = models.create_placeholders()\n",
    "output_layer = tf.layers.Dense(len(wordVecsWithMeta),bias_initializer=tf.zeros_initializer(),activation=tf.nn.relu)\n",
    "model = models.Aff2Vec(data_placeholders, wordVecsWithMeta, wordVecsWithMeta, go_token, eos_token,\n",
    "                       output_layer=output_layer)\n",
    "\n",
    "xent_epochs = 15\n",
    "train_feeds = {model.keep_prob: 0.75}\n",
    "valid_feeds = {model.keep_prob: 1}\n",
    "\n",
    "trainer = training.Trainer(checkpoint_best, checkpoint_latest, max_epochs=xent_epochs, max_stalled_steps=2)\n",
    "text_data = tf_collections.TextData(prompts_int2vocab=int2vocab, answers_int2vocab=int2vocab,\n",
    "                                unk_int=unk_int, eos_int=eos_token, pad_int=pad_token)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training.training_loop(sess, model, trainer, datasets, text_data,\n",
    "                               train_feeds, valid_feeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
